{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u524d\u8a00 # \u51fa\u4e8e\u5982\u4e0b\u539f\u56e0\u6211\u521b\u5efa\u4e86\u8fd9\u4e2a\u9879\u76ee\uff1a \u5728\u4ece\u4e8b NLP \u76f8\u5173\u7684\u9879\u76ee\u7684\u5f00\u53d1\u8fc7\u7a0b\u4e2d\uff0c\u9047\u5230\u4e86\u5f88\u591a\u548c \u8bed\u8a00 \u76f8\u5173\u7684\u7406\u8bba \u9605\u8bfb \u300aNatural Language Processing with Python\u300b \u65f6\uff0c\u53d1\u73b0\u5176\u4e2d\u6d89\u53ca\u4e86\u4e00\u4e9b\u548c \u8bed\u8a00 \u76f8\u5173\u7684\u7406\u8bba \u9605\u8bfb \u300a Compilers: Principles, Techniques, and Tools \u300b \uff08\u9f99\u4e66\uff09\u65f6\uff0c\u53d1\u73b0\u5176\u4e2d\u6d89\u53ca\u4e86\u5f88\u591a formal language \u76f8\u5173\u7684\u7406\u8bba \u672c\u9879\u76ee\u7684\u5185\u5bb9\u5927\u591a\u6570\u6765\u81ea: \u7ef4\u57fa\u767e\u79d1: Automata theory : formal languages and formal grammars Introduction to Automata and Language Theory(aka Cinderella Book ) \u8fd9\u4e2a\u9879\u76ee\u662f\u5bf9 \u8bed\u8a00 \u76f8\u5173\u7684\u7406\u8bba\u7684\u4e00\u4e2a\u68b3\u7406\uff0c\u5b83\u4e3b\u8981\u4f5c\u4e3a\u5982\u4e0b\u9879\u76ee\u6240\u6d89\u53ca\u7684\u7406\u8bba\u7684\u603b\u7ed3\uff1a compiler-principle compiler-principle-in-action Natural-Language-Processing-with-Python \u5b66\u4e60\u8ba1\u5212--\u4ece\u5165\u95e8\u5230\u7cbe\u901a # Formal language \u6240\u6d89\u53ca\u7684\u7406\u8bba\u8f83\u591a\uff0c\u5e76\u4e14\u5927\u591a\u6570\u90fd\u662f\u6bd4\u8f83\u62bd\u8c61\u7684\uff0c\u521a\u5f00\u59cb\u5b66\u4e60\uff08\u5c24\u5176\u5bf9\u4e8e\u7f3a\u4e4f\u4f7f\u7528programming language\u7684\u4eba\u6765\u8bf4\uff09\u53ef\u80fd\u4f1a\u611f\u89c9\u6bd4\u8f83\u5403\u529b\uff0c\u4ee5\u4e0b\u662f\u89c9\u5f97\u6bd4\u8f83\u597d\u7684\u5b66\u4e60\u8ba1\u5212\uff1a \u9996\u5148\u641e\u6e05\u695awhat is language\u3001what is formal language\u3001what is formal grammar\u3001what is automata\u3001What is the relationship between them\uff0c\u8fd9\u6837\u5c31\u5efa\u7acb\u8d77\u4e86\u5efa\u7acb\u8d77\u9ad8\u5c4b\u5efa\u74f4\u7684\u89c6\u91ce\uff0c\u8fd9\u5176\u5b9e\u5c31\u662f\u7b97\u5165\u95e8\u4e86\u3002\u63a8\u8350\u9605\u8bfb\u4e0b\u9762\u7684\u6587\u7ae0\uff1a Formal Languages, Grammars, and Automata \u5165\u95e8\u4e86\u4e4b\u540e\uff0c\u5c31\u9700\u8981\u5efa\u7acb\u8d77theory framework\uff0c\u6700\u7ec8\u6211\u4eec\u4f1a\u53d1\u73b0\uff0c\u4f7f\u7528 Chomsky hierarchy \u5c31\u80fd\u591f\u5c06\u6574\u4e2a\u7406\u8bba\u7ed9\u7edf\u4e00\u8d77\u6765\uff1b\u7136\u540e\u518d\u9010\u4e2a\u8fdb\u884c\u7ec6\u81f4\u5206\u6790\uff0c\u6700\u540e\u5c31\u80fd\u591f\u878d\u4f1a\u8d2f\u901a\uff0c\u8fd9\u5176\u5b9e\u5c31\u662f\u7cbe\u901a\u4e86\u3002 Theory Framework # Language # \u5bf9\u8bed\u8a00\u7684\u4e00\u79cd\u5206\u7c7b\u65b9\u6cd5\uff1a Constructed language Formal language Programming language Natural languages Note: \u4e0a\u8bc9\u5206\u7c7b\u6240\u4f20\u8fbe\u7684\u542b\u4e49\u6709\uff1a Formal language \u4e0d\u662f natural language Formal language # \u63d0\u53ca formal language \uff0c\u5c31\u5f97\u8bf7\u51fa Noam Chomsky \uff0c\u56e0\u4e3a\u4e0b\u9762\u7684\u7406\u8bba\u6846\u67b6\u662f\u7531\u4ed6\u6240\u5efa\u7acb\u7684\uff0c\u8be5theory framework\u7684\u662f\u6309\u7167 Chomsky hierarchy \u6765\u8fdb\u884c\u7ec4\u7ec7\u7684\uff1a Chomsky hierarchy Grammars Languages Abstract machines Type-0 Unrestricted Recursively enumerable Turing machine \u2014 (no common name) Decidable Decider Type-1 Context-sensitive Context-sensitive Linear-bounded \u2014 Positive range concatenation Positive range concatenation * PTIME Turing Machine \u2014 Indexed Indexed * Nested stack \u2014 \u2014 \u2014 Thread automaton \u2014 Linear context-free rewriting systems Linear context-free rewriting language restricted Tree stack automaton \u2014 Tree-adjoining Tree-adjoining Embedded pushdown Type-2 Context-free Context-free Nondeterministic pushdown \u2014 Deterministic context-free Deterministic context-free Deterministic pushdown \u2014 Visibly pushdown Visibly pushdown Visibly pushdown Type-3 Regular Regular Finite \u2014 \u2014 Star-free Counter-free (with aperiodic finite monoid) \u2014 Non-recursive Finite Acyclic finite Each category of languages, except those marked by a * , is a proper subset of the category directly above it. Any language in each category is generated by a grammar and by an automaton in the category in the same line. \u76ee\u5f55\u7ed3\u6784\u8bf4\u660e # \u672c\u5de5\u7a0b\u5c31\u662f\u6309\u7167 \u5b66\u4e60\u8ba1\u5212--\u4ece\u5165\u95e8\u5230\u7cbe\u901a \u7ae0\u8282\u6240\u63cf\u8ff0\u7684\u601d\u8def\u7ec4\u7ec7\u7684\uff1a introduction\uff1a\u5165\u95e8 theory-framework\uff1a\u7406\u8bba\u6846\u67b6","title":"Home"},{"location":"#_1","text":"\u51fa\u4e8e\u5982\u4e0b\u539f\u56e0\u6211\u521b\u5efa\u4e86\u8fd9\u4e2a\u9879\u76ee\uff1a \u5728\u4ece\u4e8b NLP \u76f8\u5173\u7684\u9879\u76ee\u7684\u5f00\u53d1\u8fc7\u7a0b\u4e2d\uff0c\u9047\u5230\u4e86\u5f88\u591a\u548c \u8bed\u8a00 \u76f8\u5173\u7684\u7406\u8bba \u9605\u8bfb \u300aNatural Language Processing with Python\u300b \u65f6\uff0c\u53d1\u73b0\u5176\u4e2d\u6d89\u53ca\u4e86\u4e00\u4e9b\u548c \u8bed\u8a00 \u76f8\u5173\u7684\u7406\u8bba \u9605\u8bfb \u300a Compilers: Principles, Techniques, and Tools \u300b \uff08\u9f99\u4e66\uff09\u65f6\uff0c\u53d1\u73b0\u5176\u4e2d\u6d89\u53ca\u4e86\u5f88\u591a formal language \u76f8\u5173\u7684\u7406\u8bba \u672c\u9879\u76ee\u7684\u5185\u5bb9\u5927\u591a\u6570\u6765\u81ea: \u7ef4\u57fa\u767e\u79d1: Automata theory : formal languages and formal grammars Introduction to Automata and Language Theory(aka Cinderella Book ) \u8fd9\u4e2a\u9879\u76ee\u662f\u5bf9 \u8bed\u8a00 \u76f8\u5173\u7684\u7406\u8bba\u7684\u4e00\u4e2a\u68b3\u7406\uff0c\u5b83\u4e3b\u8981\u4f5c\u4e3a\u5982\u4e0b\u9879\u76ee\u6240\u6d89\u53ca\u7684\u7406\u8bba\u7684\u603b\u7ed3\uff1a compiler-principle compiler-principle-in-action Natural-Language-Processing-with-Python","title":"\u524d\u8a00"},{"location":"#-","text":"Formal language \u6240\u6d89\u53ca\u7684\u7406\u8bba\u8f83\u591a\uff0c\u5e76\u4e14\u5927\u591a\u6570\u90fd\u662f\u6bd4\u8f83\u62bd\u8c61\u7684\uff0c\u521a\u5f00\u59cb\u5b66\u4e60\uff08\u5c24\u5176\u5bf9\u4e8e\u7f3a\u4e4f\u4f7f\u7528programming language\u7684\u4eba\u6765\u8bf4\uff09\u53ef\u80fd\u4f1a\u611f\u89c9\u6bd4\u8f83\u5403\u529b\uff0c\u4ee5\u4e0b\u662f\u89c9\u5f97\u6bd4\u8f83\u597d\u7684\u5b66\u4e60\u8ba1\u5212\uff1a \u9996\u5148\u641e\u6e05\u695awhat is language\u3001what is formal language\u3001what is formal grammar\u3001what is automata\u3001What is the relationship between them\uff0c\u8fd9\u6837\u5c31\u5efa\u7acb\u8d77\u4e86\u5efa\u7acb\u8d77\u9ad8\u5c4b\u5efa\u74f4\u7684\u89c6\u91ce\uff0c\u8fd9\u5176\u5b9e\u5c31\u662f\u7b97\u5165\u95e8\u4e86\u3002\u63a8\u8350\u9605\u8bfb\u4e0b\u9762\u7684\u6587\u7ae0\uff1a Formal Languages, Grammars, and Automata \u5165\u95e8\u4e86\u4e4b\u540e\uff0c\u5c31\u9700\u8981\u5efa\u7acb\u8d77theory framework\uff0c\u6700\u7ec8\u6211\u4eec\u4f1a\u53d1\u73b0\uff0c\u4f7f\u7528 Chomsky hierarchy \u5c31\u80fd\u591f\u5c06\u6574\u4e2a\u7406\u8bba\u7ed9\u7edf\u4e00\u8d77\u6765\uff1b\u7136\u540e\u518d\u9010\u4e2a\u8fdb\u884c\u7ec6\u81f4\u5206\u6790\uff0c\u6700\u540e\u5c31\u80fd\u591f\u878d\u4f1a\u8d2f\u901a\uff0c\u8fd9\u5176\u5b9e\u5c31\u662f\u7cbe\u901a\u4e86\u3002","title":"\u5b66\u4e60\u8ba1\u5212--\u4ece\u5165\u95e8\u5230\u7cbe\u901a"},{"location":"#theory-framework","text":"","title":"Theory Framework"},{"location":"#language","text":"\u5bf9\u8bed\u8a00\u7684\u4e00\u79cd\u5206\u7c7b\u65b9\u6cd5\uff1a Constructed language Formal language Programming language Natural languages Note: \u4e0a\u8bc9\u5206\u7c7b\u6240\u4f20\u8fbe\u7684\u542b\u4e49\u6709\uff1a Formal language \u4e0d\u662f natural language","title":"Language"},{"location":"#formal-language","text":"\u63d0\u53ca formal language \uff0c\u5c31\u5f97\u8bf7\u51fa Noam Chomsky \uff0c\u56e0\u4e3a\u4e0b\u9762\u7684\u7406\u8bba\u6846\u67b6\u662f\u7531\u4ed6\u6240\u5efa\u7acb\u7684\uff0c\u8be5theory framework\u7684\u662f\u6309\u7167 Chomsky hierarchy \u6765\u8fdb\u884c\u7ec4\u7ec7\u7684\uff1a Chomsky hierarchy Grammars Languages Abstract machines Type-0 Unrestricted Recursively enumerable Turing machine \u2014 (no common name) Decidable Decider Type-1 Context-sensitive Context-sensitive Linear-bounded \u2014 Positive range concatenation Positive range concatenation * PTIME Turing Machine \u2014 Indexed Indexed * Nested stack \u2014 \u2014 \u2014 Thread automaton \u2014 Linear context-free rewriting systems Linear context-free rewriting language restricted Tree stack automaton \u2014 Tree-adjoining Tree-adjoining Embedded pushdown Type-2 Context-free Context-free Nondeterministic pushdown \u2014 Deterministic context-free Deterministic context-free Deterministic pushdown \u2014 Visibly pushdown Visibly pushdown Visibly pushdown Type-3 Regular Regular Finite \u2014 \u2014 Star-free Counter-free (with aperiodic finite monoid) \u2014 Non-recursive Finite Acyclic finite Each category of languages, except those marked by a * , is a proper subset of the category directly above it. Any language in each category is generated by a grammar and by an automaton in the category in the same line.","title":"Formal language"},{"location":"#_2","text":"\u672c\u5de5\u7a0b\u5c31\u662f\u6309\u7167 \u5b66\u4e60\u8ba1\u5212--\u4ece\u5165\u95e8\u5230\u7cbe\u901a \u7ae0\u8282\u6240\u63cf\u8ff0\u7684\u601d\u8def\u7ec4\u7ec7\u7684\uff1a introduction\uff1a\u5165\u95e8 theory-framework\uff1a\u7406\u8bba\u6846\u67b6","title":"\u76ee\u5f55\u7ed3\u6784\u8bf4\u660e"},{"location":"Formal-Languages&Grammars&Automata-thinking/","text":"application of state machine [uses for state machines closed] The Rise Of The State Machines Understanding State Machines Finite-state machine regex engine and automata regex-directed engines vs Syntax-directed translation state machine vs automata application of state machine # [uses for state machines closed] # The Rise Of The State Machines # Understanding State Machines # Finite-state machine # regex engine and automata # https://www.regular-expressions.info/engine.html: While there are many implementations of regular expressions that differ sometimes slightly and sometimes significantly in syntax and behavior, there are basically only two kinds of regular expression engines: text-directed engines, and regex-directed engines. Nearly all modern regex flavors are based on regex-directed engines. This is because certain very useful features, such as lazy quantifiers and backreferences, can only be implemented in regex-directed engines. regex-directed engines vs Syntax-directed translation # state machine vs automata # state machine\u662f\u4e00\u79cdautomata","title":"Formal Languages&Grammars&Automata thinking"},{"location":"Formal-Languages&Grammars&Automata-thinking/#application-of-state-machine","text":"","title":"application of state machine"},{"location":"Formal-Languages&Grammars&Automata-thinking/#uses-for-state-machines-closed93","text":"","title":"[uses for state machines closed]"},{"location":"Formal-Languages&Grammars&Automata-thinking/#the-rise-of-the-state-machines","text":"","title":"The Rise Of The State Machines"},{"location":"Formal-Languages&Grammars&Automata-thinking/#understanding-state-machines","text":"","title":"Understanding State Machines"},{"location":"Formal-Languages&Grammars&Automata-thinking/#finite-state-machine","text":"","title":"Finite-state machine"},{"location":"Formal-Languages&Grammars&Automata-thinking/#regex-engine-and-automata","text":"https://www.regular-expressions.info/engine.html: While there are many implementations of regular expressions that differ sometimes slightly and sometimes significantly in syntax and behavior, there are basically only two kinds of regular expression engines: text-directed engines, and regex-directed engines. Nearly all modern regex flavors are based on regex-directed engines. This is because certain very useful features, such as lazy quantifiers and backreferences, can only be implemented in regex-directed engines.","title":"regex engine and automata"},{"location":"Formal-Languages&Grammars&Automata-thinking/#regex-directed-engines-vs-syntax-directed-translation","text":"","title":"regex-directed engines vs Syntax-directed translation"},{"location":"Formal-Languages&Grammars&Automata-thinking/#state-machine-vs-automata","text":"state machine\u662f\u4e00\u79cdautomata","title":"state machine vs automata"},{"location":"automata-software/","text":"python python-statemachine automata python automata-from-regex pywonderland cloujr automat java stateless4j C++ state How to Code a State Machine in C or C++ State Machine Design in C++ Expressive Code for State Machines in C++ C++ code for state machine RUST regex-automata python # python-statemachine # automata python # automata-from-regex # pywonderland # cloujr # automat # java # stateless4j # C++ # state # How to Code a State Machine in C or C++ # State Machine Design in C++ # Expressive Code for State Machines in C++ # C++ code for state machine # RUST # regex-automata #","title":"Automata software"},{"location":"automata-software/#python","text":"","title":"python"},{"location":"automata-software/#python-statemachine","text":"","title":"python-statemachine"},{"location":"automata-software/#automata-python","text":"","title":"automata python"},{"location":"automata-software/#automata-from-regex","text":"","title":"automata-from-regex"},{"location":"automata-software/#pywonderland","text":"","title":"pywonderland"},{"location":"automata-software/#cloujr","text":"","title":"cloujr"},{"location":"automata-software/#automat","text":"","title":"automat"},{"location":"automata-software/#java","text":"","title":"java"},{"location":"automata-software/#stateless4j","text":"","title":"stateless4j"},{"location":"automata-software/#c","text":"","title":"C++"},{"location":"automata-software/#state","text":"","title":"state"},{"location":"automata-software/#how-to-code-a-state-machine-in-c-or-c","text":"","title":"How to Code a State Machine in C or C++"},{"location":"automata-software/#state-machine-design-in-c","text":"","title":"State Machine Design in C++"},{"location":"automata-software/#expressive-code-for-state-machines-in-c","text":"","title":"Expressive Code for State Machines in C++"},{"location":"automata-software/#c-code-for-state-machine","text":"","title":"C++ code for state machine"},{"location":"automata-software/#rust","text":"","title":"RUST"},{"location":"automata-software/#regex-automata","text":"","title":"regex-automata"},{"location":"Introduction/","text":"introduction # \u5165\u95e8\u8bfb\u7269\u63a8\u8350\uff1a Formal Languages, Grammars, and Automata \u9664\u6b64\u4e4b\u5916\uff0c\u63a8\u8350\u9605\u8bfb\u5982\u4e0b\u5de8\u8457\uff1a Introduction to Automata and Language Theory(aka Cinderella Book )","title":"Introduction"},{"location":"Introduction/#introduction","text":"\u5165\u95e8\u8bfb\u7269\u63a8\u8350\uff1a Formal Languages, Grammars, and Automata \u9664\u6b64\u4e4b\u5916\uff0c\u63a8\u8350\u9605\u8bfb\u5982\u4e0b\u5de8\u8457\uff1a Introduction to Automata and Language Theory(aka Cinderella Book )","title":"introduction"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/","text":"Formal Languages, Grammars, and Automata Grammars and formal languages Chomsky Example Computer science and formal languages Computer science Compilers Automata and formal languages Turing, Kleene, ... Automata and grammars Which class of formal languages is recognized by a given type of automata? Describing formal languages: generative approach Generative approach Generation process Pros and Cons Describing formal languages: recognition approach Recognition approach Recognition process Pros and Cons Formal languages: definition and basic notions Grammar: informal view Formal Languages, Grammars, and Automata # Grammars and formal languages # Chomsky # Noam Chomsky (1928) is an American linguist, philosopher, cognitive scientist, historian, and activist. In Syntactic Structures (1957) , Chomsky models knowledge of language using a formal grammar , by claiming that formal grammars can explain the ability of a hearer/speaker to produce and interpret an infinite\uff08\u65e0\u9650\u7684\uff09 number of sentences with a limited set of grammatical rules and a finite set of terms. The human brain contains a limited set of rules for organizing language, known as Universal Grammar . The basic rules of grammar are hard-wired into the brain, and manifest themselves without being taught. The basic postulate of UG is that a certain set of structural rules are innate \uff08\u5148\u5929\u7684\uff09 to humans, independent of sensory experience . Chomsky proposed a hierarchy that partitions formal grammars into classes with increasing expressive power, i.e. each successive class can generate a broader set of formal languages than the one before. Interestingly, modeling some aspects of human language requires a more complex formal grammar (as measured by the Chomsky hierarchy) than modeling others. Example # While a regular language is powerful enough to model English morphology\uff08\u8bcd\u6cd5\uff09 (symbols, words), it is not powerful enough to model English syntax. Computer science and formal languages # Two application settings: Formal languages are studied in linguistics and computer science. Computer science # In computer science , formal languages are used for the precise definition of programming languages and, therefore, in the development of compilers. A compiler is a computer program (or set of programs) that transforms source code written in a programming language (the source language) into another computer language (the target language) $^a$ . $^a$ The most common reason for transforming source code is to create an executable program. Computer scientists privilege a recognition approach based on abstract machines ( automata ) that take in input a sentence and decide whether it belongs to the reference language. \u8ba1\u7b97\u673a\u79d1\u5b66\u5bb6\u4f7f\u7528\u4e00\u79cd\u57fa\u4e8e\u62bd\u8c61\u673a\u5668(automata)\u7684\u8bc6\u522b\u65b9\u6cd5\uff0c\u8fd9\u79cd\u673a\u5668\u63a5\u6536\u8f93\u5165\u7684\u53e5\u5b50\uff0c\u7136\u540e\u5224\u65ad\u5b83\u662f\u5426\u5c5e\u4e8e\u53c2\u8003\u8bed\u8a00\u3002 Compilers # Introduction to compiling Summary of compilation phases Automata and formal languages # Turing, Kleene, ... # Stephen Kleene introduced finite automata in the 50s: abstract state machines equipped with a finite memory. He demonstrated the equivalence between such a model and the description of sequences of symbols using only three logical primitives (set union, set product, and iteration). Alan Turing (and, independently, Emil Post and John Backus) put the ideas underlying the notion of pushdown automata : abstract state machines with an unbounded memory that is accessible only through a restricted mode (called a stack). \u827e\u4f26\u00b7\u56fe\u7075(\u4ee5\u53ca\u72ec\u7acb\u7684\u57c3\u7c73\u5c14\u00b7\u6ce2\u65af\u7279\u548c\u7ea6\u7ff0\u00b7\u5df4\u514b\u65af)\u63d0\u51fa\u4e86\u4e0b\u63a8\u81ea\u52a8\u673a\u6982\u5ff5\u7684\u57fa\u672c\u601d\u60f3:\u5177\u6709\u65e0\u9650\u5185\u5b58\u7684\u62bd\u8c61\u72b6\u6001\u673a\uff0c\u53ea\u80fd\u901a\u8fc7\u53d7\u9650\u6a21\u5f0f(\u79f0\u4e3a\u5806\u6808)\u8bbf\u95ee\u3002 In 1936, Alan Turing described the Turing Machine: an abstract state machine equipped with an infinite memory in the form of a strip of tape. Turing machines simulate the logic of any computer algorithm and recognize the larger class of formal languages . Automata and grammars # Which class of formal languages is recognized by a given type of automata? # There is an equivalence between the Chomsky hierarchy and the different kinds of automata. Thus, theorems about formal languages can be dealt with as either grammars or automata. Formal languages theory: generative approach recognition approach Grammars classification Automata theory Describing formal languages: generative approach # Generative approach # A language is the set of strings generated by a grammar . Generation process # Start symbol Expand with rewrite rules. Stop when a word of the language is generated. Pros and Cons # The generative approach is appealing to humans. Grammars are formal, informative, compact, finite descriptions for possibly infinite languages, but are clearly inefficient if implemented naively. Describing formal languages: recognition approach # Recognition approach # A language is the set of strings accepted by an automaton . Recognition process # Start in initial state. Transitions to other states guided by the string symbols. Until read whole string and reach accept/reject state. Pros and Cons # The recognition approach is appealing to machines. Automata are formal, compact, low-level machines that can be implemented easily and efficiently, but can be hard to understand to humans. Formal languages: definition and basic notions # Formal language :Is a set of words, that is, finite strings of symbols taken from the alphabet over which the language is defined. Alphabet : a finite, non-empty set of symbols. Example: \u03a3 1 = {0,1} \u03a3 2 = {0,1,2,3,4,5,6,7,8,9} \u03a3 3 = {0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F } \u03a3 4 = {a,b,c,...,z } Grammar: informal view #","title":"uniurb Formal Languages Grammars and Automata"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#formal-languages-grammars-and-automata","text":"","title":"Formal Languages, Grammars, and Automata"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#grammars-and-formal-languages","text":"","title":"Grammars and formal languages"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#chomsky","text":"Noam Chomsky (1928) is an American linguist, philosopher, cognitive scientist, historian, and activist. In Syntactic Structures (1957) , Chomsky models knowledge of language using a formal grammar , by claiming that formal grammars can explain the ability of a hearer/speaker to produce and interpret an infinite\uff08\u65e0\u9650\u7684\uff09 number of sentences with a limited set of grammatical rules and a finite set of terms. The human brain contains a limited set of rules for organizing language, known as Universal Grammar . The basic rules of grammar are hard-wired into the brain, and manifest themselves without being taught. The basic postulate of UG is that a certain set of structural rules are innate \uff08\u5148\u5929\u7684\uff09 to humans, independent of sensory experience . Chomsky proposed a hierarchy that partitions formal grammars into classes with increasing expressive power, i.e. each successive class can generate a broader set of formal languages than the one before. Interestingly, modeling some aspects of human language requires a more complex formal grammar (as measured by the Chomsky hierarchy) than modeling others.","title":"Chomsky"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#example","text":"While a regular language is powerful enough to model English morphology\uff08\u8bcd\u6cd5\uff09 (symbols, words), it is not powerful enough to model English syntax.","title":"Example"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#computer-science-and-formal-languages","text":"Two application settings: Formal languages are studied in linguistics and computer science.","title":"Computer science and formal languages"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#computer-science","text":"In computer science , formal languages are used for the precise definition of programming languages and, therefore, in the development of compilers. A compiler is a computer program (or set of programs) that transforms source code written in a programming language (the source language) into another computer language (the target language) $^a$ . $^a$ The most common reason for transforming source code is to create an executable program. Computer scientists privilege a recognition approach based on abstract machines ( automata ) that take in input a sentence and decide whether it belongs to the reference language. \u8ba1\u7b97\u673a\u79d1\u5b66\u5bb6\u4f7f\u7528\u4e00\u79cd\u57fa\u4e8e\u62bd\u8c61\u673a\u5668(automata)\u7684\u8bc6\u522b\u65b9\u6cd5\uff0c\u8fd9\u79cd\u673a\u5668\u63a5\u6536\u8f93\u5165\u7684\u53e5\u5b50\uff0c\u7136\u540e\u5224\u65ad\u5b83\u662f\u5426\u5c5e\u4e8e\u53c2\u8003\u8bed\u8a00\u3002","title":"Computer science"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#compilers","text":"Introduction to compiling Summary of compilation phases","title":"Compilers"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#automata-and-formal-languages","text":"","title":"Automata and formal languages"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#turing-kleene","text":"Stephen Kleene introduced finite automata in the 50s: abstract state machines equipped with a finite memory. He demonstrated the equivalence between such a model and the description of sequences of symbols using only three logical primitives (set union, set product, and iteration). Alan Turing (and, independently, Emil Post and John Backus) put the ideas underlying the notion of pushdown automata : abstract state machines with an unbounded memory that is accessible only through a restricted mode (called a stack). \u827e\u4f26\u00b7\u56fe\u7075(\u4ee5\u53ca\u72ec\u7acb\u7684\u57c3\u7c73\u5c14\u00b7\u6ce2\u65af\u7279\u548c\u7ea6\u7ff0\u00b7\u5df4\u514b\u65af)\u63d0\u51fa\u4e86\u4e0b\u63a8\u81ea\u52a8\u673a\u6982\u5ff5\u7684\u57fa\u672c\u601d\u60f3:\u5177\u6709\u65e0\u9650\u5185\u5b58\u7684\u62bd\u8c61\u72b6\u6001\u673a\uff0c\u53ea\u80fd\u901a\u8fc7\u53d7\u9650\u6a21\u5f0f(\u79f0\u4e3a\u5806\u6808)\u8bbf\u95ee\u3002 In 1936, Alan Turing described the Turing Machine: an abstract state machine equipped with an infinite memory in the form of a strip of tape. Turing machines simulate the logic of any computer algorithm and recognize the larger class of formal languages .","title":"Turing, Kleene, ..."},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#automata-and-grammars","text":"","title":"Automata and grammars"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#which-class-of-formal-languages-is-recognized-by-a-given-type-of-automata","text":"There is an equivalence between the Chomsky hierarchy and the different kinds of automata. Thus, theorems about formal languages can be dealt with as either grammars or automata. Formal languages theory: generative approach recognition approach Grammars classification Automata theory","title":"Which class of formal languages is recognized by a given type of automata?"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#describing-formal-languages-generative-approach","text":"","title":"Describing formal languages: generative approach"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#generative-approach","text":"A language is the set of strings generated by a grammar .","title":"Generative approach"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#generation-process","text":"Start symbol Expand with rewrite rules. Stop when a word of the language is generated.","title":"Generation process"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#pros-and-cons","text":"The generative approach is appealing to humans. Grammars are formal, informative, compact, finite descriptions for possibly infinite languages, but are clearly inefficient if implemented naively.","title":"Pros and Cons"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#describing-formal-languages-recognition-approach","text":"","title":"Describing formal languages: recognition approach"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#recognition-approach","text":"A language is the set of strings accepted by an automaton .","title":"Recognition approach"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#recognition-process","text":"Start in initial state. Transitions to other states guided by the string symbols. Until read whole string and reach accept/reject state.","title":"Recognition process"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#pros-and-cons_1","text":"The recognition approach is appealing to machines. Automata are formal, compact, low-level machines that can be implemented easily and efficiently, but can be hard to understand to humans.","title":"Pros and Cons"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#formal-languages-definition-and-basic-notions","text":"Formal language :Is a set of words, that is, finite strings of symbols taken from the alphabet over which the language is defined. Alphabet : a finite, non-empty set of symbols. Example: \u03a3 1 = {0,1} \u03a3 2 = {0,1,2,3,4,5,6,7,8,9} \u03a3 3 = {0,1,2,3,4,5,6,7,8,9,A,B,C,D,E,F } \u03a3 4 = {a,b,c,...,z }","title":"Formal languages: definition and basic notions"},{"location":"Introduction/uniurb-Formal-Languages-Grammars-and-Automata/#grammar-informal-view","text":"","title":"Grammar: informal view"},{"location":"Theory-framework/","text":"\u524d\u8a00 # \u9996\u5148\u8bf4\u660eformal language\uff0cformal grammar\uff0cautomata\uff0cChomsky hierarchy\u7b49\u57fa\u672c\u6982\u5ff5\uff0c\u5efa\u7acb\u7406\u8bba\u6846\u67b6\u3002 \u7136\u540e\u6309\u7167Chomsky hierarchy\u7684\u6bcf\u4e00\u5c42\u8fdb\u884c\u8bf4\u660e\uff0c\u5bf9Chomsky hierarchy\u7684\u6bcf\u4e00\u5c42\u7684\u8bf4\u660e\u91c7\u7528\u5982\u4e0b\u987a\u5e8f\uff0c\u5373\uff1a Type-3 grammars: Regular grammar Type-2 grammars: Context-free grammar Type-1 grammars: Context-sensitive grammar Type-0 grammars: Unrestricted grammar \u8fd9\u662f\u56e0\u4e3a\u4eceType-3 grammars\u5230Type-0 grammars\uff0cgrammar\u8d8a\u6765\u8d8a\u62bd\u8c61\uff0c\u8d8a\u6765\u8d8a\u96be\u7406\u89e3\uff0c\u8fd9\u6837\u7531\u6613\u5230\u96be\u4f1a\u6bd4\u8f83\u7b26\u5408\u8ba4\u77e5\u89c4\u5f8b\u3002 \u5728\u4e86\u89e3\u4e86\u8fd9\u4e9b\u4e4b\u540e\uff0c\u6211\u4eec\u4e0d\u80fd\u591f\u4ec5\u4ec5\u5c40\u9650\u4e8e\u6b64\uff0c\u800c\u662f\u5e94\u8be5\u8d70\u5411\u66f4\u52a0\u5bbd\u5e7f\u7684\u7406\u8bba\uff1a Theory of computation \uff0c\u56e0\u4e3a\u6309\u71672012 ACM Computing Classification System \uff0c\u524d\u9762\u6240\u8ba8\u8bba\u7684 formal language \uff0c automata theory \u90fd\u5c5e\u4e8e\u6b64\u8303\u8f74\u3002","title":"Introduction"},{"location":"Theory-framework/#_1","text":"\u9996\u5148\u8bf4\u660eformal language\uff0cformal grammar\uff0cautomata\uff0cChomsky hierarchy\u7b49\u57fa\u672c\u6982\u5ff5\uff0c\u5efa\u7acb\u7406\u8bba\u6846\u67b6\u3002 \u7136\u540e\u6309\u7167Chomsky hierarchy\u7684\u6bcf\u4e00\u5c42\u8fdb\u884c\u8bf4\u660e\uff0c\u5bf9Chomsky hierarchy\u7684\u6bcf\u4e00\u5c42\u7684\u8bf4\u660e\u91c7\u7528\u5982\u4e0b\u987a\u5e8f\uff0c\u5373\uff1a Type-3 grammars: Regular grammar Type-2 grammars: Context-free grammar Type-1 grammars: Context-sensitive grammar Type-0 grammars: Unrestricted grammar \u8fd9\u662f\u56e0\u4e3a\u4eceType-3 grammars\u5230Type-0 grammars\uff0cgrammar\u8d8a\u6765\u8d8a\u62bd\u8c61\uff0c\u8d8a\u6765\u8d8a\u96be\u7406\u89e3\uff0c\u8fd9\u6837\u7531\u6613\u5230\u96be\u4f1a\u6bd4\u8f83\u7b26\u5408\u8ba4\u77e5\u89c4\u5f8b\u3002 \u5728\u4e86\u89e3\u4e86\u8fd9\u4e9b\u4e4b\u540e\uff0c\u6211\u4eec\u4e0d\u80fd\u591f\u4ec5\u4ec5\u5c40\u9650\u4e8e\u6b64\uff0c\u800c\u662f\u5e94\u8be5\u8d70\u5411\u66f4\u52a0\u5bbd\u5e7f\u7684\u7406\u8bba\uff1a Theory of computation \uff0c\u56e0\u4e3a\u6309\u71672012 ACM Computing Classification System \uff0c\u524d\u9762\u6240\u8ba8\u8bba\u7684 formal language \uff0c automata theory \u90fd\u5c5e\u4e8e\u6b64\u8303\u8f74\u3002","title":"\u524d\u8a00"},{"location":"Theory-framework/Formal-language/","text":"\u524d\u8a00 # \u672c\u7ae0\u8282\uff0c\u9996\u5148\u4ee5 description-and-language \u8fd9\u7bc7\u6587\u7ae0\u4f5c\u4e3a\u5f00\u5934\uff0c\u5f15\u51fa Formal language \uff0c \u7136\u540e\u5bf9\u5b83\u8fdb\u884c\u8be6\u7ec6\u7684\u5206\u6790\u3002\u7ef4\u57fa\u767e\u79d1\u7684 Formal language \u5185\u5bb9\u662f\u975e\u5e38\u597d\u7684\uff08\u5168\u9762\uff0c\u6df1\u5165\u6d45\u51fa\uff09\uff0c\u9700\u8981\u4ed4\u7ec6\u9605\u8bfb\u3002 \u7406\u8bba\u5f80\u5f80\u4e0d\u662f\u5b64\u7acb\u7684\uff0c\u800c\u662f\u76f8\u4e92\u5173\u8054\uff0c\u76f8\u4e92\u501f\u7528\u7684\uff0c\u76f8\u4e92\u542f\u53d1\u7684\uff0c\u5728\u9605\u8bfb Formal language \u65f6\uff0c\u4f60\u4f1a\u53d1\u73b0\u4f5c\u8005\u5bf9\u5b83\u8fdb\u884c\u4e86\u5927\u91cf\u7684\u53d1\u6563\uff0c\u6d89\u53ca\u5230\u7684\u5b66\u79d1\u6709 mathematics \uff08\u5c24\u5176\u662f Mathematical logic \uff09, computer science , and linguistics \u3002\u6240\u4ee5\uff0c\u5728\u9605\u8bfb\u7684\u65f6\u5019\uff0c\u5c31\u6709\u5fc5\u8981\u68b3\u7406\u6e05\u695a\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6293\u4f4f\u95ee\u9898\u7684\u672c\u8d28\uff0c\u800c\u4e0d\u662f\u88ab\u8868\u9762\u7684\u63cf\u8ff0\u8bc6\u6240\u6270\u4e71\u3002","title":"Introduction"},{"location":"Theory-framework/Formal-language/#_1","text":"\u672c\u7ae0\u8282\uff0c\u9996\u5148\u4ee5 description-and-language \u8fd9\u7bc7\u6587\u7ae0\u4f5c\u4e3a\u5f00\u5934\uff0c\u5f15\u51fa Formal language \uff0c \u7136\u540e\u5bf9\u5b83\u8fdb\u884c\u8be6\u7ec6\u7684\u5206\u6790\u3002\u7ef4\u57fa\u767e\u79d1\u7684 Formal language \u5185\u5bb9\u662f\u975e\u5e38\u597d\u7684\uff08\u5168\u9762\uff0c\u6df1\u5165\u6d45\u51fa\uff09\uff0c\u9700\u8981\u4ed4\u7ec6\u9605\u8bfb\u3002 \u7406\u8bba\u5f80\u5f80\u4e0d\u662f\u5b64\u7acb\u7684\uff0c\u800c\u662f\u76f8\u4e92\u5173\u8054\uff0c\u76f8\u4e92\u501f\u7528\u7684\uff0c\u76f8\u4e92\u542f\u53d1\u7684\uff0c\u5728\u9605\u8bfb Formal language \u65f6\uff0c\u4f60\u4f1a\u53d1\u73b0\u4f5c\u8005\u5bf9\u5b83\u8fdb\u884c\u4e86\u5927\u91cf\u7684\u53d1\u6563\uff0c\u6d89\u53ca\u5230\u7684\u5b66\u79d1\u6709 mathematics \uff08\u5c24\u5176\u662f Mathematical logic \uff09, computer science , and linguistics \u3002\u6240\u4ee5\uff0c\u5728\u9605\u8bfb\u7684\u65f6\u5019\uff0c\u5c31\u6709\u5fc5\u8981\u68b3\u7406\u6e05\u695a\u6982\u5ff5\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u6293\u4f4f\u95ee\u9898\u7684\u672c\u8d28\uff0c\u800c\u4e0d\u662f\u88ab\u8868\u9762\u7684\u63cf\u8ff0\u8bc6\u6240\u6270\u4e71\u3002","title":"\u524d\u8a00"},{"location":"Theory-framework/Formal-language/Description-and-language/","text":"\u5982\u4f55\u6765\u8fdb\u884c\u63cf\u8ff0\uff1f # \u5404\u79cd\u5b66\u79d1\uff0c\u5728\u8fdb\u884c\u7814\u7a76\u7684\u65f6\u5019\uff0c\u5f80\u5f80\u662f\u4f7f\u7528\u7b80\u6d01\u7684\u516c\u5f0f/\u8868\u8fbe\u5f0f\u6765 \u63cf\u8ff0 / \u8868\u793a \u590d\u6742\u7684\u95ee\u9898\uff0c\u4ee5\u8fbe\u5230\u7b80\u5316\u7684\u76ee\u7684\u3002\u5176\u5b9e\u662f\u4e00\u79cd \u62bd\u8c61 \uff0c\u62bd\u8c61\u7684\u8fc7\u7a0b\u5bf9\u4e8e\u4efb\u4f55\u5b66\u79d1\u90fd\u662f\u81f3\u5173\u91cd\u8981\u7684\uff0c\u56e0\u4e3a\u62bd\u8c61\u7684\u8fc7\u7a0b\u662f\u5bf9\u672c\u8d28\u7684\u9760\u8fd1\u7684\u8fc7\u7a0b\u3002 \u4e0b\u9762\u603b\u7ed3\u4e86\u5728\u5404\u4e2a\u5b66\u79d1\u4e2d\u90fd\u975e\u5e38\u5e38\u89c1\u7684\u63cf\u8ff0/\u8868\u793a\u65b9\u5f0f\uff1a \u6570\u5b66\u4e2d\u7684\u63cf\u8ff0\u65b9\u5f0f # Expression (mathematics) # \u8868\u793a\u8ba1\u7b97\uff0chuman-readable\u3001machine-readable \u8bed\u8a00\u5b66\u4e2d\u7684\u63cf\u8ff0\u65b9\u5f0f # \u5728\u8bed\u8a00\u5b66\u4e2d\uff0c grammar \u6765\u63cf\u8ff0\u8bed\u8a00\u7684\u7ed3\u6784\uff0c formal language \u7684grammar\u662f formal grammar \uff0c\u6bd4\u5982 context free grammar \u3002 Production (computer science) \u5e38\u5e38\u7528\u6765\u8868\u793a context free grammar \u3002 \u8ba1\u7b97\u673a\u79d1\u5b66 # \u0441omputer language # programming language # \u8868\u793a\u7b97\u6cd5\uff0chuman-readable\u3001machine-readable Specification language # Interface description language # human-readable\u3001machine-readable Markup language # human-readable\u3001machine-readable YAML Data modeling languages # \u63cf\u8ff0\u7ed3\u6784 # ADSL # \u5728\u8bba\u6587 The Zephyr Abstract Syntax Description Language \u4e2d\u6709\u8fd9\u6837\u7684\u603b\u7ed3\uff1a Regular expressions describe lexical structures of programming languages. Context free grammars describe syntactic structures of programming languages . ASDL describes the abstract syntax of compiler intermediate representations (IRs) and other tree-like data structures. Algebraic data types # see also # \u5728\u6211\u7684\u5de5\u7a0b data-structure \u7ed9\u51fa\u4e86\u5404\u79cd\u6570\u636e\u7ed3\u6784\u7684\u63cf\u8ff0\u65b9\u5f0f\uff0c\u4e0b\u9762\u7ed9\u51fa\u94fe\u63a5\uff1a - https://github.com/dengking/data-structure/blob/master/docs/tree/representing-trees.md # compiler\u4e2d\u7684\u63cf\u8ff0 # \u5728compiler\u4e2d\u4f7f\u7528\u4e86\u591a\u79cd Intermediate representation \uff0c\u8fd9\u4e9bIR\u90fd\u662f\u5bf9source code\u7684\u4e0d\u540c\u7684\u8868\u793a/\u63cf\u8ff0\u3002 see also\uff1a dragon book human-readable and machine-readable # \u4e0b\u9762\u8fd9\u6bb5\u662f\u6211\u5728\u9605\u8bfb The Python Language Specification \u65f6\u9047\u5230\u7684\uff1a Contained within the CPython source code is the definition of the Python language. This is the reference specification used by all the Python interpreters. The specification is in both human-readable and machine-readable format. Inside the documentation is a detailed explanation of the Python language, what is allowed, and how each statement should behave. \u5b83\u5bf9\u6211\u7684\u542f\u53d1\u662f\uff1a \u4e0d\u540c\u7684\u63cf\u8ff0\u6709\u5176\u76f8\u5e94\u7684\u7684\u4f18\u52bf \u5728\u5de5\u7a0b\u4e2d\uff0c\u6211\u4eec\u5f80\u5f80\u9700\u8981\u5c06\u4e00\u79cd\u63cf\u8ff0\u65b9\u5f0f\u8f6c\u6362\u4e3a\u53e6\u5916\u4e00\u79cd\u63cf\u8ff0\u65b9\u5f0f \u6240\u6709\u7684\u63cf\u8ff0\u90fd\u662f\u8bed\u8a00\uff1f # \u53ef\u4ee5\u8ba4\u4e3a\u63cf\u8ff0\u7684\u672c\u8d28\u662f \u8bed\u8a00 \u3002\u79d1\u5b66\u9700\u8981\u4e25\u8c28\u7684\u3001\u51c6\u786e\u7684\u63cf\u8ff0\u65b9\u5f0f\uff0c\u6240\u4ee5\u5b83\u4f7f\u7528\u7684\u8bed\u8a00\u9700\u8981\u4e0d\u540c\u4e8e\u4eba\u7c7b\u8bf4\u8bdd\u65f6\u4f7f\u7528\u7684 \u81ea\u7136\u8bed\u8a00 \uff0c\u5728\u79d1\u5b66\u4e2d\uff0c\u5f80\u5f80\u4f7f\u7528\u7684\u4e00\u79cd\u53eb\u505a formal language \u7684\u8bed\u8a00\uff0c\u8fd9\u7c7b\u8bed\u8a00\u6709\u7740\u8bf8\u591a\u4f18\u826f\u7684\u7279\u6027\uff0c\u5b83\u662f\u5f88\u591a\u5b66\u79d1\u7684\u57fa\u7840\u3002 \u672c\u7ae0\u6240\u8981\u7814\u7a76\u7684\u5c31\u662f formal language \u3002 \u63cf\u8ff0\u62bd\u8c61\u7ed3\u6784 # ASDL # cpython \u4f7f\u7528ASDL\u6765\u63cf\u8ff0\u81ea\u5df1\u7684AST https://www.usenix.org/legacy/publications/library/proceedings/dsl97/full_papers/wang/wang.pdf http://www.oilshell.org/blog/2016/12/11.html https://stackoverflow.com/questions/8873126/zephyr-asdl-abstract-syntax-description-language https://devguide.python.org/compiler/ https://github.com/python/cpython/blob/master/Parser/Python.asdl http://asdl.sourceforge.net/ https://www.cs.princeton.edu/research/techreps/TR-554-97 \u663e\u7136\uff0c\u5b83\u4e5f\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u6811\u63cf\u8ff0\u8bed\u8a00\u3002 https://en.wikipedia.org/wiki/Algebraic_data_type https://en.wikipedia.org/wiki/Abstract_syntax \u63cf\u8ff0\u7684\u9012\u5f52\u6027 # \u50cfCFG\u5c31\u5177\u5907\u9012\u5f52\u6027\uff0c\u6709 recursive grammar \u7684\u6982\u5ff5\u3002\u5173\u4e8e\u63cf\u8ff0\u7684\u9012\u5f52\u6027\u5728 Production(computer-science) \u3001 Chomsky-hierarchy \u4e2d\u6709\u4e13\u95e8\u7684\u63cf\u8ff0\u3002","title":"Description-and-language"},{"location":"Theory-framework/Formal-language/Description-and-language/#_1","text":"\u5404\u79cd\u5b66\u79d1\uff0c\u5728\u8fdb\u884c\u7814\u7a76\u7684\u65f6\u5019\uff0c\u5f80\u5f80\u662f\u4f7f\u7528\u7b80\u6d01\u7684\u516c\u5f0f/\u8868\u8fbe\u5f0f\u6765 \u63cf\u8ff0 / \u8868\u793a \u590d\u6742\u7684\u95ee\u9898\uff0c\u4ee5\u8fbe\u5230\u7b80\u5316\u7684\u76ee\u7684\u3002\u5176\u5b9e\u662f\u4e00\u79cd \u62bd\u8c61 \uff0c\u62bd\u8c61\u7684\u8fc7\u7a0b\u5bf9\u4e8e\u4efb\u4f55\u5b66\u79d1\u90fd\u662f\u81f3\u5173\u91cd\u8981\u7684\uff0c\u56e0\u4e3a\u62bd\u8c61\u7684\u8fc7\u7a0b\u662f\u5bf9\u672c\u8d28\u7684\u9760\u8fd1\u7684\u8fc7\u7a0b\u3002 \u4e0b\u9762\u603b\u7ed3\u4e86\u5728\u5404\u4e2a\u5b66\u79d1\u4e2d\u90fd\u975e\u5e38\u5e38\u89c1\u7684\u63cf\u8ff0/\u8868\u793a\u65b9\u5f0f\uff1a","title":"\u5982\u4f55\u6765\u8fdb\u884c\u63cf\u8ff0\uff1f"},{"location":"Theory-framework/Formal-language/Description-and-language/#_2","text":"","title":"\u6570\u5b66\u4e2d\u7684\u63cf\u8ff0\u65b9\u5f0f"},{"location":"Theory-framework/Formal-language/Description-and-language/#expression-mathematics","text":"\u8868\u793a\u8ba1\u7b97\uff0chuman-readable\u3001machine-readable","title":"Expression (mathematics)"},{"location":"Theory-framework/Formal-language/Description-and-language/#_3","text":"\u5728\u8bed\u8a00\u5b66\u4e2d\uff0c grammar \u6765\u63cf\u8ff0\u8bed\u8a00\u7684\u7ed3\u6784\uff0c formal language \u7684grammar\u662f formal grammar \uff0c\u6bd4\u5982 context free grammar \u3002 Production (computer science) \u5e38\u5e38\u7528\u6765\u8868\u793a context free grammar \u3002","title":"\u8bed\u8a00\u5b66\u4e2d\u7684\u63cf\u8ff0\u65b9\u5f0f"},{"location":"Theory-framework/Formal-language/Description-and-language/#_4","text":"","title":"\u8ba1\u7b97\u673a\u79d1\u5b66"},{"location":"Theory-framework/Formal-language/Description-and-language/#omputer-language","text":"","title":"\u0441omputer language"},{"location":"Theory-framework/Formal-language/Description-and-language/#programming-language","text":"\u8868\u793a\u7b97\u6cd5\uff0chuman-readable\u3001machine-readable","title":"programming language"},{"location":"Theory-framework/Formal-language/Description-and-language/#specification-language","text":"","title":"Specification language"},{"location":"Theory-framework/Formal-language/Description-and-language/#interface-description-language","text":"human-readable\u3001machine-readable","title":"Interface description language"},{"location":"Theory-framework/Formal-language/Description-and-language/#markup-language","text":"human-readable\u3001machine-readable YAML","title":"Markup language"},{"location":"Theory-framework/Formal-language/Description-and-language/#data-modeling-languages","text":"","title":"Data modeling languages"},{"location":"Theory-framework/Formal-language/Description-and-language/#_5","text":"","title":"\u63cf\u8ff0\u7ed3\u6784"},{"location":"Theory-framework/Formal-language/Description-and-language/#adsl","text":"\u5728\u8bba\u6587 The Zephyr Abstract Syntax Description Language \u4e2d\u6709\u8fd9\u6837\u7684\u603b\u7ed3\uff1a Regular expressions describe lexical structures of programming languages. Context free grammars describe syntactic structures of programming languages . ASDL describes the abstract syntax of compiler intermediate representations (IRs) and other tree-like data structures.","title":"ADSL"},{"location":"Theory-framework/Formal-language/Description-and-language/#algebraic-data-types","text":"","title":"Algebraic data types"},{"location":"Theory-framework/Formal-language/Description-and-language/#see-also","text":"\u5728\u6211\u7684\u5de5\u7a0b data-structure \u7ed9\u51fa\u4e86\u5404\u79cd\u6570\u636e\u7ed3\u6784\u7684\u63cf\u8ff0\u65b9\u5f0f\uff0c\u4e0b\u9762\u7ed9\u51fa\u94fe\u63a5\uff1a","title":"see also"},{"location":"Theory-framework/Formal-language/Description-and-language/#-httpsgithubcomdengkingdata-structureblobmasterdocstreerepresenting-treesmd","text":"","title":"- https://github.com/dengking/data-structure/blob/master/docs/tree/representing-trees.md"},{"location":"Theory-framework/Formal-language/Description-and-language/#compiler","text":"\u5728compiler\u4e2d\u4f7f\u7528\u4e86\u591a\u79cd Intermediate representation \uff0c\u8fd9\u4e9bIR\u90fd\u662f\u5bf9source code\u7684\u4e0d\u540c\u7684\u8868\u793a/\u63cf\u8ff0\u3002 see also\uff1a dragon book","title":"compiler\u4e2d\u7684\u63cf\u8ff0"},{"location":"Theory-framework/Formal-language/Description-and-language/#human-readable-and-machine-readable","text":"\u4e0b\u9762\u8fd9\u6bb5\u662f\u6211\u5728\u9605\u8bfb The Python Language Specification \u65f6\u9047\u5230\u7684\uff1a Contained within the CPython source code is the definition of the Python language. This is the reference specification used by all the Python interpreters. The specification is in both human-readable and machine-readable format. Inside the documentation is a detailed explanation of the Python language, what is allowed, and how each statement should behave. \u5b83\u5bf9\u6211\u7684\u542f\u53d1\u662f\uff1a \u4e0d\u540c\u7684\u63cf\u8ff0\u6709\u5176\u76f8\u5e94\u7684\u7684\u4f18\u52bf \u5728\u5de5\u7a0b\u4e2d\uff0c\u6211\u4eec\u5f80\u5f80\u9700\u8981\u5c06\u4e00\u79cd\u63cf\u8ff0\u65b9\u5f0f\u8f6c\u6362\u4e3a\u53e6\u5916\u4e00\u79cd\u63cf\u8ff0\u65b9\u5f0f","title":"human-readable and machine-readable"},{"location":"Theory-framework/Formal-language/Description-and-language/#_6","text":"\u53ef\u4ee5\u8ba4\u4e3a\u63cf\u8ff0\u7684\u672c\u8d28\u662f \u8bed\u8a00 \u3002\u79d1\u5b66\u9700\u8981\u4e25\u8c28\u7684\u3001\u51c6\u786e\u7684\u63cf\u8ff0\u65b9\u5f0f\uff0c\u6240\u4ee5\u5b83\u4f7f\u7528\u7684\u8bed\u8a00\u9700\u8981\u4e0d\u540c\u4e8e\u4eba\u7c7b\u8bf4\u8bdd\u65f6\u4f7f\u7528\u7684 \u81ea\u7136\u8bed\u8a00 \uff0c\u5728\u79d1\u5b66\u4e2d\uff0c\u5f80\u5f80\u4f7f\u7528\u7684\u4e00\u79cd\u53eb\u505a formal language \u7684\u8bed\u8a00\uff0c\u8fd9\u7c7b\u8bed\u8a00\u6709\u7740\u8bf8\u591a\u4f18\u826f\u7684\u7279\u6027\uff0c\u5b83\u662f\u5f88\u591a\u5b66\u79d1\u7684\u57fa\u7840\u3002 \u672c\u7ae0\u6240\u8981\u7814\u7a76\u7684\u5c31\u662f formal language \u3002","title":"\u6240\u6709\u7684\u63cf\u8ff0\u90fd\u662f\u8bed\u8a00\uff1f"},{"location":"Theory-framework/Formal-language/Description-and-language/#_7","text":"","title":"\u63cf\u8ff0\u62bd\u8c61\u7ed3\u6784"},{"location":"Theory-framework/Formal-language/Description-and-language/#asdl","text":"cpython \u4f7f\u7528ASDL\u6765\u63cf\u8ff0\u81ea\u5df1\u7684AST https://www.usenix.org/legacy/publications/library/proceedings/dsl97/full_papers/wang/wang.pdf http://www.oilshell.org/blog/2016/12/11.html https://stackoverflow.com/questions/8873126/zephyr-asdl-abstract-syntax-description-language https://devguide.python.org/compiler/ https://github.com/python/cpython/blob/master/Parser/Python.asdl http://asdl.sourceforge.net/ https://www.cs.princeton.edu/research/techreps/TR-554-97 \u663e\u7136\uff0c\u5b83\u4e5f\u53ef\u4ee5\u4f5c\u4e3a\u4e00\u79cd\u6811\u63cf\u8ff0\u8bed\u8a00\u3002 https://en.wikipedia.org/wiki/Algebraic_data_type https://en.wikipedia.org/wiki/Abstract_syntax","title":"ASDL"},{"location":"Theory-framework/Formal-language/Description-and-language/#_8","text":"\u50cfCFG\u5c31\u5177\u5907\u9012\u5f52\u6027\uff0c\u6709 recursive grammar \u7684\u6982\u5ff5\u3002\u5173\u4e8e\u63cf\u8ff0\u7684\u9012\u5f52\u6027\u5728 Production(computer-science) \u3001 Chomsky-hierarchy \u4e2d\u6709\u4e13\u95e8\u7684\u63cf\u8ff0\u3002","title":"\u63cf\u8ff0\u7684\u9012\u5f52\u6027"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/","text":"Formal language Words over an alphabet Definition Constructions Language-specification formalisms Operations on languages Applications Programming languages Formal theories, systems, and proofs Interpretations and models \u68b3\u7406 Formal system and formal language \u4eceMathematical logic\u7684\u89d2\u5ea6\u6765\u770bFormal grammars Automata theory\u548cFormal language Turing machine and Mathematical logic Formal language # In mathematics , computer science , and linguistics , a formal language consists of words whose letters are taken from an alphabet and are well-formed according to a specific set of rules. The alphabet of a formal language consist of symbols, letters, or tokens that concatenate into strings of the language. Each string concatenated from symbols of this alphabet is called a word , and the words that belong to a particular formal language are sometimes called well-formed words or well-formed formulas . A formal language is often defined by means of a formal grammar such as a regular grammar or context-free grammar , which consists of its formation rules . The field of formal language theory studies primarily the purely syntactical \uff08\u8bed\u6cd5\uff09 aspects of such languages\u2014that is, their internal structural patterns . Formal language theory sprang out of linguistics, as a way of understanding the syntactic regularities\uff08\u89c4\u5f8b\uff09 of natural languages . In computer science, formal languages are used among others as the basis for defining the grammar of programming languages and formalized versions of subsets of natural languages in which the words of the language represent concepts that are associated with particular meanings or semantics \uff08\u8bed\u4e49\uff09. In computational complexity theory , decision problems are typically defined as formal languages , and complexity classes are defined as the sets of the formal languages that can be parsed by machines with limited computational power. In logic and the foundations of mathematics , formal languages are used to represent the syntax of axiomatic systems , and mathematical formalism is the philosophy that all of mathematics can be reduced to the syntactic manipulation of formal languages in this way. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u7b2c\u4e00\u53e5\u8bdd\u63ed\u793a\u4e86 formal language \u548c logic \u4e4b\u95f4\u7684\u5173\u7cfb\u3002 NOTE: \u6700\u540e\u4e00\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff1a mathematical formalism \u7684\u601d\u60f3\u662f\uff1a\u6240\u6709\u7684\u6570\u5b66\u90fd\u53ef\u4ee5\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u7b80\u5316\u4e3aformal language\u7684syntactic manipulation\u3002\u6d4f\u89c8\u4e86\u4e00\u4e0b\u8fd9\u7bc7\u6587\u7ae0\uff0c\u53d1\u73b0 theory of computation \u4e2d\u7684\u5f88\u591a\u8bfe\u9898\u90fd\u6e90\u4e8e\u8fd9\u4e2a\u601d\u60f3\uff0c\u6bd4\u5982 Turing machine \u3002 Words over an alphabet # An alphabet , in the context of formal languages, can be any set , although it often makes sense to use an alphabet in the usual sense of the word, or more generally a character set such as ASCII or Unicode . The elements of an alphabet are called its letters . An alphabet may contain an infinite number of elements; however, most definitions in formal language theory specify alphabets with a finite number of elements, and most results apply only to them. A word over an alphabet can be any finite sequence (i.e., string ) of letters. The set of all words over an alphabet \u03a3 is usually denoted by \u03a3 (using the Kleene star ). The length of a word is the number of letters it is composed of. For any alphabet, there is only one word of length 0, the empty word*, which is often denoted by e, \u03b5, \u03bb or even \u039b. By concatenation one can combine two words to form a new word, whose length is the sum of the lengths of the original words. The result of concatenating a word with the empty word is the original word. In some applications, especially in logic , the alphabet is also known as the vocabulary and words are known as formulas or sentences ; this breaks the letter/word metaphor and replaces it by a word/sentence metaphor. NOTE: \u5728formal language\u7406\u8bba\u4e2d\uff0c alphabet \u3001 character set \u3001vocabulary\u53ef\u4ee5\u8ba4\u4e3a\u662f\u540c\u4e49\u8bcd\u3002 Definition # A formal language L over an alphabet \u03a3 is a subset of \u03a3*, that is, a set of words over that alphabet. Sometimes the sets of words are grouped into expressions, whereas rules and constraints may be formulated for the creation of 'well-formed expressions'. NOTE: \u6240\u8c13\u7684rules\u5176\u5b9e\u5c31\u662fgrammar\u3002 In computer science and mathematics, which do not usually deal with natural languages , the adjective \"formal\" is often omitted as redundant. NOTE: \u6309\u7167\u8fd9\u4e2a\u8bf4\u6cd5\uff0cprogramming language\u7684\u66f4\u52a0\u4e25\u8c28\u7684\u8bf4\u6cd5\u662f\uff1aprogramming formal language\u3002 While formal language theory usually concerns itself with formal languages that are described by some syntactical rules, the actual definition of the concept \"formal language\" is only as above: a (possibly infinite) set of finite-length strings composed from a given alphabet, no more and no less. In practice, there are many languages that can be described by rules , such as regular languages or context-free languages . The notion of a formal grammar may be closer to the intuitive concept of a \"language,\" one described by syntactic rules. By an abuse of the definition, a particular formal language is often thought of as being equipped with a formal grammar that describes it. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u6240\u5f3a\u8c03\u7684\u662fformal language\u7684\u51c6\u786e\u5b9a\u4e49\u4e2d\u662f\u4e0d\u5305\u542brules\uff08grammar\uff09\u7684\u3002\u4f46\u662f\u5b9e\u9645\u4e2d\uff0c\u8981\u60f3\u51c6\u786e\u7684\u5b9a\u4e49\u4e00\u95e8\u8bed\u8a00\u662f\u79bb\u4e0d\u5f00rules\u7684\u3002\u4ee5programming language\u4e3a\u4f8b\u7684\u8bdd\uff0c\u5b83\u9700\u8981\u8bcd\u6cd5\u548c\u8bed\u6cd5\u624d\u80fd\u591f\u6b63\u786e\u5730\u63cf\u8ff0\u8be5\u8bed\u8a00\u3002 Constructions # For finite languages, one can explicitly enumerate all well-formed words. For example, we can describe a language L as just L = {a,\u2009b,\u2009ab,\u2009cba}. The degenerate case of this construction is the empty language , which contains no words at all ( L = \u2205 ). However, even over a finite (non-empty) alphabet such as \u03a3 = {a, b} there are an infinite number of finite-length words that can potentially be expressed: \"a\", \"abb\", \"ababba\", \"aaababbbbaab\", .... Therefore, formal languages are typically infinite, and describing an infinite formal language is not as simple as writing L = {a,\u2009b,\u2009ab,\u2009cba}. Here are some examples of formal languages: L = \u03a3 , the set of all* words over \u03a3; $L = {a}^ = {a^n}$, where n ranges over the natural numbers and \"$a^n$\" means \"a\" repeated n* times (this is the set of words consisting only of the symbol \"a\"); the set of syntactically correct programs in a given programming language (the syntax of which is usually defined by a context-free grammar ); the set of inputs upon which a certain Turing machine halts; or the set of maximal strings of alphanumeric ASCII characters on this line, i.e., the set {the, set, of, maximal, strings, alphanumeric, ASCII, characters, on, this, line, i, e}. Language-specification formalisms # Formal languages are used as tools in multiple disciplines. However, formal language theory rarely concerns itself with particular languages (except as examples), but is mainly concerned with the study of various types of formalisms to describe languages. For instance, a language can be given as those strings generated by some formal grammar ; those strings described or matched by a particular regular expression ; those strings accepted by some automaton , such as a Turing machine or finite-state automaton ; those strings for which some decision procedure (an algorithm that asks a sequence of related YES/NO questions) produces the answer YES. Typical questions asked about such formalisms include: What is their expressive power? (Can formalism X describe every language that formalism Y can describe? Can it describe other languages?) What is their recognizability? (How difficult is it to decide whether a given word belongs to a language described by formalism X ?) What is their comparability? (How difficult is it to decide whether two languages, one described in formalism X and one in formalism Y , or in X again, are actually the same language?). Surprisingly often, the answer to these decision problems is \"it cannot be done at all\", or \"it is extremely expensive\" (with a characterization of how expensive). Therefore, formal language theory is a major application area of computability theory and complexity theory . Formal languages may be classified in the Chomsky hierarchy based on the expressive power of their generative grammar as well as the complexity of their recognizing automaton . Context-free grammars and regular grammars provide a good compromise between expressivity and ease of parsing , and are widely used in practical applications. Operations on languages # Certain operations on languages are common. This includes the standard set operations, such as union, intersection, and complement. Another class of operation is the element-wise application of string operations. Examples: suppose $ L_{1} $ and $ L_{2} $ are languages over some common alphabet $ \\Sigma $. The concatenation $ L_{1}\\cdot L_{2} $ consists of all strings of the form $ vw $ where $ v $ is a string from $ L_{1} $ and $ w $ is a string from $ L_{2} $. The intersection $ L_{1}\\cap L_{2} $ of $ L_{1} $ and $ L_{2} $ consists of all strings that are contained in both languages The complement $ \\neg L_{1} $ of $ L_{1} $ with respect to $ \\Sigma $ consists of all strings over $ \\Sigma $ that are not in $ L_{1} $. The Kleene star : the language consisting of all words that are concatenations of zero or more words in the original language; Reversal: Let \u03b5 be the empty word, then $ \\varepsilon ^{R}=\\varepsilon $, and for each non-empty word $ w=\\sigma {1}\\cdots \\sigma {n} $ (where $ \\sigma {1},\\ldots ,\\sigma {n} $are elements of some alphabet), let $ w^{R}=\\sigma {n}\\cdots \\sigma {1} $, then for a formal language $ L $, $ L^{R}={w^{R}\\mid w\\in L} $. String homomorphism Such string operations are used to investigate closure properties of classes of languages. A class of languages is closed under a particular operation when the operation, applied to languages in the class, always produces a language in the same class again. For instance, the context-free languages are known to be closed under union, concatenation, and intersection with regular languages , but not closed under intersection or complement. The theory of trios and abstract families of languages studies the most common closure properties of language families in their own right. Applications # Programming languages # Main articles: Compiler compiler and Syntax (programming languages) Formal theories, systems, and proofs # Main articles: Theory (mathematical logic) and Formal system In mathematical logic , a formal theory is a set of sentences expressed in a formal language . A formal system (also called a logical calculus , or a logical system ) consists of a formal language together with a deductive apparatus (also called a deductive system ). The deductive apparatus may consist of a set of transformation rules , which may be interpreted as valid rules of inference, or a set of axioms , or have both. A formal system is used to derive one expression from one or more other expressions. Although a formal language can be identified with its formulas, a formal system cannot be likewise identified by its theorems. Two formal systems $ {\\mathcal {FS}} $ and $ {\\mathcal {FS'}} $ may have all the same theorems and yet differ in some significant proof-theoretic way (a formula A may be a syntactic consequence of a formula B in one but not another for instance). A formal proof or derivation is a finite sequence of well-formed formulas (which may be interpreted as sentences, or propositions ) each of which is an axiom or follows from the preceding formulas in the sequence by a rule of inference . The last sentence in the sequence is a theorem of a formal system. Formal proofs are useful because their theorems can be interpreted as true propositions. Interpretations and models # Main articles: Formal semantics (logic) , Interpretation (logic) and Model theory Formal languages are entirely syntactic in nature but may be given semantics that give meaning to the elements of the language. For instance, in mathematical logic , the set of possible formulas of a particular logic is a formal language, and an interpretation assigns a meaning to each of the formulas\u2014usually, a truth value . The study of interpretations of formal languages is called formal semantics . In mathematical logic, this is often done in terms of model theory . In model theory, the terms that occur in a formula are interpreted as objects within mathematical structures , and fixed compositional interpretation rules determine how the truth value of the formula can be derived from the interpretation of its terms; a model for a formula is an interpretation of terms such that the formula becomes true. This diagram shows the syntactic divisions within a formal system . Strings of symbols may be broadly divided into nonsense and well-formed formulas . The set of well-formed formulas is divided into theorems and non-theorems. \u68b3\u7406 # Formal system and formal language # \u4e0b\u9762\u8fd9\u6bb5\u6458\u81ea Formal systems A formal system (also called a logical calculus , or a logical system ) consists of a formal language together with a deductive apparatus (also called a deductive system ). The deductive apparatus may consist of a set of transformation rules (also called inference rules ) or a set of axioms , or have both. A formal system is used to derive (\u63a8\u5bfc) one expression from one or more other expressions. Propositional and predicate calculi are examples of formal systems. Formal grammars \u76f8\u5f53\u4e8e deductive apparatus \u3002 \u4ece Mathematical logic \u7684\u89d2\u5ea6\u6765\u770b Formal grammars # \u5982\u679c\u4ece Mathematical logic \u7684\u903b\u8f91\u63a8\u5bfc\u7684\u89d2\u5ea6\u6765\u770b\u5f85 Formal grammars \u7684\u8bdd\uff0c formal grammars \u7684\u5f88\u591a\u5185\u5bb9\u5c31\u53d8\u5f97\u975e\u5e38\u5bb9\u6613\u7406\u89e3\uff1a formal grammars \u672c\u8d28\u4e0a\u5c31\u662f \u63a8\u5bfc\u89c4\u5219 \u4e0b\u9762\u603b\u7ed3\u4e86formal grammar\u4e2d\u7684\u4e00\u4e9b\u6982\u5ff5\u548cmathematical logic\u4e2d\u7684\u4e00\u4e9b\u6982\u5ff5\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u5982\u4e0b\uff1a Formal grammar Mathematical logic Production rule Formation rule \u3001 Rule of inference \u3001 Rewriting \u4e0a\u8ff0\u5bf9\u5e94\u5173\u7cfb\u7684\u542b\u4e49\u662f\uff1a\u5982\u679c\u4ece Mathematical logic \u6765\u770b\u5f85 Production rule \u7684\u8bdd\uff0c\u5b83\u5c31\u76f8\u5f53\u4e8e\u662f Formation rule \u3001 Rule of inference \u3001 Rewriting \u3002 \u6309\u7167\u516c\u5f0f\u8fdb\u884c\u63a8\u5bfc\u4ece\u53e6\u5916\u4e00\u4e2a\u89d2\u5ea6\u6765\u770b\u5176\u5b9e\u662f\u91cd\u5199\uff0c\u4e0d\u65ad\u5730\u8fdb\u884c\u66ff\u6362\uff0c\u611f\u89c9\u6570\u7406\u903b\u8f91\u672c\u8d28\u4e0a\u5c31\u662f\u8fd9\u4e2a\u4e1c\u897f\u3002\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u770b\uff0cparsing\u7684\u8fc7\u7a0b\u5176\u5b9e\u5c31\u662f\u4e0d\u65ad\u7684\u63a8\u5bfc\u7684\u8fc7\u7a0b\uff0c\u4e0d\u65ad\u7684\u91cd\u5199\u7684\u8fc7\u7a0b\u3002\u7531\u4e8e\u53ef\u80fd\u7684\u63a8\u5bfc\u683c\u5f0f\u662f\u975e\u5e38\u591a\u7684\uff0c\u6240\u4ee5\u9700\u8981\u4e0d\u65ad\u5730\u8fdb\u884c\u5c1d\u8bd5\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u5176\u5b9e\u5c31\u662f search \u3001 backtracking \uff0c\u6240\u4ee5\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u770b\uff0c parsing \u6240\u505a\u7684\u5de5\u4f5c\u5176\u5b9e\u5c31\u662f\u63a8\u5bfc\u52a0search\u3002\u81ea\u9876\u5411\u4e0b\u5176\u5b9e\u6240\u5bf9\u5e94\u7684\u662f\u6b63\u5411\u63a8\u5bfc\uff0c\u81ea\u5e95\u5411\u4e0a\u5176\u5b9e\u6240\u5bf9\u5e94\u7684\u5c31\u662f\u65b9\u5411\u63a8\u5bfc\u3002 NOTE: \u5728\u9f99\u4e66\u76844.2.3 Derivations\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff1a The construction of a parse tree can be made precise by taking a derivational view , in which productions are treated as rewriting rules . Beginning with the start symbol, each rewriting step replaces a nonterminal by the body of one of its productions. This derivational view corresponds to the top-down construction of a parse tree, but the precision afforded by derivations will be especially helpful when bottom-up parsing is discussed. As we shall see, bottom-up parsing is related to a class of derivations known as \"rightmost\" derivations, in which the rightmost nonterminal is rewritten at each step. \u4e0a\u9762\u7684\u8fd9\u4e9b\u5185\u5bb9\u7ed9\u6211\u7684\u542f\u53d1\u662f\uff1a\u4e0d\u540c\u7684\u5b66\u79d1\u5bf9\u540c\u4e00\u4e8b\u7269\u7684\u547d\u540d\u53ef\u80fd\u4e0d\u540c\uff0c\u4f46\u662f\u5b83\u4eec\u672c\u8d28\u4e0a\u6240\u63cf\u8ff0\u7684\u662f\u540c\u4e00\u4e8b\u7269\u3002 \u5176\u5b9e\u4e0a\u8ff0\u6240\u6709\u8fd9\u4e9b\u8ba8\u8bba\uff0c\u672c\u8d28\u4e0a\u90fd\u662f\u5c5e\u4e8e Logic \u5b66\u7684\u8303\u8f74\uff0c\u63a8\u5bfc\uff08 inference \uff09\u5c31\u5c5e\u4e8e\u903b\u8f91\u5b66\u7684\u8303\u8f74\u3002 Set theory \u662f\u6570\u5b66\u7684\u57fa\u77f3\u6240\u5728\uff0c\u5f88\u591a\u5176\u4ed6\u6570\u5b66\u5b66\u79d1\u90fd\u662f\u5efa\u7acb\u5728\u5b83\u7684\u57fa\u7840\u4e4b\u4e0a\u3002 Automata theory \u548c Formal language # \u5728\u4e0a\u8ff0 Language-specification formalisms \u7ae0\u8282\u5c31\u5bf9 Automata theory \u548c Formal language \u4e4b\u95f4\u7684\u5173\u7cfb\u8fdb\u884c\u4e86\u5206\u6790\u3002 Chomsky hierarchy \u5c06 Automata theory \u548c formal language \u8fdb\u884c\u4e86\u5173\u8054\u548c\u5bf9\u5e94\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c Automata theory \u5728\u5176\u4ed6\u9886\u57df\u6709\u7740\u975e\u5e38\u5e7f\u6cdb\u7684\u5e94\u7528\u3002 Turing machine and Mathematical logic # \u5728\u7b2c\u4e00\u6bb5\u7684NOTE\u4e2d\u5c31\u5bf9\u4e24\u8005\u8fdb\u884c\u4e86\u5206\u6790\u3002 \u9664\u6b64\u4e4b\u5916\uff0c\u4e0b\u9762\u6587\u7ae0\u4e5f\u662f\u503c\u5f97\u9605\u8bfb\u7684\uff1a Automated theorem proving Formal methods","title":"Formal-language"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#formal-language","text":"In mathematics , computer science , and linguistics , a formal language consists of words whose letters are taken from an alphabet and are well-formed according to a specific set of rules. The alphabet of a formal language consist of symbols, letters, or tokens that concatenate into strings of the language. Each string concatenated from symbols of this alphabet is called a word , and the words that belong to a particular formal language are sometimes called well-formed words or well-formed formulas . A formal language is often defined by means of a formal grammar such as a regular grammar or context-free grammar , which consists of its formation rules . The field of formal language theory studies primarily the purely syntactical \uff08\u8bed\u6cd5\uff09 aspects of such languages\u2014that is, their internal structural patterns . Formal language theory sprang out of linguistics, as a way of understanding the syntactic regularities\uff08\u89c4\u5f8b\uff09 of natural languages . In computer science, formal languages are used among others as the basis for defining the grammar of programming languages and formalized versions of subsets of natural languages in which the words of the language represent concepts that are associated with particular meanings or semantics \uff08\u8bed\u4e49\uff09. In computational complexity theory , decision problems are typically defined as formal languages , and complexity classes are defined as the sets of the formal languages that can be parsed by machines with limited computational power. In logic and the foundations of mathematics , formal languages are used to represent the syntax of axiomatic systems , and mathematical formalism is the philosophy that all of mathematics can be reduced to the syntactic manipulation of formal languages in this way. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u7684\u7b2c\u4e00\u53e5\u8bdd\u63ed\u793a\u4e86 formal language \u548c logic \u4e4b\u95f4\u7684\u5173\u7cfb\u3002 NOTE: \u6700\u540e\u4e00\u6bb5\u8bdd\u7684\u610f\u601d\u662f\uff1a mathematical formalism \u7684\u601d\u60f3\u662f\uff1a\u6240\u6709\u7684\u6570\u5b66\u90fd\u53ef\u4ee5\u901a\u8fc7\u8fd9\u79cd\u65b9\u5f0f\u7b80\u5316\u4e3aformal language\u7684syntactic manipulation\u3002\u6d4f\u89c8\u4e86\u4e00\u4e0b\u8fd9\u7bc7\u6587\u7ae0\uff0c\u53d1\u73b0 theory of computation \u4e2d\u7684\u5f88\u591a\u8bfe\u9898\u90fd\u6e90\u4e8e\u8fd9\u4e2a\u601d\u60f3\uff0c\u6bd4\u5982 Turing machine \u3002","title":"Formal language"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#words-over-an-alphabet","text":"An alphabet , in the context of formal languages, can be any set , although it often makes sense to use an alphabet in the usual sense of the word, or more generally a character set such as ASCII or Unicode . The elements of an alphabet are called its letters . An alphabet may contain an infinite number of elements; however, most definitions in formal language theory specify alphabets with a finite number of elements, and most results apply only to them. A word over an alphabet can be any finite sequence (i.e., string ) of letters. The set of all words over an alphabet \u03a3 is usually denoted by \u03a3 (using the Kleene star ). The length of a word is the number of letters it is composed of. For any alphabet, there is only one word of length 0, the empty word*, which is often denoted by e, \u03b5, \u03bb or even \u039b. By concatenation one can combine two words to form a new word, whose length is the sum of the lengths of the original words. The result of concatenating a word with the empty word is the original word. In some applications, especially in logic , the alphabet is also known as the vocabulary and words are known as formulas or sentences ; this breaks the letter/word metaphor and replaces it by a word/sentence metaphor. NOTE: \u5728formal language\u7406\u8bba\u4e2d\uff0c alphabet \u3001 character set \u3001vocabulary\u53ef\u4ee5\u8ba4\u4e3a\u662f\u540c\u4e49\u8bcd\u3002","title":"Words over an alphabet"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#definition","text":"A formal language L over an alphabet \u03a3 is a subset of \u03a3*, that is, a set of words over that alphabet. Sometimes the sets of words are grouped into expressions, whereas rules and constraints may be formulated for the creation of 'well-formed expressions'. NOTE: \u6240\u8c13\u7684rules\u5176\u5b9e\u5c31\u662fgrammar\u3002 In computer science and mathematics, which do not usually deal with natural languages , the adjective \"formal\" is often omitted as redundant. NOTE: \u6309\u7167\u8fd9\u4e2a\u8bf4\u6cd5\uff0cprogramming language\u7684\u66f4\u52a0\u4e25\u8c28\u7684\u8bf4\u6cd5\u662f\uff1aprogramming formal language\u3002 While formal language theory usually concerns itself with formal languages that are described by some syntactical rules, the actual definition of the concept \"formal language\" is only as above: a (possibly infinite) set of finite-length strings composed from a given alphabet, no more and no less. In practice, there are many languages that can be described by rules , such as regular languages or context-free languages . The notion of a formal grammar may be closer to the intuitive concept of a \"language,\" one described by syntactic rules. By an abuse of the definition, a particular formal language is often thought of as being equipped with a formal grammar that describes it. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u6240\u5f3a\u8c03\u7684\u662fformal language\u7684\u51c6\u786e\u5b9a\u4e49\u4e2d\u662f\u4e0d\u5305\u542brules\uff08grammar\uff09\u7684\u3002\u4f46\u662f\u5b9e\u9645\u4e2d\uff0c\u8981\u60f3\u51c6\u786e\u7684\u5b9a\u4e49\u4e00\u95e8\u8bed\u8a00\u662f\u79bb\u4e0d\u5f00rules\u7684\u3002\u4ee5programming language\u4e3a\u4f8b\u7684\u8bdd\uff0c\u5b83\u9700\u8981\u8bcd\u6cd5\u548c\u8bed\u6cd5\u624d\u80fd\u591f\u6b63\u786e\u5730\u63cf\u8ff0\u8be5\u8bed\u8a00\u3002","title":"Definition"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#constructions","text":"For finite languages, one can explicitly enumerate all well-formed words. For example, we can describe a language L as just L = {a,\u2009b,\u2009ab,\u2009cba}. The degenerate case of this construction is the empty language , which contains no words at all ( L = \u2205 ). However, even over a finite (non-empty) alphabet such as \u03a3 = {a, b} there are an infinite number of finite-length words that can potentially be expressed: \"a\", \"abb\", \"ababba\", \"aaababbbbaab\", .... Therefore, formal languages are typically infinite, and describing an infinite formal language is not as simple as writing L = {a,\u2009b,\u2009ab,\u2009cba}. Here are some examples of formal languages: L = \u03a3 , the set of all* words over \u03a3; $L = {a}^ = {a^n}$, where n ranges over the natural numbers and \"$a^n$\" means \"a\" repeated n* times (this is the set of words consisting only of the symbol \"a\"); the set of syntactically correct programs in a given programming language (the syntax of which is usually defined by a context-free grammar ); the set of inputs upon which a certain Turing machine halts; or the set of maximal strings of alphanumeric ASCII characters on this line, i.e., the set {the, set, of, maximal, strings, alphanumeric, ASCII, characters, on, this, line, i, e}.","title":"Constructions"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#language-specification-formalisms","text":"Formal languages are used as tools in multiple disciplines. However, formal language theory rarely concerns itself with particular languages (except as examples), but is mainly concerned with the study of various types of formalisms to describe languages. For instance, a language can be given as those strings generated by some formal grammar ; those strings described or matched by a particular regular expression ; those strings accepted by some automaton , such as a Turing machine or finite-state automaton ; those strings for which some decision procedure (an algorithm that asks a sequence of related YES/NO questions) produces the answer YES. Typical questions asked about such formalisms include: What is their expressive power? (Can formalism X describe every language that formalism Y can describe? Can it describe other languages?) What is their recognizability? (How difficult is it to decide whether a given word belongs to a language described by formalism X ?) What is their comparability? (How difficult is it to decide whether two languages, one described in formalism X and one in formalism Y , or in X again, are actually the same language?). Surprisingly often, the answer to these decision problems is \"it cannot be done at all\", or \"it is extremely expensive\" (with a characterization of how expensive). Therefore, formal language theory is a major application area of computability theory and complexity theory . Formal languages may be classified in the Chomsky hierarchy based on the expressive power of their generative grammar as well as the complexity of their recognizing automaton . Context-free grammars and regular grammars provide a good compromise between expressivity and ease of parsing , and are widely used in practical applications.","title":"Language-specification formalisms"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#operations-on-languages","text":"Certain operations on languages are common. This includes the standard set operations, such as union, intersection, and complement. Another class of operation is the element-wise application of string operations. Examples: suppose $ L_{1} $ and $ L_{2} $ are languages over some common alphabet $ \\Sigma $. The concatenation $ L_{1}\\cdot L_{2} $ consists of all strings of the form $ vw $ where $ v $ is a string from $ L_{1} $ and $ w $ is a string from $ L_{2} $. The intersection $ L_{1}\\cap L_{2} $ of $ L_{1} $ and $ L_{2} $ consists of all strings that are contained in both languages The complement $ \\neg L_{1} $ of $ L_{1} $ with respect to $ \\Sigma $ consists of all strings over $ \\Sigma $ that are not in $ L_{1} $. The Kleene star : the language consisting of all words that are concatenations of zero or more words in the original language; Reversal: Let \u03b5 be the empty word, then $ \\varepsilon ^{R}=\\varepsilon $, and for each non-empty word $ w=\\sigma {1}\\cdots \\sigma {n} $ (where $ \\sigma {1},\\ldots ,\\sigma {n} $are elements of some alphabet), let $ w^{R}=\\sigma {n}\\cdots \\sigma {1} $, then for a formal language $ L $, $ L^{R}={w^{R}\\mid w\\in L} $. String homomorphism Such string operations are used to investigate closure properties of classes of languages. A class of languages is closed under a particular operation when the operation, applied to languages in the class, always produces a language in the same class again. For instance, the context-free languages are known to be closed under union, concatenation, and intersection with regular languages , but not closed under intersection or complement. The theory of trios and abstract families of languages studies the most common closure properties of language families in their own right.","title":"Operations on languages"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#applications","text":"","title":"Applications"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#programming-languages","text":"Main articles: Compiler compiler and Syntax (programming languages)","title":"Programming languages"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#formal-theories-systems-and-proofs","text":"Main articles: Theory (mathematical logic) and Formal system In mathematical logic , a formal theory is a set of sentences expressed in a formal language . A formal system (also called a logical calculus , or a logical system ) consists of a formal language together with a deductive apparatus (also called a deductive system ). The deductive apparatus may consist of a set of transformation rules , which may be interpreted as valid rules of inference, or a set of axioms , or have both. A formal system is used to derive one expression from one or more other expressions. Although a formal language can be identified with its formulas, a formal system cannot be likewise identified by its theorems. Two formal systems $ {\\mathcal {FS}} $ and $ {\\mathcal {FS'}} $ may have all the same theorems and yet differ in some significant proof-theoretic way (a formula A may be a syntactic consequence of a formula B in one but not another for instance). A formal proof or derivation is a finite sequence of well-formed formulas (which may be interpreted as sentences, or propositions ) each of which is an axiom or follows from the preceding formulas in the sequence by a rule of inference . The last sentence in the sequence is a theorem of a formal system. Formal proofs are useful because their theorems can be interpreted as true propositions.","title":"Formal theories, systems, and proofs"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#interpretations-and-models","text":"Main articles: Formal semantics (logic) , Interpretation (logic) and Model theory Formal languages are entirely syntactic in nature but may be given semantics that give meaning to the elements of the language. For instance, in mathematical logic , the set of possible formulas of a particular logic is a formal language, and an interpretation assigns a meaning to each of the formulas\u2014usually, a truth value . The study of interpretations of formal languages is called formal semantics . In mathematical logic, this is often done in terms of model theory . In model theory, the terms that occur in a formula are interpreted as objects within mathematical structures , and fixed compositional interpretation rules determine how the truth value of the formula can be derived from the interpretation of its terms; a model for a formula is an interpretation of terms such that the formula becomes true. This diagram shows the syntactic divisions within a formal system . Strings of symbols may be broadly divided into nonsense and well-formed formulas . The set of well-formed formulas is divided into theorems and non-theorems.","title":"Interpretations and models"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#_1","text":"","title":"\u68b3\u7406"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#formal-system-and-formal-language","text":"\u4e0b\u9762\u8fd9\u6bb5\u6458\u81ea Formal systems A formal system (also called a logical calculus , or a logical system ) consists of a formal language together with a deductive apparatus (also called a deductive system ). The deductive apparatus may consist of a set of transformation rules (also called inference rules ) or a set of axioms , or have both. A formal system is used to derive (\u63a8\u5bfc) one expression from one or more other expressions. Propositional and predicate calculi are examples of formal systems. Formal grammars \u76f8\u5f53\u4e8e deductive apparatus \u3002","title":"Formal system and formal language"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#mathematical-logicformal-grammars","text":"\u5982\u679c\u4ece Mathematical logic \u7684\u903b\u8f91\u63a8\u5bfc\u7684\u89d2\u5ea6\u6765\u770b\u5f85 Formal grammars \u7684\u8bdd\uff0c formal grammars \u7684\u5f88\u591a\u5185\u5bb9\u5c31\u53d8\u5f97\u975e\u5e38\u5bb9\u6613\u7406\u89e3\uff1a formal grammars \u672c\u8d28\u4e0a\u5c31\u662f \u63a8\u5bfc\u89c4\u5219 \u4e0b\u9762\u603b\u7ed3\u4e86formal grammar\u4e2d\u7684\u4e00\u4e9b\u6982\u5ff5\u548cmathematical logic\u4e2d\u7684\u4e00\u4e9b\u6982\u5ff5\u4e4b\u95f4\u7684\u5bf9\u5e94\u5173\u7cfb\uff0c\u5982\u4e0b\uff1a Formal grammar Mathematical logic Production rule Formation rule \u3001 Rule of inference \u3001 Rewriting \u4e0a\u8ff0\u5bf9\u5e94\u5173\u7cfb\u7684\u542b\u4e49\u662f\uff1a\u5982\u679c\u4ece Mathematical logic \u6765\u770b\u5f85 Production rule \u7684\u8bdd\uff0c\u5b83\u5c31\u76f8\u5f53\u4e8e\u662f Formation rule \u3001 Rule of inference \u3001 Rewriting \u3002 \u6309\u7167\u516c\u5f0f\u8fdb\u884c\u63a8\u5bfc\u4ece\u53e6\u5916\u4e00\u4e2a\u89d2\u5ea6\u6765\u770b\u5176\u5b9e\u662f\u91cd\u5199\uff0c\u4e0d\u65ad\u5730\u8fdb\u884c\u66ff\u6362\uff0c\u611f\u89c9\u6570\u7406\u903b\u8f91\u672c\u8d28\u4e0a\u5c31\u662f\u8fd9\u4e2a\u4e1c\u897f\u3002\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u770b\uff0cparsing\u7684\u8fc7\u7a0b\u5176\u5b9e\u5c31\u662f\u4e0d\u65ad\u7684\u63a8\u5bfc\u7684\u8fc7\u7a0b\uff0c\u4e0d\u65ad\u7684\u91cd\u5199\u7684\u8fc7\u7a0b\u3002\u7531\u4e8e\u53ef\u80fd\u7684\u63a8\u5bfc\u683c\u5f0f\u662f\u975e\u5e38\u591a\u7684\uff0c\u6240\u4ee5\u9700\u8981\u4e0d\u65ad\u5730\u8fdb\u884c\u5c1d\u8bd5\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u5176\u5b9e\u5c31\u662f search \u3001 backtracking \uff0c\u6240\u4ee5\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u6765\u770b\uff0c parsing \u6240\u505a\u7684\u5de5\u4f5c\u5176\u5b9e\u5c31\u662f\u63a8\u5bfc\u52a0search\u3002\u81ea\u9876\u5411\u4e0b\u5176\u5b9e\u6240\u5bf9\u5e94\u7684\u662f\u6b63\u5411\u63a8\u5bfc\uff0c\u81ea\u5e95\u5411\u4e0a\u5176\u5b9e\u6240\u5bf9\u5e94\u7684\u5c31\u662f\u65b9\u5411\u63a8\u5bfc\u3002 NOTE: \u5728\u9f99\u4e66\u76844.2.3 Derivations\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff1a The construction of a parse tree can be made precise by taking a derivational view , in which productions are treated as rewriting rules . Beginning with the start symbol, each rewriting step replaces a nonterminal by the body of one of its productions. This derivational view corresponds to the top-down construction of a parse tree, but the precision afforded by derivations will be especially helpful when bottom-up parsing is discussed. As we shall see, bottom-up parsing is related to a class of derivations known as \"rightmost\" derivations, in which the rightmost nonterminal is rewritten at each step. \u4e0a\u9762\u7684\u8fd9\u4e9b\u5185\u5bb9\u7ed9\u6211\u7684\u542f\u53d1\u662f\uff1a\u4e0d\u540c\u7684\u5b66\u79d1\u5bf9\u540c\u4e00\u4e8b\u7269\u7684\u547d\u540d\u53ef\u80fd\u4e0d\u540c\uff0c\u4f46\u662f\u5b83\u4eec\u672c\u8d28\u4e0a\u6240\u63cf\u8ff0\u7684\u662f\u540c\u4e00\u4e8b\u7269\u3002 \u5176\u5b9e\u4e0a\u8ff0\u6240\u6709\u8fd9\u4e9b\u8ba8\u8bba\uff0c\u672c\u8d28\u4e0a\u90fd\u662f\u5c5e\u4e8e Logic \u5b66\u7684\u8303\u8f74\uff0c\u63a8\u5bfc\uff08 inference \uff09\u5c31\u5c5e\u4e8e\u903b\u8f91\u5b66\u7684\u8303\u8f74\u3002 Set theory \u662f\u6570\u5b66\u7684\u57fa\u77f3\u6240\u5728\uff0c\u5f88\u591a\u5176\u4ed6\u6570\u5b66\u5b66\u79d1\u90fd\u662f\u5efa\u7acb\u5728\u5b83\u7684\u57fa\u7840\u4e4b\u4e0a\u3002","title":"\u4eceMathematical logic\u7684\u89d2\u5ea6\u6765\u770bFormal grammars"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#automata-theoryformal-language","text":"\u5728\u4e0a\u8ff0 Language-specification formalisms \u7ae0\u8282\u5c31\u5bf9 Automata theory \u548c Formal language \u4e4b\u95f4\u7684\u5173\u7cfb\u8fdb\u884c\u4e86\u5206\u6790\u3002 Chomsky hierarchy \u5c06 Automata theory \u548c formal language \u8fdb\u884c\u4e86\u5173\u8054\u548c\u5bf9\u5e94\u3002\u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c Automata theory \u5728\u5176\u4ed6\u9886\u57df\u6709\u7740\u975e\u5e38\u5e7f\u6cdb\u7684\u5e94\u7528\u3002","title":"Automata theory\u548cFormal language"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-language/#turing-machine-and-mathematical-logic","text":"\u5728\u7b2c\u4e00\u6bb5\u7684NOTE\u4e2d\u5c31\u5bf9\u4e24\u8005\u8fdb\u884c\u4e86\u5206\u6790\u3002 \u9664\u6b64\u4e4b\u5916\uff0c\u4e0b\u9762\u6587\u7ae0\u4e5f\u662f\u503c\u5f97\u9605\u8bfb\u7684\uff1a Automated theorem proving Formal methods","title":"Turing machine and Mathematical logic"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-system/","text":"Formal system # A formal system is used for inferring theorems from axioms according to a set of rules . These rules, which are used for carrying out the inference of theorems from axioms, are the logical calculus of the formal system. A formal system is essentially an \" axiomatic system \". In 1921, David Hilbert proposed to use such system as the foundation for the knowledge in mathematics . A formal system may represent a well-defined system of abstract thought . NOTE: \u5982\u4f55\u7406\u89e3theorem\u548caxiom\uff1f\u53c2\u8003\u4e00\u4e0b\u4e0b\u9762\u7684\u5185\u5bb9\uff1a Axiom \uff1a\u516c\u7406\uff0c\u4e00\u5b9a\u4e3aTrue Theorem \uff1a\u5b9a\u7406\uff0c\u7531axiom\u63a8\u7406\u800c\u6765 The term formalism is sometimes a rough synonym for formal system , but is also refers to a given style of notation , for example, Paul Dirac 's bra\u2013ket notation . Background # Each formal system uses primitive symbols (which collectively form an alphabet ) to finitely construct a formal language from a set of axioms through inferential rules of formation . The system thus consists of valid formulas built up through finite combinations of the primitive symbols\u2014combinations that are formed from the axioms in accordance with the stated rules. More formally, this can be expressed as the following: A finite set of symbols, known as the alphabet, which concatenate formulas , so that a formula is just a finite string of symbols taken from the alphabet. A grammar consisting of rules to form formulas from simpler formulas. A formula is said to be well-formed if it can be formed using the rules of the formal grammar. It is often required that there be a decision procedure for deciding whether a formula is well-formed. A set of axioms, or axiom schemata , consisting of well-formed formulas. A set of inference rules . A well-formed formula that can be inferred from the axioms is known as a theorem of the formal system. Recursive # A formal system is said to be recursive (i.e. effective) or recursively enumerable if the set of axioms and the set of inference rules are decidable sets or semidecidable sets , respectively. List of formal systems #","title":"Formal-system"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-system/#formal-system","text":"A formal system is used for inferring theorems from axioms according to a set of rules . These rules, which are used for carrying out the inference of theorems from axioms, are the logical calculus of the formal system. A formal system is essentially an \" axiomatic system \". In 1921, David Hilbert proposed to use such system as the foundation for the knowledge in mathematics . A formal system may represent a well-defined system of abstract thought . NOTE: \u5982\u4f55\u7406\u89e3theorem\u548caxiom\uff1f\u53c2\u8003\u4e00\u4e0b\u4e0b\u9762\u7684\u5185\u5bb9\uff1a Axiom \uff1a\u516c\u7406\uff0c\u4e00\u5b9a\u4e3aTrue Theorem \uff1a\u5b9a\u7406\uff0c\u7531axiom\u63a8\u7406\u800c\u6765 The term formalism is sometimes a rough synonym for formal system , but is also refers to a given style of notation , for example, Paul Dirac 's bra\u2013ket notation .","title":"Formal system"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-system/#background","text":"Each formal system uses primitive symbols (which collectively form an alphabet ) to finitely construct a formal language from a set of axioms through inferential rules of formation . The system thus consists of valid formulas built up through finite combinations of the primitive symbols\u2014combinations that are formed from the axioms in accordance with the stated rules. More formally, this can be expressed as the following: A finite set of symbols, known as the alphabet, which concatenate formulas , so that a formula is just a finite string of symbols taken from the alphabet. A grammar consisting of rules to form formulas from simpler formulas. A formula is said to be well-formed if it can be formed using the rules of the formal grammar. It is often required that there be a decision procedure for deciding whether a formula is well-formed. A set of axioms, or axiom schemata , consisting of well-formed formulas. A set of inference rules . A well-formed formula that can be inferred from the axioms is known as a theorem of the formal system.","title":"Background"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-system/#recursive","text":"A formal system is said to be recursive (i.e. effective) or recursively enumerable if the set of axioms and the set of inference rules are decidable sets or semidecidable sets , respectively.","title":"Recursive"},{"location":"Theory-framework/Formal-language/wikipedia-Formal-system/#list-of-formal-systems","text":"","title":"List of formal systems"},{"location":"Theory-framework/Formal-language/wikipedia-Language/","text":"Language Study Modern linguistics \u5206\u7c7b Language # Study # Modern linguistics # In the 1960s, Noam Chomsky formulated the generative theory of language . According to this theory, the most basic form of language is a set of syntactic rules that is universal for all humans and which underlies the grammars of all human languages. This set of rules is called Universal Grammar ; for Chomsky, describing it is the primary objective of the discipline of linguistics. Thus, he considered that the grammars of individual languages are only of importance to linguistics insofar as they allow us to deduce the universal underlying rules from which the observable linguistic variability is generated. In opposition to the formal theories of the generative school, functional theories of language propose that since language is fundamentally a tool, its structures are best analyzed and understood by reference to their functions. Formal theories of grammar seek to define the different elements of language and describe the way they relate to each other as systems of formal rules or operations, while functional theories seek to define the functions performed by language and then relate them to the linguistic elements that carry them out. The framework of cognitive linguistics interprets language in terms of the concepts (which are sometimes universal, and sometimes specific to a particular language) which underlie its forms. Cognitive linguistics is primarily concerned with how the mind creates meaning through language \u5206\u7c7b # Constructed language Natural languages","title":"wikipedia Language"},{"location":"Theory-framework/Formal-language/wikipedia-Language/#language","text":"","title":"Language"},{"location":"Theory-framework/Formal-language/wikipedia-Language/#study","text":"","title":"Study"},{"location":"Theory-framework/Formal-language/wikipedia-Language/#modern-linguistics","text":"In the 1960s, Noam Chomsky formulated the generative theory of language . According to this theory, the most basic form of language is a set of syntactic rules that is universal for all humans and which underlies the grammars of all human languages. This set of rules is called Universal Grammar ; for Chomsky, describing it is the primary objective of the discipline of linguistics. Thus, he considered that the grammars of individual languages are only of importance to linguistics insofar as they allow us to deduce the universal underlying rules from which the observable linguistic variability is generated. In opposition to the formal theories of the generative school, functional theories of language propose that since language is fundamentally a tool, its structures are best analyzed and understood by reference to their functions. Formal theories of grammar seek to define the different elements of language and describe the way they relate to each other as systems of formal rules or operations, while functional theories seek to define the functions performed by language and then relate them to the linguistic elements that carry them out. The framework of cognitive linguistics interprets language in terms of the concepts (which are sometimes universal, and sometimes specific to a particular language) which underlie its forms. Cognitive linguistics is primarily concerned with how the mind creates meaning through language","title":"Modern linguistics"},{"location":"Theory-framework/Formal-language/wikipedia-Language/#_1","text":"Constructed language Natural languages","title":"\u5206\u7c7b"},{"location":"Theory-framework/Formal-language/Formal-grammar/wikipedia-Formal-grammar/","text":"Formal grammar Formal definition The syntax of grammars The Chomsky hierarchy Analytic grammars Formal grammar # In formal language theory , a grammar (when the context is not given, often called a formal grammar for clarity) is a set of production rules for strings in a formal language . The rules describe how to form strings from the language's alphabet that are valid according to the language's syntax . A grammar does not describe the meaning of the strings or what can be done with them in whatever context\u2014only their form. NOTE: \u4e0d\u6d89\u53ca semantics A formal grammar is a set of rules for rewriting strings, along with a \"start symbol\" from which rewriting starts. Therefore, a grammar is usually thought of as a language generator . However, it can also sometimes be used as the basis for a \" recognizer \"\u2014a function in computing that determines whether a given string belongs to the language or is grammatically incorrect. To describe such recognizers , formal language theory uses separate formalisms, known as automata theory . One of the interesting results of automata theory is that it is not possible to design a recognizer for certain formal languages . Parsing is the process of recognizing an utterance (a string in natural languages) by breaking it down to a set of symbols and analyzing each one against the grammar of the language. Most languages have the meanings of their utterances structured according to their syntax \u2014a practice known as compositional semantics . As a result, the first step to describing the meaning of an utterance in language is to break it down part by part and look at its analyzed form (known as its parse tree in computer science, and as its deep structure in generative grammar ). Formal definition # Main article: Unrestricted grammar The syntax of grammars # NOTE: \u8fd9\u4e00\u6bb5\u662f\u63cf\u8ff0\u8bed\u6cd5\u7684\u8bed\u6cd5\uff0c\u5176\u5b9e\u5c31\u662f Metasyntax The Chomsky hierarchy # Main article: Chomsky hierarchy NOTE: Chomsky hierarchy \u5bf9formal grammar\u8fdb\u884c\u5206\u7c7b\u3002\u5728Chomsky-hierarchy\u7ae0\u8282\u5bf9\u5b83\u8fdb\u884c\u5206\u6790\u3002 Analytic grammars # NOTE: \u5728compiler\u4e2d\uff0c\u5f80\u5f80\u662f\u57fa\u4e8egrammar\u6765\u5bf9language\uff08\u5176\u5b9e\u5c31\u662f\u6211\u4eec\u6240\u5199\u7684\u7a0b\u5e8f\uff09\u8fdb\u884c\u5206\u6790\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u5c31\u662f parsing ,","title":"Formal-grammar"},{"location":"Theory-framework/Formal-language/Formal-grammar/wikipedia-Formal-grammar/#formal-grammar","text":"In formal language theory , a grammar (when the context is not given, often called a formal grammar for clarity) is a set of production rules for strings in a formal language . The rules describe how to form strings from the language's alphabet that are valid according to the language's syntax . A grammar does not describe the meaning of the strings or what can be done with them in whatever context\u2014only their form. NOTE: \u4e0d\u6d89\u53ca semantics A formal grammar is a set of rules for rewriting strings, along with a \"start symbol\" from which rewriting starts. Therefore, a grammar is usually thought of as a language generator . However, it can also sometimes be used as the basis for a \" recognizer \"\u2014a function in computing that determines whether a given string belongs to the language or is grammatically incorrect. To describe such recognizers , formal language theory uses separate formalisms, known as automata theory . One of the interesting results of automata theory is that it is not possible to design a recognizer for certain formal languages . Parsing is the process of recognizing an utterance (a string in natural languages) by breaking it down to a set of symbols and analyzing each one against the grammar of the language. Most languages have the meanings of their utterances structured according to their syntax \u2014a practice known as compositional semantics . As a result, the first step to describing the meaning of an utterance in language is to break it down part by part and look at its analyzed form (known as its parse tree in computer science, and as its deep structure in generative grammar ).","title":"Formal grammar"},{"location":"Theory-framework/Formal-language/Formal-grammar/wikipedia-Formal-grammar/#formal-definition","text":"Main article: Unrestricted grammar","title":"Formal definition"},{"location":"Theory-framework/Formal-language/Formal-grammar/wikipedia-Formal-grammar/#the-syntax-of-grammars","text":"NOTE: \u8fd9\u4e00\u6bb5\u662f\u63cf\u8ff0\u8bed\u6cd5\u7684\u8bed\u6cd5\uff0c\u5176\u5b9e\u5c31\u662f Metasyntax","title":"The syntax of grammars"},{"location":"Theory-framework/Formal-language/Formal-grammar/wikipedia-Formal-grammar/#the-chomsky-hierarchy","text":"Main article: Chomsky hierarchy NOTE: Chomsky hierarchy \u5bf9formal grammar\u8fdb\u884c\u5206\u7c7b\u3002\u5728Chomsky-hierarchy\u7ae0\u8282\u5bf9\u5b83\u8fdb\u884c\u5206\u6790\u3002","title":"The Chomsky hierarchy"},{"location":"Theory-framework/Formal-language/Formal-grammar/wikipedia-Formal-grammar/#analytic-grammars","text":"NOTE: \u5728compiler\u4e2d\uff0c\u5f80\u5f80\u662f\u57fa\u4e8egrammar\u6765\u5bf9language\uff08\u5176\u5b9e\u5c31\u662f\u6211\u4eec\u6240\u5199\u7684\u7a0b\u5e8f\uff09\u8fdb\u884c\u5206\u6790\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u5c31\u662f parsing ,","title":"Analytic grammars"},{"location":"Theory-framework/Formal-language/Formal-grammar/wikipedia-Production(computer-science)/","text":"Production (computer science) \u4ea7\u751f\u5f0f\u7684\u9012\u5f52\u6027 \u9012\u5f52\u516c\u5f0fVS\u4ea7\u751f\u5f0f \u4eceMathematical logic\u7684\u89d2\u5ea6\u6765\u770bFormal grammars Backus\u2013Naur form Production (computer science) # \u57fa\u672c\u4e0a\u6240\u6709\u7684formal grammar\u90fd\u662f\u4f7f\u7528\u7684production\u6765\u8fdb\u884c\u63cf\u8ff0\uff0c\u6240\u4ee5\u5bf9production\u8fdb\u884c\u5206\u6790\u662f\u6709\u4e00\u5b9a\u5fc5\u8981\u7684\u3002 \u4ea7\u751f\u5f0f\u7684\u9012\u5f52\u6027 # \u5f53\u4ea7\u751f\u5f0f\u4f53\u4e2d\u5305\u542b\u4ea7\u751f\u5f0f\u5934\u90e8\u4e2d\u7684non-terminal\u7684\u65f6\uff0c\u8be5\u4ea7\u751f\u5f0f\u5c31\u662f recursive \uff0c\u5b83\u6240\u63cf\u8ff0\u7684grammar\u5c31\u662f recursive grammar \u3002 \u4e0e\u4ea7\u751f\u5f0f\u7684\u9012\u5f52\u6027\u76f8\u5173\u7684\u53e6\u5916\u4e00\u4e2a\u6982\u5ff5\u662f left recursion \u3002 \u9012\u5f52\u516c\u5f0fVS\u4ea7\u751f\u5f0f # \u6570\u5b66\u4e2d\u7684\u9012\u5f52\u516c\u5f0f\uff08 recurrence relation \uff09\uff0c\u8bed\u8a00\u5b66\u4e2d\u7684\u4ea7\u751f\u5f0f\uff0c\u4e24\u8005\u5176\u5b9e\u6709\u7740\u5171\u540c\u4e4b\u5904\uff1a\u9012\u5f52\u3002 \u4ece Mathematical logic \u7684\u89d2\u5ea6\u6765\u770b Formal grammars # \u5728 Formal-language \u7684\u300a\u4ece Mathematical logic \u7684\u89d2\u5ea6\u6765\u770b Formal grammars \u300b\u7ae0\u8282\u5c31\u4ece Mathematical logic \u7684\u89d2\u5ea6\u5206\u6790\u4e86 Formal grammars \uff0c\u5176\u5b9e\u8fd9\u662f\u5bf9production\u7684\u5206\u6790\u3002 \u4ece Formation rule \u7684\u89d2\u5ea6\u6765\u770b\u5f85production\uff0c\u5219\u5b83\u662f\u4e00\u79cd\u63a8\u5bfc\u3002\u5982\u679c\u4ece\u63a8\u5bfc\u7684\u89d2\u5ea6\u6765\u770b\u5f85\u4ea7\u751f\u5f0f\u7684\u8bdd\uff0c\u5219\u5173\u4e8e\u81ea\u9876\u5411\u4e0bparsing\u65e0\u6cd5\u5904\u7406\u5de6\u9012\u5f52\u7684\u60c5\u51b5\u5c31\u975e\u5e38\u4efb\u610f\u7406\u89e3\u4e86 Backus\u2013Naur form # BNF\u672c\u8d28\u4e0a\u4e5f\u662f\u4e00\u79cd\u4ea7\u751f\u5f0f","title":"Production"},{"location":"Theory-framework/Formal-language/Formal-grammar/wikipedia-Production(computer-science)/#production-computer-science","text":"\u57fa\u672c\u4e0a\u6240\u6709\u7684formal grammar\u90fd\u662f\u4f7f\u7528\u7684production\u6765\u8fdb\u884c\u63cf\u8ff0\uff0c\u6240\u4ee5\u5bf9production\u8fdb\u884c\u5206\u6790\u662f\u6709\u4e00\u5b9a\u5fc5\u8981\u7684\u3002","title":"Production (computer science)"},{"location":"Theory-framework/Formal-language/Formal-grammar/wikipedia-Production(computer-science)/#_1","text":"\u5f53\u4ea7\u751f\u5f0f\u4f53\u4e2d\u5305\u542b\u4ea7\u751f\u5f0f\u5934\u90e8\u4e2d\u7684non-terminal\u7684\u65f6\uff0c\u8be5\u4ea7\u751f\u5f0f\u5c31\u662f recursive \uff0c\u5b83\u6240\u63cf\u8ff0\u7684grammar\u5c31\u662f recursive grammar \u3002 \u4e0e\u4ea7\u751f\u5f0f\u7684\u9012\u5f52\u6027\u76f8\u5173\u7684\u53e6\u5916\u4e00\u4e2a\u6982\u5ff5\u662f left recursion \u3002","title":"\u4ea7\u751f\u5f0f\u7684\u9012\u5f52\u6027"},{"location":"Theory-framework/Formal-language/Formal-grammar/wikipedia-Production(computer-science)/#vs","text":"\u6570\u5b66\u4e2d\u7684\u9012\u5f52\u516c\u5f0f\uff08 recurrence relation \uff09\uff0c\u8bed\u8a00\u5b66\u4e2d\u7684\u4ea7\u751f\u5f0f\uff0c\u4e24\u8005\u5176\u5b9e\u6709\u7740\u5171\u540c\u4e4b\u5904\uff1a\u9012\u5f52\u3002","title":"\u9012\u5f52\u516c\u5f0fVS\u4ea7\u751f\u5f0f"},{"location":"Theory-framework/Formal-language/Formal-grammar/wikipedia-Production(computer-science)/#mathematical-logicformal-grammars","text":"\u5728 Formal-language \u7684\u300a\u4ece Mathematical logic \u7684\u89d2\u5ea6\u6765\u770b Formal grammars \u300b\u7ae0\u8282\u5c31\u4ece Mathematical logic \u7684\u89d2\u5ea6\u5206\u6790\u4e86 Formal grammars \uff0c\u5176\u5b9e\u8fd9\u662f\u5bf9production\u7684\u5206\u6790\u3002 \u4ece Formation rule \u7684\u89d2\u5ea6\u6765\u770b\u5f85production\uff0c\u5219\u5b83\u662f\u4e00\u79cd\u63a8\u5bfc\u3002\u5982\u679c\u4ece\u63a8\u5bfc\u7684\u89d2\u5ea6\u6765\u770b\u5f85\u4ea7\u751f\u5f0f\u7684\u8bdd\uff0c\u5219\u5173\u4e8e\u81ea\u9876\u5411\u4e0bparsing\u65e0\u6cd5\u5904\u7406\u5de6\u9012\u5f52\u7684\u60c5\u51b5\u5c31\u975e\u5e38\u4efb\u610f\u7406\u89e3\u4e86","title":"\u4eceMathematical logic\u7684\u89d2\u5ea6\u6765\u770bFormal grammars"},{"location":"Theory-framework/Formal-language/Formal-grammar/wikipedia-Production(computer-science)/#backusnaur-form","text":"BNF\u672c\u8d28\u4e0a\u4e5f\u662f\u4e00\u79cd\u4ea7\u751f\u5f0f","title":"Backus\u2013Naur form"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/","text":"Chomsky hierarchy The hierarchy Type-0 grammars Type-1 grammars Type-2 grammars Type-3 grammars \u5bf9\u6bd4\u5206\u6790 Type-0 grammars:Unrestricted grammar formal definition \u5bf9\u6bd4\u5206\u6790 Type-1 grammars:Context-sensitive grammar formal definition \u5bf9\u6bd4\u5206\u6790 Type-2 grammars:Context-free grammar formal definitions Production rule notation Rule application Repetitive rule application Context-free language \u5bf9\u6bd4\u5206\u6790 Type-3 grammars:Regular grammar formal definition \u5bf9\u6bd4\u5206\u6790 \u603b\u7ed3 Chomsky hierarchy # In the formal languages of computer science and linguistics , the Chomsky hierarchy (occasionally referred to as the Chomsky\u2013Sch\u00fctzenberger hierarchy ) is a containment hierarchy of classes of formal grammars . This hierarchy of grammars was described by Noam Chomsky in 1956. It is also named after Marcel-Paul Sch\u00fctzenberger , who played a crucial role in the development of the theory of formal languages . The hierarchy # The following table summarizes each of Chomsky's four types of grammars, the class of language it generates, the type of automaton that recognizes it, and the form its rules must have. Grammar Languages Automaton Production rules (constraints)* Examples Type-0 Recursively enumerable Turing machine $ \\alpha A\\beta \\rightarrow \\delta $ (no constraints) $ L={w Type-1 Context-sensitive Linear-bounded non-deterministic Turing machine $ \\alpha A\\beta \\rightarrow \\alpha \\gamma \\beta $ $ L={a^{n}b^{n}c^{n} Type-2 Context-free Non-deterministic pushdown automaton $ A\\rightarrow \\alpha $ $ L={a^{n}b^{n} Type-3 Regular Finite state automaton $ A\\rightarrow {\\text{a}} $ and $ A\\rightarrow {\\text{a}}B $ $ L={a^{n} Meaning of symbols: $ {\\text{a}} $ = terminal $ A $, $ B $ = non-terminal $ \\alpha $, $ \\beta $, $ \\gamma $, $ \\delta $ = string of terminals and/or non-terminals $ \\alpha $, $ \\beta $, $ \\delta $ = maybe empty $ \\gamma $ = never empty Set inclusions described by the Chomsky hierarchy Note that the set of grammars corresponding to recursive languages is not a member of this hierarchy; these would be properly between Type-0 and Type-1. Every regular language is context-free, every context-free language is context-sensitive, every context-sensitive language is recursive and every recursive language is recursively enumerable . These are all proper inclusions , meaning that there exist recursively enumerable languages that are not context-sensitive, context-sensitive languages that are not context-free and context-free languages that are not regular. Type-0 grammars # Main article: Unrestricted grammar Type-0 grammars include all formal grammars. They generate exactly all languages that can be recognized by a Turing machine . These languages are also known as the recursively enumerable or Turing-recognizable languages. Note that this is different from the recursive languages , which can be decided by an always-halting Turing machine . Type-1 grammars # Main article: Context-sensitive grammar Type-1 grammars generate context-sensitive languages . These grammars have rules of the form $ \\alpha A\\beta \\rightarrow \\alpha \\gamma \\beta $ with $ A $ a nonterminal and $ \\alpha $, $ \\beta $ and $ \\gamma $ strings of terminals and/or nonterminals. The strings $ \\alpha $ and $ \\beta $ may be empty, but $ \\gamma $ must be nonempty. The rule $ S\\rightarrow \\epsilon $ is allowed if $ S $ does not appear on the right side of any rule. The languages described by these grammars are exactly all languages that can be recognized by a linear bounded automaton (a nondeterministic Turing machine whose tape is bounded by a constant times the length of the input.) Type-2 grammars # Main article: Context-free grammar Type-2 grammars generate the context-free languages . These are defined by rules of the form $ A\\rightarrow \\alpha $ with $ A $ being a nonterminal and $ \\alpha $ being a string of terminals and/or nonterminals. These languages are exactly all languages that can be recognized by a non-deterministic pushdown automaton . Context-free languages\u2014or rather its subset of deterministic context-free language \u2014are the theoretical basis for the phrase structure of most programming languages , though their syntax also includes context-sensitive name resolution due to declarations and scope . Often a subset of grammars is used to make parsing easier, such as by an LL parser . Type-3 grammars # Main article: Regular grammar Type-3 grammars generate the regular languages . Such a grammar restricts its rules to a single nonterminal on the left-hand side and a right-hand side consisting of a single terminal, possibly followed by a single nonterminal (right regular). Alternatively, the right-hand side of the grammar can consist of a single terminal, possibly preceded by a single nonterminal (left regular). These generate the same languages. However, if left-regular rules and right-regular rules are combined, the language need no longer be regular. The rule $ S\\rightarrow \\epsilon $ is also allowed here if $ S $ does not appear on the right side of any rule. These languages are exactly all languages that can be decided by a finite state automaton . Additionally, this family of formal languages can be obtained by regular expressions . Regular languages are commonly used to define search patterns and the lexical structure of programming languages. \u5bf9\u6bd4\u5206\u6790 # Type-0 grammars\u53c8\u53eb\u505a unrestricted grammar \uff0c\u4ece\u5b83\u7684\u540d\u5b57\u53ef\u4ee5\u770b\u51fa\uff0c\u5b83\u662funrestricted\u7684\uff0c\u5373 No restrictions are made on the productions of an unrestricted grammar \u90a3\u5176\u5b83grammar\uff08Type-1 grammars Context-sensitive grammar \u3001Type-2 grammars Context-free grammar \u3001Type-3 grammars Regular grammar \uff09\uff0c\u5bf9\u5404\u81ea\u7684production\u7684restriction\u662f\u4ec0\u4e48\u5462\uff1f\u4e0b\u9762\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u5bf9\u8fd9\u51e0\u79cdgrammar\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c \u7531\u4e0a\u8ff0Chomsky hierarchy\u6240\u63cf\u8ff0\u7684\u5c42\u7ea7\u53ef\u4ee5\u770b\u51fa\uff0c\u4eceType 0 grammars\u5230Type 3 grammars\u9010\u7ea7\u589e\u52a0restriction\uff0c\u6240\u4ee5\u5728\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u7684\u65f6\u5019\uff0c\u6bcf\u4e2agrammar\u53ea\u9700\u8981\u548c\u5b83\u7684\u5347\u4e00\u7ea7grammar\u8fdb\u884c\u5bf9\u6bd4\u5373\u53ef\u3002 Type-0 grammars: Unrestricted grammar formal definition # An unrestricted grammar is a formal grammar $ G=(N,\\Sigma ,P,S) $, where $ N $ is a set of nonterminal symbols, $ \\Sigma $ is a set of terminal symbols , $ N $ and $ \\Sigma $ are disjoint, $ P $ is a set of production rules of the form $ \\alpha \\to \\beta $ where $ \\alpha $ and $ \\beta $ are strings of symbols in $ N\\cup \\Sigma $ and $ \\alpha $ is not the empty string , and $ S\\in N $ is a specially designated start symbol. As the name implies, there are no real restrictions on the types of production rules that unrestricted grammars can have. \u5bf9\u6bd4\u5206\u6790 # \u548c\u5176\u4ed6\u7684grammar production\u76f8\u6bd4\uff0c\u5b83\u7684unrestriction\u4f53\u73b0\u5728\uff1a $\\alpha$\u53ef\u4ee5\u4e3aterminal\u3001non-terminal $\\beta$\u53ef\u4ee5\u4e3aempty string Type-1 grammars: Context-sensitive grammar formal definition # A formal grammar G = ( N , \u03a3, P , S ), where N is a set of nonterminal symbols, \u03a3 is a set of terminal symbols, P is a set of production rules, and S is the start symbol , is context-sensitive if all rules in P are of the form \u03b1 A \u03b2 \u2192 \u03b1\u03b3\u03b2 where A \u2208 N , \u03b1,\u03b2 \u2208 ( N \u222a\u03a3) and \u03b3 \u2208 ( N*\u222a\u03a3)+. \u4e0a\u8ff0 * \u548c + \u90fd\u662f\u4f7f\u7528\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u6982\u5ff5\u3002 \u5bf9\u6bd4\u5206\u6790 # \u548c unrestricted grammar production\u76f8\u6bd4\uff0c\u5b83\u7684restriction\u5728\u4e8e\uff1a \u03b3\u4e0d\u53ef\u4e3aempty string A\uff08\u5728\u4ea7\u751f\u5f0f\u7684\u5de6\u90e8\uff09\u5fc5\u987b\u662fnon-terminal \u4e0a\u8ff0\u4e24\u4e2arestriction\u5728Type-0 grammar\u4e2d\u90fd\u4e0d\u5b58\u5728\u3002 Type-2 grammars: Context-free grammar formal definitions # A context-free grammar G is defined by the 4- tuple : $ G=(V,\\Sigma ,R,S) $ where V is a finite set; each element $ v\\in V $ is called a nonterminal character or a variable . Each variable represents a different type of phrase or clause in the sentence. Variables are also sometimes called syntactic categories. Each variable defines a sub-language of the language defined by G . \u03a3 is a finite set of terminal s, disjoint from V , which make up the actual content of the sentence. The set of terminals is the alphabet of the language defined by the grammar G . R is a finite relation from V to $ (V\\cup \\Sigma )^{ } $, where the asterisk represents the Kleene star operation. The members of R are called the (rewrite) rule s or production s of the grammar. (also commonly symbolized by a P*) NOTE: See also production rule rewriting S is the start variable (or start symbol), used to represent the whole sentence (or program). It must be an element of V . Production rule notation # A production rule in R is formalized mathematically as a pair $ (\\alpha ,\\beta )\\in R $, where $ \\alpha \\in V $ is a nonterminal and $ \\beta \\in (V\\cup \\Sigma )^{ } $ is a string of variables and/or terminals; rather than using ordered pair notation, production rules are usually written using an arrow operator with \u03b1 as its left hand side and \u03b2* as its right hand side: $ \\alpha \\rightarrow \\beta $. It is allowed for \u03b2 to be the empty string , and in this case it is customary to denote it by \u03b5. The form $ \\alpha \\rightarrow \\varepsilon $ is called an \u03b5 -production. It is common to list all right-hand sides for the same left-hand side on the same line, using | (the pipe symbol ) to separate them. Rules $ \\alpha \\rightarrow \\beta {1} $ and $ \\alpha \\rightarrow \\beta {2} $ can hence be written as $ \\alpha \\rightarrow \\beta {1}\\mid \\beta {2} $. In this case, $ \\beta {1} $ and $ \\beta {2} $ is called the first and second alternative, respectively. Rule application # For any strings $ u,v\\in (V\\cup \\Sigma )^{ } $, we say u directly yields v , written as $ u\\Rightarrow v\\, $, if $ \\exists (\\alpha ,\\beta )\\in R $ with $ \\alpha \\in V $ and $ u_{1},u_{2}\\in (V\\cup \\Sigma )^{ } $ such that $ u\\,=u_{1}\\alpha u_{2} $ and $ v\\,=u_{1}\\beta u_{2} $. Thus, v is a result of applying the rule $ (\\alpha ,\\beta ) $ to u . Repetitive rule application # For any strings $ u,v\\in (V\\cup \\Sigma )^{ }, $ we say u yields v , written as $ u{\\stackrel { }{\\Rightarrow }}v $ (or $ u\\Rightarrow \\Rightarrow v\\, $ in some textbooks), if $ \\exists k\\geq 1\\,\\exists \\,u_{1},\\cdots ,u_{k}\\in (V\\cup \\Sigma )^{ } $ such that $ u=\\,u_{1}\\Rightarrow u_{2}\\Rightarrow \\cdots \\Rightarrow u_{k}\\,=v $. In this case, if $ k\\geq 2 $ (i.e., $ u\\neq v $), the relation $ u{\\stackrel {+}{\\Rightarrow }}v $ holds. In other words, $ ({\\stackrel { }{\\Rightarrow }}) $ and $ ({\\stackrel {+}{\\Rightarrow }}) $ are the reflexive transitive closure (allowing a word to yield itself) and the transitive closure (requiring at least one step) of $ (\\Rightarrow ) $, respectively. Context-free language # The language of a grammar $ G=(V,\\Sigma ,R,S) $ is the set $ L(G)={w\\in \\Sigma ^{ }:S{\\stackrel { }{\\Rightarrow }}w} $ A language L is said to be a context-free language (CFL), if there exists a CFG G , such that $ L\\,=\\,L(G) $. Non-deterministic pushdown automata recognize exactly the context-free languages. \u5bf9\u6bd4\u5206\u6790 # Context-free grammar \u7684restriction\u5728\u4e8e The left-hand side of the production rule is always a nonterminal symbol. This means that the symbol does not appear in the resulting formal language. \u5728type 1 grammar\u4e2d\uff0c\u5bf9\u4ea7\u751f\u5f0f\u7684\u5de6\u90e8\u4e2d nonterminal symbol\u7684\u4e2a\u6570\u5e76\u6ca1\u6709\u9650\u5236\u3002 Type-3 grammars: Regular grammar formal definition # A right regular grammar (also called right linear grammar ) is a formal grammar ( N , \u03a3, P , S ) such that all the production rules in P are of one of the following forms: A \u2192 a , where A is a non-terminal in N and a is a terminal in \u03a3 A \u2192 aB , where A and B are non-terminals in N and a is in \u03a3 A \u2192 \u03b5, where A is in N and \u03b5 denotes the empty string , i.e. the string of length 0. In a left regular grammar (also called left linear grammar ), all rules obey the forms A \u2192 a , where A is a non-terminal in N and a is a terminal in \u03a3 A \u2192 Ba , where A and B are in N and a is in \u03a3 A \u2192 \u03b5, where A is in N and \u03b5 is the empty string. A regular grammar is a left or right regular grammar. Some textbooks and articles disallow empty production rules, and assume that the empty string is not present in languages. \u5bf9\u6bd4\u5206\u6790 # \u4e0eType-2 grammars\u76f8\u6bd4\uff0cType-3 grammars\u7684\u9650\u5236\u5728\u4e8e\u4ea7\u751f\u5f0f\u53f3\u4fa7\u7684non-terminal\uff1a \u4ea7\u751f\u5f0f\u7684\u53f3\u4fa7\u6700\u591a\u53ea\u80fd\u591f\u6709\u4e00\u4e2anon-terminal \u4ea7\u751f\u5f0f\u53f3\u4fa7\u7684non-terminal\u53ea\u80fd\u591f\u5728\u6700\u5de6\u4fa7\u6216\u6700\u53f3\u4fa7 \u663e\u7136\uff0c\u4e0eType-2 grammars\u76f8\u6bd4\uff0c\u7531\u4e8eType-3 grammar\u7684production\u7684\u53f3\u4fa7\u53ea\u80fd\u591f\u6709\u4e00\u4e2anon-terminal\uff0c\u6240\u4ee5\u5728\u6309\u7167\u5b83\u7684production\u8fdb\u884crewrite\uff08\u6269\u5c55\uff09\u7684\u65f6\u5019\uff0c\u53ea\u80fd\u591f\u5411\u4e00\u4e2a\u65b9\u5411\u8fdb\u884c\u6269\u5c55\uff0c\u6240\u4ee5\u6700\u7ec8\u7684\u6269\u5c55\u7ed3\u679c\u53ea\u80fd\u591f\u662f\u4e00\u4e2a\u7ebf\u6027\u7684\u7ed3\u6784\uff0c\u6240\u4ee5\u5b83\u662f linear grammar \u3002\u800cType-2 grammar\u7684production\u7684\u53f3\u4fa7\u53ef\u4ee5\u6709\u591a\u4e2anon-terminal\uff0c\u6240\u4ee5\u5728\u6309\u7167\u5b83\u7684production\u8fdb\u884crewrite\uff08\u6269\u5c55\uff09\u7684\u65f6\u5019\uff0c\u80fd\u591f\u5411\u591a\u4e2a\u65b9\u5411\u8fdb\u884c\u6269\u5c55\uff0c\u6240\u4ee5\u6700\u7ec8\u7684\u6269\u5c55\u7ed3\u679c\u662f\u4e00\u4e2a\u6811\u5f62\u7684\u7ed3\u6784\uff0c\u6240\u4ee5\u5b83\u4e0d\u662f linear grammar \u3002 NOTE: \u63cf\u8ff0\u7684\u7ed3\u6784 \u603b\u7ed3 # \u4e0a\u8ff0\u6240\u6709grammar\u7684production\u90fd\u53ef\u4ee5\u652f\u6301\u9012\u5f52\uff0c\u5373\u90fd\u53ef\u4ee5\u662f recursive grammar \u3002 NOTE: \u63cf\u8ff0\u7684\u9012\u5f52\u6027 \u5728 Recursively enumerable language \u4e2d\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff1a All regular , context-free , context-sensitive and recursive languages are recursively enumerable.","title":"Chomsky-hierarchy"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#chomsky-hierarchy","text":"In the formal languages of computer science and linguistics , the Chomsky hierarchy (occasionally referred to as the Chomsky\u2013Sch\u00fctzenberger hierarchy ) is a containment hierarchy of classes of formal grammars . This hierarchy of grammars was described by Noam Chomsky in 1956. It is also named after Marcel-Paul Sch\u00fctzenberger , who played a crucial role in the development of the theory of formal languages .","title":"Chomsky hierarchy"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#the-hierarchy","text":"The following table summarizes each of Chomsky's four types of grammars, the class of language it generates, the type of automaton that recognizes it, and the form its rules must have. Grammar Languages Automaton Production rules (constraints)* Examples Type-0 Recursively enumerable Turing machine $ \\alpha A\\beta \\rightarrow \\delta $ (no constraints) $ L={w Type-1 Context-sensitive Linear-bounded non-deterministic Turing machine $ \\alpha A\\beta \\rightarrow \\alpha \\gamma \\beta $ $ L={a^{n}b^{n}c^{n} Type-2 Context-free Non-deterministic pushdown automaton $ A\\rightarrow \\alpha $ $ L={a^{n}b^{n} Type-3 Regular Finite state automaton $ A\\rightarrow {\\text{a}} $ and $ A\\rightarrow {\\text{a}}B $ $ L={a^{n} Meaning of symbols: $ {\\text{a}} $ = terminal $ A $, $ B $ = non-terminal $ \\alpha $, $ \\beta $, $ \\gamma $, $ \\delta $ = string of terminals and/or non-terminals $ \\alpha $, $ \\beta $, $ \\delta $ = maybe empty $ \\gamma $ = never empty Set inclusions described by the Chomsky hierarchy Note that the set of grammars corresponding to recursive languages is not a member of this hierarchy; these would be properly between Type-0 and Type-1. Every regular language is context-free, every context-free language is context-sensitive, every context-sensitive language is recursive and every recursive language is recursively enumerable . These are all proper inclusions , meaning that there exist recursively enumerable languages that are not context-sensitive, context-sensitive languages that are not context-free and context-free languages that are not regular.","title":"The hierarchy"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#type-0-grammars","text":"Main article: Unrestricted grammar Type-0 grammars include all formal grammars. They generate exactly all languages that can be recognized by a Turing machine . These languages are also known as the recursively enumerable or Turing-recognizable languages. Note that this is different from the recursive languages , which can be decided by an always-halting Turing machine .","title":"Type-0 grammars"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#type-1-grammars","text":"Main article: Context-sensitive grammar Type-1 grammars generate context-sensitive languages . These grammars have rules of the form $ \\alpha A\\beta \\rightarrow \\alpha \\gamma \\beta $ with $ A $ a nonterminal and $ \\alpha $, $ \\beta $ and $ \\gamma $ strings of terminals and/or nonterminals. The strings $ \\alpha $ and $ \\beta $ may be empty, but $ \\gamma $ must be nonempty. The rule $ S\\rightarrow \\epsilon $ is allowed if $ S $ does not appear on the right side of any rule. The languages described by these grammars are exactly all languages that can be recognized by a linear bounded automaton (a nondeterministic Turing machine whose tape is bounded by a constant times the length of the input.)","title":"Type-1 grammars"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#type-2-grammars","text":"Main article: Context-free grammar Type-2 grammars generate the context-free languages . These are defined by rules of the form $ A\\rightarrow \\alpha $ with $ A $ being a nonterminal and $ \\alpha $ being a string of terminals and/or nonterminals. These languages are exactly all languages that can be recognized by a non-deterministic pushdown automaton . Context-free languages\u2014or rather its subset of deterministic context-free language \u2014are the theoretical basis for the phrase structure of most programming languages , though their syntax also includes context-sensitive name resolution due to declarations and scope . Often a subset of grammars is used to make parsing easier, such as by an LL parser .","title":"Type-2 grammars"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#type-3-grammars","text":"Main article: Regular grammar Type-3 grammars generate the regular languages . Such a grammar restricts its rules to a single nonterminal on the left-hand side and a right-hand side consisting of a single terminal, possibly followed by a single nonterminal (right regular). Alternatively, the right-hand side of the grammar can consist of a single terminal, possibly preceded by a single nonterminal (left regular). These generate the same languages. However, if left-regular rules and right-regular rules are combined, the language need no longer be regular. The rule $ S\\rightarrow \\epsilon $ is also allowed here if $ S $ does not appear on the right side of any rule. These languages are exactly all languages that can be decided by a finite state automaton . Additionally, this family of formal languages can be obtained by regular expressions . Regular languages are commonly used to define search patterns and the lexical structure of programming languages.","title":"Type-3 grammars"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#_1","text":"Type-0 grammars\u53c8\u53eb\u505a unrestricted grammar \uff0c\u4ece\u5b83\u7684\u540d\u5b57\u53ef\u4ee5\u770b\u51fa\uff0c\u5b83\u662funrestricted\u7684\uff0c\u5373 No restrictions are made on the productions of an unrestricted grammar \u90a3\u5176\u5b83grammar\uff08Type-1 grammars Context-sensitive grammar \u3001Type-2 grammars Context-free grammar \u3001Type-3 grammars Regular grammar \uff09\uff0c\u5bf9\u5404\u81ea\u7684production\u7684restriction\u662f\u4ec0\u4e48\u5462\uff1f\u4e0b\u9762\u4ece\u8fd9\u4e2a\u89d2\u5ea6\u5bf9\u8fd9\u51e0\u79cdgrammar\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\uff0c \u7531\u4e0a\u8ff0Chomsky hierarchy\u6240\u63cf\u8ff0\u7684\u5c42\u7ea7\u53ef\u4ee5\u770b\u51fa\uff0c\u4eceType 0 grammars\u5230Type 3 grammars\u9010\u7ea7\u589e\u52a0restriction\uff0c\u6240\u4ee5\u5728\u8fdb\u884c\u5bf9\u6bd4\u5206\u6790\u7684\u65f6\u5019\uff0c\u6bcf\u4e2agrammar\u53ea\u9700\u8981\u548c\u5b83\u7684\u5347\u4e00\u7ea7grammar\u8fdb\u884c\u5bf9\u6bd4\u5373\u53ef\u3002","title":"\u5bf9\u6bd4\u5206\u6790"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#type-0-grammarsunrestricted-grammar-formal-definition","text":"An unrestricted grammar is a formal grammar $ G=(N,\\Sigma ,P,S) $, where $ N $ is a set of nonterminal symbols, $ \\Sigma $ is a set of terminal symbols , $ N $ and $ \\Sigma $ are disjoint, $ P $ is a set of production rules of the form $ \\alpha \\to \\beta $ where $ \\alpha $ and $ \\beta $ are strings of symbols in $ N\\cup \\Sigma $ and $ \\alpha $ is not the empty string , and $ S\\in N $ is a specially designated start symbol. As the name implies, there are no real restrictions on the types of production rules that unrestricted grammars can have.","title":"Type-0 grammars:Unrestricted grammar formal definition"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#_2","text":"\u548c\u5176\u4ed6\u7684grammar production\u76f8\u6bd4\uff0c\u5b83\u7684unrestriction\u4f53\u73b0\u5728\uff1a $\\alpha$\u53ef\u4ee5\u4e3aterminal\u3001non-terminal $\\beta$\u53ef\u4ee5\u4e3aempty string","title":"\u5bf9\u6bd4\u5206\u6790"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#type-1-grammarscontext-sensitive-grammar-formal-definition","text":"A formal grammar G = ( N , \u03a3, P , S ), where N is a set of nonterminal symbols, \u03a3 is a set of terminal symbols, P is a set of production rules, and S is the start symbol , is context-sensitive if all rules in P are of the form \u03b1 A \u03b2 \u2192 \u03b1\u03b3\u03b2 where A \u2208 N , \u03b1,\u03b2 \u2208 ( N \u222a\u03a3) and \u03b3 \u2208 ( N*\u222a\u03a3)+. \u4e0a\u8ff0 * \u548c + \u90fd\u662f\u4f7f\u7528\u7684\u6b63\u5219\u8868\u8fbe\u5f0f\u7684\u6982\u5ff5\u3002","title":"Type-1 grammars:Context-sensitive grammar formal definition"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#_3","text":"\u548c unrestricted grammar production\u76f8\u6bd4\uff0c\u5b83\u7684restriction\u5728\u4e8e\uff1a \u03b3\u4e0d\u53ef\u4e3aempty string A\uff08\u5728\u4ea7\u751f\u5f0f\u7684\u5de6\u90e8\uff09\u5fc5\u987b\u662fnon-terminal \u4e0a\u8ff0\u4e24\u4e2arestriction\u5728Type-0 grammar\u4e2d\u90fd\u4e0d\u5b58\u5728\u3002","title":"\u5bf9\u6bd4\u5206\u6790"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#type-2-grammarscontext-free-grammar-formal-definitions","text":"A context-free grammar G is defined by the 4- tuple : $ G=(V,\\Sigma ,R,S) $ where V is a finite set; each element $ v\\in V $ is called a nonterminal character or a variable . Each variable represents a different type of phrase or clause in the sentence. Variables are also sometimes called syntactic categories. Each variable defines a sub-language of the language defined by G . \u03a3 is a finite set of terminal s, disjoint from V , which make up the actual content of the sentence. The set of terminals is the alphabet of the language defined by the grammar G . R is a finite relation from V to $ (V\\cup \\Sigma )^{ } $, where the asterisk represents the Kleene star operation. The members of R are called the (rewrite) rule s or production s of the grammar. (also commonly symbolized by a P*) NOTE: See also production rule rewriting S is the start variable (or start symbol), used to represent the whole sentence (or program). It must be an element of V .","title":"Type-2 grammars:Context-free grammar formal definitions"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#production-rule-notation","text":"A production rule in R is formalized mathematically as a pair $ (\\alpha ,\\beta )\\in R $, where $ \\alpha \\in V $ is a nonterminal and $ \\beta \\in (V\\cup \\Sigma )^{ } $ is a string of variables and/or terminals; rather than using ordered pair notation, production rules are usually written using an arrow operator with \u03b1 as its left hand side and \u03b2* as its right hand side: $ \\alpha \\rightarrow \\beta $. It is allowed for \u03b2 to be the empty string , and in this case it is customary to denote it by \u03b5. The form $ \\alpha \\rightarrow \\varepsilon $ is called an \u03b5 -production. It is common to list all right-hand sides for the same left-hand side on the same line, using | (the pipe symbol ) to separate them. Rules $ \\alpha \\rightarrow \\beta {1} $ and $ \\alpha \\rightarrow \\beta {2} $ can hence be written as $ \\alpha \\rightarrow \\beta {1}\\mid \\beta {2} $. In this case, $ \\beta {1} $ and $ \\beta {2} $ is called the first and second alternative, respectively.","title":"Production rule notation"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#rule-application","text":"For any strings $ u,v\\in (V\\cup \\Sigma )^{ } $, we say u directly yields v , written as $ u\\Rightarrow v\\, $, if $ \\exists (\\alpha ,\\beta )\\in R $ with $ \\alpha \\in V $ and $ u_{1},u_{2}\\in (V\\cup \\Sigma )^{ } $ such that $ u\\,=u_{1}\\alpha u_{2} $ and $ v\\,=u_{1}\\beta u_{2} $. Thus, v is a result of applying the rule $ (\\alpha ,\\beta ) $ to u .","title":"Rule application"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#repetitive-rule-application","text":"For any strings $ u,v\\in (V\\cup \\Sigma )^{ }, $ we say u yields v , written as $ u{\\stackrel { }{\\Rightarrow }}v $ (or $ u\\Rightarrow \\Rightarrow v\\, $ in some textbooks), if $ \\exists k\\geq 1\\,\\exists \\,u_{1},\\cdots ,u_{k}\\in (V\\cup \\Sigma )^{ } $ such that $ u=\\,u_{1}\\Rightarrow u_{2}\\Rightarrow \\cdots \\Rightarrow u_{k}\\,=v $. In this case, if $ k\\geq 2 $ (i.e., $ u\\neq v $), the relation $ u{\\stackrel {+}{\\Rightarrow }}v $ holds. In other words, $ ({\\stackrel { }{\\Rightarrow }}) $ and $ ({\\stackrel {+}{\\Rightarrow }}) $ are the reflexive transitive closure (allowing a word to yield itself) and the transitive closure (requiring at least one step) of $ (\\Rightarrow ) $, respectively.","title":"Repetitive rule application"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#context-free-language","text":"The language of a grammar $ G=(V,\\Sigma ,R,S) $ is the set $ L(G)={w\\in \\Sigma ^{ }:S{\\stackrel { }{\\Rightarrow }}w} $ A language L is said to be a context-free language (CFL), if there exists a CFG G , such that $ L\\,=\\,L(G) $. Non-deterministic pushdown automata recognize exactly the context-free languages.","title":"Context-free language"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#_4","text":"Context-free grammar \u7684restriction\u5728\u4e8e The left-hand side of the production rule is always a nonterminal symbol. This means that the symbol does not appear in the resulting formal language. \u5728type 1 grammar\u4e2d\uff0c\u5bf9\u4ea7\u751f\u5f0f\u7684\u5de6\u90e8\u4e2d nonterminal symbol\u7684\u4e2a\u6570\u5e76\u6ca1\u6709\u9650\u5236\u3002","title":"\u5bf9\u6bd4\u5206\u6790"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#type-3-grammarsregular-grammar-formal-definition","text":"A right regular grammar (also called right linear grammar ) is a formal grammar ( N , \u03a3, P , S ) such that all the production rules in P are of one of the following forms: A \u2192 a , where A is a non-terminal in N and a is a terminal in \u03a3 A \u2192 aB , where A and B are non-terminals in N and a is in \u03a3 A \u2192 \u03b5, where A is in N and \u03b5 denotes the empty string , i.e. the string of length 0. In a left regular grammar (also called left linear grammar ), all rules obey the forms A \u2192 a , where A is a non-terminal in N and a is a terminal in \u03a3 A \u2192 Ba , where A and B are in N and a is in \u03a3 A \u2192 \u03b5, where A is in N and \u03b5 is the empty string. A regular grammar is a left or right regular grammar. Some textbooks and articles disallow empty production rules, and assume that the empty string is not present in languages.","title":"Type-3 grammars:Regular grammar formal definition"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#_5","text":"\u4e0eType-2 grammars\u76f8\u6bd4\uff0cType-3 grammars\u7684\u9650\u5236\u5728\u4e8e\u4ea7\u751f\u5f0f\u53f3\u4fa7\u7684non-terminal\uff1a \u4ea7\u751f\u5f0f\u7684\u53f3\u4fa7\u6700\u591a\u53ea\u80fd\u591f\u6709\u4e00\u4e2anon-terminal \u4ea7\u751f\u5f0f\u53f3\u4fa7\u7684non-terminal\u53ea\u80fd\u591f\u5728\u6700\u5de6\u4fa7\u6216\u6700\u53f3\u4fa7 \u663e\u7136\uff0c\u4e0eType-2 grammars\u76f8\u6bd4\uff0c\u7531\u4e8eType-3 grammar\u7684production\u7684\u53f3\u4fa7\u53ea\u80fd\u591f\u6709\u4e00\u4e2anon-terminal\uff0c\u6240\u4ee5\u5728\u6309\u7167\u5b83\u7684production\u8fdb\u884crewrite\uff08\u6269\u5c55\uff09\u7684\u65f6\u5019\uff0c\u53ea\u80fd\u591f\u5411\u4e00\u4e2a\u65b9\u5411\u8fdb\u884c\u6269\u5c55\uff0c\u6240\u4ee5\u6700\u7ec8\u7684\u6269\u5c55\u7ed3\u679c\u53ea\u80fd\u591f\u662f\u4e00\u4e2a\u7ebf\u6027\u7684\u7ed3\u6784\uff0c\u6240\u4ee5\u5b83\u662f linear grammar \u3002\u800cType-2 grammar\u7684production\u7684\u53f3\u4fa7\u53ef\u4ee5\u6709\u591a\u4e2anon-terminal\uff0c\u6240\u4ee5\u5728\u6309\u7167\u5b83\u7684production\u8fdb\u884crewrite\uff08\u6269\u5c55\uff09\u7684\u65f6\u5019\uff0c\u80fd\u591f\u5411\u591a\u4e2a\u65b9\u5411\u8fdb\u884c\u6269\u5c55\uff0c\u6240\u4ee5\u6700\u7ec8\u7684\u6269\u5c55\u7ed3\u679c\u662f\u4e00\u4e2a\u6811\u5f62\u7684\u7ed3\u6784\uff0c\u6240\u4ee5\u5b83\u4e0d\u662f linear grammar \u3002 NOTE: \u63cf\u8ff0\u7684\u7ed3\u6784","title":"\u5bf9\u6bd4\u5206\u6790"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/wikipedia-Chomsky-hierarchy/#_6","text":"\u4e0a\u8ff0\u6240\u6709grammar\u7684production\u90fd\u53ef\u4ee5\u652f\u6301\u9012\u5f52\uff0c\u5373\u90fd\u53ef\u4ee5\u662f recursive grammar \u3002 NOTE: \u63cf\u8ff0\u7684\u9012\u5f52\u6027 \u5728 Recursively enumerable language \u4e2d\u6709\u8fd9\u6837\u7684\u63cf\u8ff0\uff1a All regular , context-free , context-sensitive and recursive languages are recursively enumerable.","title":"\u603b\u7ed3"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/wikipedia-Recursively-enumerable-language/","text":"Recursively enumerable language # Unrestricted grammar # In automata theory , the class of unrestricted grammars (also called semi-Thue , type-0 or phrase structure grammars ) is the most general class of grammars in the Chomsky hierarchy . No restrictions are made on the productions of an unrestricted grammar, other than each of their left-hand sides being non-empty. This grammar class can generate arbitrary recursively enumerable languages . Formal definition # An unrestricted grammar is a formal grammar $ G=(N,\\Sigma ,P,S) $, where $ N $ is a set of nonterminal symbols, $ \\Sigma $ is a set of terminal symbols , $ N $ and $ \\Sigma $ are disjoint, $ P $ is a set of production rules of the form $ \\alpha \\to \\beta $ where $ \\alpha $ and $ \\beta $ are strings of symbols in $ N\\cup \\Sigma $ and $ \\alpha $ is not the empty string, and $ S\\in N $ is a specially designated start symbol. As the name implies, there are no real restrictions on the types of production rules that unrestricted grammars can have. Semi-Thue system # In theoretical computer science and mathematical logic a string rewriting system ( SRS ), historically called a semi- Thue system , is a rewriting system over strings from a (usually finite ) alphabet . Given a binary relation $ R $ between fixed strings over the alphabet, called rewrite rules , denoted by $ s\\rightarrow t $, an SRS extends the rewriting relation to all strings in which the left- and right-hand side of the rules appear as substrings , that is $ usv\\rightarrow utv $, where $ s $, $ t $, $ u $, and $ v $ are strings.","title":"Recursively-enumerable-language"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/wikipedia-Recursively-enumerable-language/#recursively-enumerable-language","text":"","title":"Recursively enumerable language"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/wikipedia-Recursively-enumerable-language/#unrestricted-grammar","text":"In automata theory , the class of unrestricted grammars (also called semi-Thue , type-0 or phrase structure grammars ) is the most general class of grammars in the Chomsky hierarchy . No restrictions are made on the productions of an unrestricted grammar, other than each of their left-hand sides being non-empty. This grammar class can generate arbitrary recursively enumerable languages .","title":"Unrestricted grammar"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/wikipedia-Recursively-enumerable-language/#formal-definition","text":"An unrestricted grammar is a formal grammar $ G=(N,\\Sigma ,P,S) $, where $ N $ is a set of nonterminal symbols, $ \\Sigma $ is a set of terminal symbols , $ N $ and $ \\Sigma $ are disjoint, $ P $ is a set of production rules of the form $ \\alpha \\to \\beta $ where $ \\alpha $ and $ \\beta $ are strings of symbols in $ N\\cup \\Sigma $ and $ \\alpha $ is not the empty string, and $ S\\in N $ is a specially designated start symbol. As the name implies, there are no real restrictions on the types of production rules that unrestricted grammars can have.","title":"Formal definition"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/wikipedia-Recursively-enumerable-language/#semi-thue-system","text":"In theoretical computer science and mathematical logic a string rewriting system ( SRS ), historically called a semi- Thue system , is a rewriting system over strings from a (usually finite ) alphabet . Given a binary relation $ R $ between fixed strings over the alphabet, called rewrite rules , denoted by $ s\\rightarrow t $, an SRS extends the rewriting relation to all strings in which the left- and right-hand side of the rules appear as substrings , that is $ usv\\rightarrow utv $, where $ s $, $ t $, $ u $, and $ v $ are strings.","title":"Semi-Thue system"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/","text":"Turing machine\u975e\u5e38\u91cd\u8981\uff0c\u5bf9\u4e8e\u4e00\u4e2asoftware engineer\uff0c\u6709\u5fc5\u8981\u4e86\u89e3\u4e00\u4e0b\u5b83\u3002 \u7ef4\u57fa\u767e\u79d1\u4e2d\u5173\u4e8e Turing machine \u7684\u4ecb\u7ecd\u975e\u5e38\u5197\u957f\uff0c\u521d\u8bfb\u8d77\u6765\u4f1a\u6bd4\u8f83\u8d39\u52b2\uff0c\u6240\u4ee5\u627e\u4e86\u4e00\u4e9b\u5176\u4ed6\u7684\u76f8\u5bf9\u7cbe\u7b80\u4e00\u4e9b\u7684\u6587\u7ae0\uff0c\u4e0b\u9762\u7f57\u5217\u4e86\u6211\u89c9\u5f97\u6bd4\u8f83\u597d\u7684\u9605\u8bfb\u987a\u5e8f\uff1a What is a Turing machine? Turing machine Turing machine","title":"Introduction"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/Turing-machine/","text":"Turing machine # The Turing machine is a computer device which consists of a read and write header , what we know best today as a scanner and a paper ribbon that passes through the machine. This tape was divided into squares , and each of them had a symbol at the same time. It was responsible for the storage of the machine and was a kind of vehicle for entry and exit , as well as working memory to store the results of the intermediate steps of the calculation. What is the Turing machine? # It is a more general language recognition module that any Finite and Stack automaton has, as it has the ability to recognize regular and context- independent languages, as well as many other types of languages. Features of Turing Machine # The main features of the Turing machine were as follows: The input that the tape has before the calculation begins, must consist of a finite number of symbols. The machine tape has an unlimited length. The read/write head can be programmable. The Turing machine is capable of doing six types of fundamental operations: read, write, move left, move right, change state and stop. It has the ability to compute anything any modern computer can calculate. It consists of an input and output alphabet and a special symbol called white. History of Turing machine # Alan Mathison Turing was the inventor of the Turing machine. He was known as an extremely talented man, who had great influences on the development of computing and on the formalization of the concept of algorithm and computation through his Turing machine, which played a very important role in the creation of the modern computer. Turing described it for the first time in his 1936 article dealing with issues concerning computable numbers . In his article, Turing imagines that his creation is not a mechanical machine, but rather a person he decided to call a computer, which carelessly executes these deterministic mechanical rules.","title":"Turing-machine"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/Turing-machine/#turing-machine","text":"The Turing machine is a computer device which consists of a read and write header , what we know best today as a scanner and a paper ribbon that passes through the machine. This tape was divided into squares , and each of them had a symbol at the same time. It was responsible for the storage of the machine and was a kind of vehicle for entry and exit , as well as working memory to store the results of the intermediate steps of the calculation.","title":"Turing machine"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/Turing-machine/#what-is-the-turing-machine","text":"It is a more general language recognition module that any Finite and Stack automaton has, as it has the ability to recognize regular and context- independent languages, as well as many other types of languages.","title":"What is the Turing machine?"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/Turing-machine/#features-of-turing-machine","text":"The main features of the Turing machine were as follows: The input that the tape has before the calculation begins, must consist of a finite number of symbols. The machine tape has an unlimited length. The read/write head can be programmable. The Turing machine is capable of doing six types of fundamental operations: read, write, move left, move right, change state and stop. It has the ability to compute anything any modern computer can calculate. It consists of an input and output alphabet and a special symbol called white.","title":"Features of Turing Machine"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/Turing-machine/#history-of-turing-machine","text":"Alan Mathison Turing was the inventor of the Turing machine. He was known as an extremely talented man, who had great influences on the development of computing and on the formalization of the concept of algorithm and computation through his Turing machine, which played a very important role in the creation of the modern computer. Turing described it for the first time in his 1936 article dealing with issues concerning computable numbers . In his article, Turing imagines that his creation is not a mechanical machine, but rather a person he decided to call a computer, which carelessly executes these deterministic mechanical rules.","title":"History of Turing machine"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/What-is-a-Turing-machine/","text":"What is a Turing machine? # A Turing machine is a hypothetical machine thought of by the mathematician Alan Turing in 1936. Despite its simplicity, the machine can simulate ANY computer algorithm, no matter how complicated it is! Above is a very simple representation of a Turing machine . It consists of an infinitely-long tape which acts like the memory in a typical computer, or any other form of data storage. The squares on the tape are usually blank at the start and can be written with symbols. In this case, the machine can only process the symbols 0 and 1 and \" \" (blank), and is thus said to be a 3-symbol Turing machine . At any one time, the machine has a head which is positioned over one of the squares on the tape. With this head , the machine can perform three very basic operations: Read the symbol on the square under the head( read ). Edit the symbol by writing a new symbol or erasing it( write ). Move the tape left of right by one square so that the machine can read and edit the symbol on a neighbouring square( move ). NOTE: \u5728\u4efb\u4f55\u65f6\u523b\uff0chead\u53ea\u80fd\u591f\u7f6e\u4e8etape\u7684\u4f17\u591asquare\u4e2d\u7684\u4e00\u4e2asquare\u4e4b\u4e0a A simple demonstration # As a trivial example to demonstrate these operations, let's try printing the symbols \" 1 1 0 \" on an initially blank tape: First, we write a 1 on the square under the head: Next, we move the tape left by one square: Now, write a 1 on the new square under the head: We then move the tape left by one square again: Finally, write a 0 and that's it! A simple program # With the symbols \" 1 1 0 \" printed on the tape, let's attempt to convert the 1 s to 0 s and vice versa. This is called bit inversion , since 1 s and 0 s are bits in binary. This can be done by passing the following instructions to the Turing machine , utilising the machine's reading capabilities to decide its subsequent operations on its own. These instructions make up a simple program. Symbol read Write instruction Move instruction Blank None None 0 Write 1 Move tape to the right 1 Write 0 Move tape to the right The machine will first read the symbol under the head, write a new symbol accordingly, then move the tape left or right as instructed, before repeating the read-write-move sequence again. Let's see what this program does to our tape from the previous end point of the instructions: The current symbol under the head is 0 , so we write a 1 and move the tape right by one square. The symbol being read is now 1, so we write a 0 and move the tape right by one square: Similarly, the symbol read is a 1 , so we repeat the same instructions. Finally, a 'blank' symbol is read, so the machine does nothing apart from read the blank symbol continuously since we have instructed it to repeat the read-write-move sequence without stopping. In fact, the program is incomplete . How does the machine repeat the sequence endlessly, and how does the machine stop running the program? The program tells it to with the concept of a machine state . The machine state # To complete the program, the state changes during the execution of the program on the machine must be considered. The following changes, marked in italics , must be added to our table which can now be called a state table : State Symbol read Write instruction Move instruction Next state State 0 Blank None None Stop state 0 Write 1 Move the tape to the right State 0 1 Write 0 Move the tape to the right State 0 We allocate the previous set of instructions to a machine state , so that the machine will perform those instructions when it is in the specified state. After every instruction, we also specify a state for the machine to transition to. In the example, the machine is redirected back to its original state, State 0 , to repeat the read-write-move sequence , unless a blank symbol is read. When the machine reads a blank symbol, the machine is directed to a stop state and the program terminates. NOTE: machine state\u76f8\u5f53\u4e8elabel\uff0ctransition to a machine state\u76f8\u5f53\u4e8e goto label Finite state machines # Even though it seems silly to do so, let's now add an additional state to our program that reverts the already inverted bits \" 1 1 0 \" back from \" 0 0 1 \" to \" 1 1 0 \". Below is the updated table, with changes listed in italics . The Turing machine now acts like a finite state machine with two states\u2014these are called three-symbol, two-state Turing machines. State Symbol read Write instruction Move instruction Next state State 0 Blank Write blank Move the tape to the left State 1 0 Write 1 Move the tape to the right State 0 1 Write 0 Move the tape to the right State 0 State 1 Blank Write blank Move the tape to the right Stop state 0 Write 1 Move the tape to the left State 1 1 Write 0 Move the tape to the left State 1 For the write instruction, \"None\" has been changed to \"Write blank\" for uniformity's sake (so that only the machine's symbols are referred to), and it should be noted that they are equivalent. Instead of a state table, the program can also be represented with a state diagram: From where the program was previously, instead of doing nothing and stopping after the machine encounters a blank symbol, we instruct it to move the tape left before transitioning to State 1 where it reverses the bit inversion process. Next, we invert the bits again, this time moving the tape left instead of right. Finally, a blank symbol is read, so we move the tape right to get back to where we started, and stop the program. With the introduction of more states to our program, we can instruct the Turing machine to perform more complex functions and hence run any algorithm that a modern day computer can.","title":"What-is-a-Turing-machine"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/What-is-a-Turing-machine/#what-is-a-turing-machine","text":"A Turing machine is a hypothetical machine thought of by the mathematician Alan Turing in 1936. Despite its simplicity, the machine can simulate ANY computer algorithm, no matter how complicated it is! Above is a very simple representation of a Turing machine . It consists of an infinitely-long tape which acts like the memory in a typical computer, or any other form of data storage. The squares on the tape are usually blank at the start and can be written with symbols. In this case, the machine can only process the symbols 0 and 1 and \" \" (blank), and is thus said to be a 3-symbol Turing machine . At any one time, the machine has a head which is positioned over one of the squares on the tape. With this head , the machine can perform three very basic operations: Read the symbol on the square under the head( read ). Edit the symbol by writing a new symbol or erasing it( write ). Move the tape left of right by one square so that the machine can read and edit the symbol on a neighbouring square( move ). NOTE: \u5728\u4efb\u4f55\u65f6\u523b\uff0chead\u53ea\u80fd\u591f\u7f6e\u4e8etape\u7684\u4f17\u591asquare\u4e2d\u7684\u4e00\u4e2asquare\u4e4b\u4e0a","title":"What is a Turing machine?"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/What-is-a-Turing-machine/#a-simple-demonstration","text":"As a trivial example to demonstrate these operations, let's try printing the symbols \" 1 1 0 \" on an initially blank tape: First, we write a 1 on the square under the head: Next, we move the tape left by one square: Now, write a 1 on the new square under the head: We then move the tape left by one square again: Finally, write a 0 and that's it!","title":"A simple demonstration"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/What-is-a-Turing-machine/#a-simple-program","text":"With the symbols \" 1 1 0 \" printed on the tape, let's attempt to convert the 1 s to 0 s and vice versa. This is called bit inversion , since 1 s and 0 s are bits in binary. This can be done by passing the following instructions to the Turing machine , utilising the machine's reading capabilities to decide its subsequent operations on its own. These instructions make up a simple program. Symbol read Write instruction Move instruction Blank None None 0 Write 1 Move tape to the right 1 Write 0 Move tape to the right The machine will first read the symbol under the head, write a new symbol accordingly, then move the tape left or right as instructed, before repeating the read-write-move sequence again. Let's see what this program does to our tape from the previous end point of the instructions: The current symbol under the head is 0 , so we write a 1 and move the tape right by one square. The symbol being read is now 1, so we write a 0 and move the tape right by one square: Similarly, the symbol read is a 1 , so we repeat the same instructions. Finally, a 'blank' symbol is read, so the machine does nothing apart from read the blank symbol continuously since we have instructed it to repeat the read-write-move sequence without stopping. In fact, the program is incomplete . How does the machine repeat the sequence endlessly, and how does the machine stop running the program? The program tells it to with the concept of a machine state .","title":"A simple program"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/What-is-a-Turing-machine/#the-machine-state","text":"To complete the program, the state changes during the execution of the program on the machine must be considered. The following changes, marked in italics , must be added to our table which can now be called a state table : State Symbol read Write instruction Move instruction Next state State 0 Blank None None Stop state 0 Write 1 Move the tape to the right State 0 1 Write 0 Move the tape to the right State 0 We allocate the previous set of instructions to a machine state , so that the machine will perform those instructions when it is in the specified state. After every instruction, we also specify a state for the machine to transition to. In the example, the machine is redirected back to its original state, State 0 , to repeat the read-write-move sequence , unless a blank symbol is read. When the machine reads a blank symbol, the machine is directed to a stop state and the program terminates. NOTE: machine state\u76f8\u5f53\u4e8elabel\uff0ctransition to a machine state\u76f8\u5f53\u4e8e goto label","title":"The machine state"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/What-is-a-Turing-machine/#finite-state-machines","text":"Even though it seems silly to do so, let's now add an additional state to our program that reverts the already inverted bits \" 1 1 0 \" back from \" 0 0 1 \" to \" 1 1 0 \". Below is the updated table, with changes listed in italics . The Turing machine now acts like a finite state machine with two states\u2014these are called three-symbol, two-state Turing machines. State Symbol read Write instruction Move instruction Next state State 0 Blank Write blank Move the tape to the left State 1 0 Write 1 Move the tape to the right State 0 1 Write 0 Move the tape to the right State 0 State 1 Blank Write blank Move the tape to the right Stop state 0 Write 1 Move the tape to the left State 1 1 Write 0 Move the tape to the left State 1 For the write instruction, \"None\" has been changed to \"Write blank\" for uniformity's sake (so that only the machine's symbols are referred to), and it should be noted that they are equivalent. Instead of a state table, the program can also be represented with a state diagram: From where the program was previously, instead of doing nothing and stopping after the machine encounters a blank symbol, we instruct it to move the tape left before transitioning to State 1 where it reverses the bit inversion process. Next, we invert the bits again, this time moving the tape left instead of right. Finally, a blank symbol is read, so we move the tape right to get back to where we started, and stop the program. With the introduction of more states to our program, we can instruct the Turing machine to perform more complex functions and hence run any algorithm that a modern day computer can.","title":"Finite state machines"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/wikipedia-Turing-machine/","text":"Turing machine # A Turing machine is a mathematical model of computation that defines an abstract machine , which manipulates symbols on a strip of tape according to a table of rules . Despite the model's simplicity, given any computer algorithm , a Turing machine capable of simulating that algorithm's logic can be constructed. The machine operates on an infinite memory tape divided into discrete \"cells\". The machine positions its \"head\" over a cell and \"reads\" or \"scans\" the symbol there. Then, as per the symbol and its present place in a \"finite table\" of user-specified instructions, the machine (i) writes a symbol (e.g., a digit or a letter from a finite alphabet) in the cell (some models allow symbol erasure or no writing), then (ii) either moves the tape one cell left or right (some models allow no motion, some models move the head), then (iii) (as determined by the observed symbol and the machine's place in the table) either proceeds to a subsequent instruction or halts the computation. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u5df2\u7ecf\u603b\u7ed3\u4e86Turing machine\u7684\u7ec4\u6210\u548c\u8fd0\u884c\u673a\u5236 The Turing machine was invented in 1936 by Alan Turing . With this model, Turing was able to answer two questions in the negative: (1) Does a machine exist that can determine whether any arbitrary machine on its tape is \"circular\" (e.g., freezes, or fails to continue its computational task) (2) does a machine exist that can determine whether any arbitrary machine on its tape ever prints a given symbol Note: \u4e0a\u9762\u4e24\u53e5\u4e2d\uff0cthat\u5f15\u5bfc\u7684\u5b9a\u4ece\u662f\u4fee\u9970machine\u7684 Thus by providing a mathematical description of a very simple device capable of arbitrary computations, he was able to prove properties of computation in general\u2014and in particular, the uncomputability of the Entscheidungsproblem ('decision problem'). NOTE: \u5173\u4e8eTuring\u63d0\u53ca\u7684\u4e24\u4e2a\u95ee\u9898\uff0c\u5e76\u6ca1\u6709\u641e\u6e05\u695a\u8fd9\u4e9b\u95ee\u9898\u5230\u5e95\u662f\u4ec0\u4e48\u3002 Thus, Turing machines prove fundamental limitations on the power of mechanical computation . While they can express arbitrary computations, their minimalist design makes them unsuitable for computation in practice: real-world computers are based on different designs that, unlike Turing machines, use random-access memory . NOTE: \u4e0a\u9762\u7684\u4e00\u6bb5\u8bdd\u5176\u5b9e\u8bf4\u660e\u4e86Turing machine\u7684\u4ef7\u503c\u6240\u5728\uff1a\u7406\u8bba\u4e0a\u8bc1\u660e mechanical computation \u7684\u9650\u5236\u6240\u5728\uff0c\u8fd9\u5bf9\u4e8e\u901a\u7528\u8ba1\u7b97\u673a\u7684\u8bde\u751f\u662f\u5177\u6709\u975e\u5e38\u91cd\u8981\u7684\u610f\u4e49\u7684\u3002 NOTE: \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u867d\u7136real-world computers \u6ca1\u6709\u91c7\u7eb3Turing machine\u7684\u8bbe\u8ba1\uff0c\u4f46\u662fTuring machine\u542f\u53d1\u4e86real-world computers \u7684\u8bbe\u8ba1\u3002\u4e00\u4e2areal-world computers \uff0c\u5e94\u8be5\u80fd\u591f\u63d0\u4f9b\u548cTuring machine\u76f8\u540c\u7684 power of mechanical computation \u3002\u5173\u4e8eTuring machine\u548c\u73b0\u4ee3computer\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u53ef\u4ee5\u53c2\u770b\u4e0b\u9762\u7684overview\u7ae0\u8282\uff0c\u5f53\u7136\u5728\u5b66\u4e60\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u7684\u65f6\u5019\uff0c\u8fd8\u662f\u4f1a\u8ba8\u8bbaTuring machine\u548c Von Neumann architecture \u3001 stored-program computer \u3002 \u9664\u6b64\u4e4b\u5916\uff0cTuring machine theory of computation Turing completeness is the ability for a system of instructions to simulate a Turing machine. A programming language that is Turing complete is theoretically capable of expressing all tasks accomplishable by computers; nearly all programming languages are Turing complete if the limitations of finite memory are ignored. Classes of automata Overview # A Turing machine is a general example of a central processing unit (CPU) that controls all data manipulation done by a computer, with the canonical machine using sequential memory to store data. More specifically, it is a machine ( automaton ) capable of enumerating some arbitrary subset of valid strings of an alphabet ; these strings are part of a recursively enumerable set . A Turing machine has a tape of infinite length on which it can perform read and write operations. Assuming a black box , the Turing machine cannot know whether it will eventually enumerate any one specific string of the subset with a given program. This is due to the fact that the halting problem is unsolvable, which has major implications for the theoretical limits of computing. The Turing machine is capable of processing an unrestricted grammar , which further implies that it is capable of robustly evaluating first-order logic in an infinite number of ways. This is famously demonstrated through lambda calculus . A Turing machine that is able to simulate any other Turing machine is called a universal Turing machine (UTM, or simply a universal machine). A more mathematically oriented definition with a similar \"universal\" nature was introduced by Alonzo Church , whose work on lambda calculus intertwined with Turing's in a formal theory of computation known as the Church\u2013Turing thesis . The thesis states that Turing machines indeed capture the informal notion of effective methods in logic and mathematics , and provide a precise definition of an algorithm or \"mechanical procedure\". Studying their abstract properties yields many insights into computer science and complexity theory . NOTE: lambda calculus \u4e0d\u7406\u89e3 visualizations of Turing machines # see Turing machine gallery . Description #","title":"wikipedia-Turing-machine"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/wikipedia-Turing-machine/#turing-machine","text":"A Turing machine is a mathematical model of computation that defines an abstract machine , which manipulates symbols on a strip of tape according to a table of rules . Despite the model's simplicity, given any computer algorithm , a Turing machine capable of simulating that algorithm's logic can be constructed. The machine operates on an infinite memory tape divided into discrete \"cells\". The machine positions its \"head\" over a cell and \"reads\" or \"scans\" the symbol there. Then, as per the symbol and its present place in a \"finite table\" of user-specified instructions, the machine (i) writes a symbol (e.g., a digit or a letter from a finite alphabet) in the cell (some models allow symbol erasure or no writing), then (ii) either moves the tape one cell left or right (some models allow no motion, some models move the head), then (iii) (as determined by the observed symbol and the machine's place in the table) either proceeds to a subsequent instruction or halts the computation. NOTE: \u4e0a\u9762\u8fd9\u6bb5\u8bdd\u5df2\u7ecf\u603b\u7ed3\u4e86Turing machine\u7684\u7ec4\u6210\u548c\u8fd0\u884c\u673a\u5236 The Turing machine was invented in 1936 by Alan Turing . With this model, Turing was able to answer two questions in the negative: (1) Does a machine exist that can determine whether any arbitrary machine on its tape is \"circular\" (e.g., freezes, or fails to continue its computational task) (2) does a machine exist that can determine whether any arbitrary machine on its tape ever prints a given symbol Note: \u4e0a\u9762\u4e24\u53e5\u4e2d\uff0cthat\u5f15\u5bfc\u7684\u5b9a\u4ece\u662f\u4fee\u9970machine\u7684 Thus by providing a mathematical description of a very simple device capable of arbitrary computations, he was able to prove properties of computation in general\u2014and in particular, the uncomputability of the Entscheidungsproblem ('decision problem'). NOTE: \u5173\u4e8eTuring\u63d0\u53ca\u7684\u4e24\u4e2a\u95ee\u9898\uff0c\u5e76\u6ca1\u6709\u641e\u6e05\u695a\u8fd9\u4e9b\u95ee\u9898\u5230\u5e95\u662f\u4ec0\u4e48\u3002 Thus, Turing machines prove fundamental limitations on the power of mechanical computation . While they can express arbitrary computations, their minimalist design makes them unsuitable for computation in practice: real-world computers are based on different designs that, unlike Turing machines, use random-access memory . NOTE: \u4e0a\u9762\u7684\u4e00\u6bb5\u8bdd\u5176\u5b9e\u8bf4\u660e\u4e86Turing machine\u7684\u4ef7\u503c\u6240\u5728\uff1a\u7406\u8bba\u4e0a\u8bc1\u660e mechanical computation \u7684\u9650\u5236\u6240\u5728\uff0c\u8fd9\u5bf9\u4e8e\u901a\u7528\u8ba1\u7b97\u673a\u7684\u8bde\u751f\u662f\u5177\u6709\u975e\u5e38\u91cd\u8981\u7684\u610f\u4e49\u7684\u3002 NOTE: \u9700\u8981\u6ce8\u610f\u7684\u662f\uff0c\u867d\u7136real-world computers \u6ca1\u6709\u91c7\u7eb3Turing machine\u7684\u8bbe\u8ba1\uff0c\u4f46\u662fTuring machine\u542f\u53d1\u4e86real-world computers \u7684\u8bbe\u8ba1\u3002\u4e00\u4e2areal-world computers \uff0c\u5e94\u8be5\u80fd\u591f\u63d0\u4f9b\u548cTuring machine\u76f8\u540c\u7684 power of mechanical computation \u3002\u5173\u4e8eTuring machine\u548c\u73b0\u4ee3computer\u4e4b\u95f4\u7684\u5173\u8054\uff0c\u53ef\u4ee5\u53c2\u770b\u4e0b\u9762\u7684overview\u7ae0\u8282\uff0c\u5f53\u7136\u5728\u5b66\u4e60\u8ba1\u7b97\u673a\u7ec4\u6210\u539f\u7406\u7684\u65f6\u5019\uff0c\u8fd8\u662f\u4f1a\u8ba8\u8bbaTuring machine\u548c Von Neumann architecture \u3001 stored-program computer \u3002 \u9664\u6b64\u4e4b\u5916\uff0cTuring machine theory of computation Turing completeness is the ability for a system of instructions to simulate a Turing machine. A programming language that is Turing complete is theoretically capable of expressing all tasks accomplishable by computers; nearly all programming languages are Turing complete if the limitations of finite memory are ignored. Classes of automata","title":"Turing machine"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/wikipedia-Turing-machine/#overview","text":"A Turing machine is a general example of a central processing unit (CPU) that controls all data manipulation done by a computer, with the canonical machine using sequential memory to store data. More specifically, it is a machine ( automaton ) capable of enumerating some arbitrary subset of valid strings of an alphabet ; these strings are part of a recursively enumerable set . A Turing machine has a tape of infinite length on which it can perform read and write operations. Assuming a black box , the Turing machine cannot know whether it will eventually enumerate any one specific string of the subset with a given program. This is due to the fact that the halting problem is unsolvable, which has major implications for the theoretical limits of computing. The Turing machine is capable of processing an unrestricted grammar , which further implies that it is capable of robustly evaluating first-order logic in an infinite number of ways. This is famously demonstrated through lambda calculus . A Turing machine that is able to simulate any other Turing machine is called a universal Turing machine (UTM, or simply a universal machine). A more mathematically oriented definition with a similar \"universal\" nature was introduced by Alonzo Church , whose work on lambda calculus intertwined with Turing's in a formal theory of computation known as the Church\u2013Turing thesis . The thesis states that Turing machines indeed capture the informal notion of effective methods in logic and mathematics , and provide a precise definition of an algorithm or \"mechanical procedure\". Studying their abstract properties yields many insights into computer science and complexity theory . NOTE: lambda calculus \u4e0d\u7406\u89e3","title":"Overview"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/wikipedia-Turing-machine/#visualizations-of-turing-machines","text":"see Turing machine gallery .","title":"visualizations of Turing machines"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-0/Turinig-machine/wikipedia-Turing-machine/#description","text":"","title":"Description"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-1/wikipedia-Context-sensitive-language/","text":"Context-sensitive language # Context-sensitive grammar #","title":"Context-sensitive-language"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-1/wikipedia-Context-sensitive-language/#context-sensitive-language","text":"","title":"Context-sensitive language"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-1/wikipedia-Context-sensitive-language/#context-sensitive-grammar","text":"","title":"Context-sensitive grammar"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-2/Automaton/","text":"Pushdown automaton Informal description Deterministic pushdown automaton Pushdown automaton # In the theory of computation , a branch of theoretical computer science , a pushdown automaton ( PDA ) is a type of automaton that employs a stack . Pushdown automata are used in theories about what can be computed by machines. They are more capable than finite-state machines but less capable than Turing machines . Deterministic pushdown automata can recognize all deterministic context-free languages while nondeterministic ones can recognize all context-free languages , with the former often used in parser design. The term \"pushdown\" refers to the fact that the stack can be regarded as being \"pushed down\" like a tray dispenser at a cafeteria, since the operations never work on elements other than the top element. A stack automaton , by contrast, does allow access to and operations on deeper elements. Stack automata can recognize a strictly larger set of languages than pushdown automata.[ 1] A nested stack automaton allows full access, and also allows stacked values to be entire sub-stacks rather than just single finite symbols. Informal description # A finite state machine just looks at the input signal and the current state : it has no stack to work with. It chooses a new state, the result of following the transition. A pushdown automaton (PDA) differs from a finite state machine in two ways: It can use the top of the stack to decide which transition to take. It can manipulate the stack as part of performing a transition. A pushdown automaton reads a given input string from left to right. In each step, it chooses a transition by indexing a table by input symbol, current state, and the symbol at the top of the stack. A pushdown automaton can also manipulate the stack, as part of performing a transition. The manipulation can be to push a particular symbol to the top of the stack, or to pop off the top of the stack. The automaton can alternatively ignore the stack, and leave it as it is. Put together: Given an input symbol, current state, and stack symbol, the automaton can follow a transition to another state, and optionally manipulate (push or pop) the stack. NOTE: In fact, without concrete example, the above description is very difficult to understand. A LL parser is a typical pushdown automaton , the Wikipedia entry LL parser give an concrete and concise example to explain the mechanism of thee parser, that is pushdown automaton . After reading it, I think you will grasp what above paragraph describe. A diagram of a pushdown automaton Deterministic pushdown automaton #","title":"Automaton"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-2/Automaton/#pushdown-automaton","text":"In the theory of computation , a branch of theoretical computer science , a pushdown automaton ( PDA ) is a type of automaton that employs a stack . Pushdown automata are used in theories about what can be computed by machines. They are more capable than finite-state machines but less capable than Turing machines . Deterministic pushdown automata can recognize all deterministic context-free languages while nondeterministic ones can recognize all context-free languages , with the former often used in parser design. The term \"pushdown\" refers to the fact that the stack can be regarded as being \"pushed down\" like a tray dispenser at a cafeteria, since the operations never work on elements other than the top element. A stack automaton , by contrast, does allow access to and operations on deeper elements. Stack automata can recognize a strictly larger set of languages than pushdown automata.[ 1] A nested stack automaton allows full access, and also allows stacked values to be entire sub-stacks rather than just single finite symbols.","title":"Pushdown automaton"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-2/Automaton/#informal-description","text":"A finite state machine just looks at the input signal and the current state : it has no stack to work with. It chooses a new state, the result of following the transition. A pushdown automaton (PDA) differs from a finite state machine in two ways: It can use the top of the stack to decide which transition to take. It can manipulate the stack as part of performing a transition. A pushdown automaton reads a given input string from left to right. In each step, it chooses a transition by indexing a table by input symbol, current state, and the symbol at the top of the stack. A pushdown automaton can also manipulate the stack, as part of performing a transition. The manipulation can be to push a particular symbol to the top of the stack, or to pop off the top of the stack. The automaton can alternatively ignore the stack, and leave it as it is. Put together: Given an input symbol, current state, and stack symbol, the automaton can follow a transition to another state, and optionally manipulate (push or pop) the stack. NOTE: In fact, without concrete example, the above description is very difficult to understand. A LL parser is a typical pushdown automaton , the Wikipedia entry LL parser give an concrete and concise example to explain the mechanism of thee parser, that is pushdown automaton . After reading it, I think you will grasp what above paragraph describe. A diagram of a pushdown automaton","title":"Informal description"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-2/Automaton/#deterministic-pushdown-automaton","text":"","title":"Deterministic pushdown automaton"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-2/wikipedia-Context-free-language/","text":"Context-free language # $ S\\to SS~|~(S)~|~\\varepsilon $. $ {a^{n}b^{n}c^{n}d^{n}|n>0} $ Context-free grammar #","title":"Context-free-language"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-2/wikipedia-Context-free-language/#context-free-language","text":"$ S\\to SS~|~(S)~|~\\varepsilon $. $ {a^{n}b^{n}c^{n}d^{n}|n>0} $","title":"Context-free language"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-2/wikipedia-Context-free-language/#context-free-grammar","text":"","title":"Context-free grammar"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/","text":"Finite-state machine Concepts and terminology Representations Classification Acceptors (recognizers) Classifiers Determinism Mathematical model Optimization Usage Software applications Finite state machines and compilers Deterministic finite automaton Deterministic acyclic finite state automaton application Finite-state machine # TIPS: In Chinese, Finite-state machine means \u6709\u7a77\u81ea\u52a8\u673a A finite-state machine ( FSM ) or finite-state automaton ( FSA , plural: automata ), finite automaton , or simply a state machine , is a mathematical model of computation . It is an abstract machine that can be in exactly one of a finite number of states at any given time. The FSM can change from one state to another in response to some external inputs and/or a condition is satisfied; the change from one state to another is called a transition .[ 1] An FSM is defined by a list of its states, its initial state, and the conditions for each transition. Finite state machines are of two types: deterministic finite state machines non-deterministic finite state machines .[ 2] A deterministic finite-state machine can be constructed equivalent to any non-deterministic one. The behavior of state machines can be observed in many devices in modern society that perform a predetermined sequence of actions depending on a sequence of events with which they are presented. Simple examples are vending machines , which dispense products when the proper combination of coins is deposited, elevators , whose sequence of stops is determined by the floors requested by riders, traffic lights , which change sequence when cars are waiting, and combination locks , which require the input of a sequence of numbers in the proper order. TIPS: The state machine can do much more, see Usage for more detail. The finite state machine has less computational power than some other models of computation such as the Turing machine .[ 3] The computational power distinction means there are computational tasks that a Turing machine can do but a FSM cannot. This is because a FSM's memory is limited by the number of states it has. FSMs are studied in the more general field of automata theory . TIPS: Turing machine operates on an infinite memory. TIPS: There is an incomplete hierarchy in terms of powers of different types of abstract machines in page automata theory Concepts and terminology # A state is a description of the status of a system that is waiting to execute a transition . A transition is a set of actions to be executed when a condition is fulfilled or when an event is received. For example, when using an audio system to listen to the radio (the system is in the \"radio\" state), receiving a \"next\" stimulus results in moving to the next station. When the system is in the \"CD\" state, the \"next\" stimulus results in moving to the next track. Identical stimuli trigger different actions depending on the current state. In some finite-state machine representations, it is also possible to associate actions with a state: an entry action: performed when entering the state, and an exit action: performed when exiting the state. Representations # state transition table UML state machines SDL state machines State diagram Classification # Finite state machines can be subdivided into transducers\uff08\u8f6c\u6362\u5668\uff09 acceptors classifiers sequencers.[ 6] Acceptors (recognizers) # Acceptors (also called recognizers and sequence detectors ), produce binary output , indicating whether or not the received input is accepted. Each state of an FSM is either \"accepting\" or \"not accepting\". Once all input has been received, if the current state is an accepting state , the input is accepted; otherwise it is rejected. As a rule, input is a sequence of symbols (characters); actions are not used. The example in figure 4 shows a finite state machine that accepts the string \"nice\". In this FSM, the only accepting state is state 7. TIPS: In machine learning terms, it's a dichotomy. Fig. 4 Acceptor FSM: parsing the string \"nice\" A (possibly infinite) set of symbol sequences, aka. formal language, is called a regular language if there is some Finite State Machine that accepts exactly that set. For example, the set of binary strings with an even number of zeroes is a regular language (cf. Fig. 5), while the set of all strings whose length is a prime number is not. Fig. 5: Representation of a finite-state machine; this example shows one that determines whether a binary number has an even number of 0s, where S 1 is an accepting state . A machine could also be described as defining a language, that would contain every string accepted by the machine but none of the rejected ones; that language is \"accepted\" by the machine. By definition, the languages accepted by FSMs are the regular languages \u2014; a language is regular if there is some FSM that accepts it. The problem of determining the language accepted by a given finite state acceptor is an instance of the algebraic path problem \u2014itself a generalization of the shortest path problem to graphs with edges weighted by the elements of an (arbitrary) semiring . TIPS: This passage reminds me of regular expression . The start state can also be an accepting state, in which case the automaton accepts the empty string. An example of an accepting state appears in Fig.5: a deterministic finite automaton (DFA) that detects whether the binary input string contains an even number of 0s. S 1 (which is also the start state) indicates the state at which an even number of 0s has been input. S1 is therefore an accepting state . This machine will finish in an accept state , if the binary string contains an even number of 0s (including any binary string containing no 0s). Examples of strings accepted by this DFA are \u03b5 (the empty string ), 1, 11, 11\u2026, 00, 010, 1010, 10110, etc. Classifiers # A classifier is a generalization of a finite state machine that, similar to an acceptor, produces a single output on termination but has more than two terminal states. TIPS: In machine learning terms, it's a multi-class classifier. Determinism # A further distinction is between deterministic ( DFA ) and non-deterministic ( NFA , GNFA ) automata. In a deterministic automaton, every state has exactly one transition for each possible input. In a non-deterministic automaton, an input can lead to one, more than one, or no transition for a given state. The powerset construction algorithm can transform any nondeterministic automaton into a (usually more complex) deterministic automaton with identical functionality. A finite state machine with only one state is called a \"combinatorial FSM\". It only allows actions upon transition into a state. This concept is useful in cases where a number of finite state machines are required to work together, and when it is convenient to consider a purely combinatorial part as a form of FSM to suit the design tools.[ 10] Mathematical model # In accordance with the general classification, the following formal definitions are found: A deterministic finite state machine or acceptor deterministic finite state machine is a quintuple $ (\\Sigma ,S,s_{0},\\delta ,F) $, where: $ \\Sigma $ is the input alphabet (a finite, non-empty set of symbols). $ S $ is a finite, non-empty set of states. $ s_{0} $ is an initial state, an element of $ S $. $ \\delta $ is the state-transition function: $ \\delta :S\\times \\Sigma \\rightarrow S $ (in a nondeterministic finite automaton it would be $ \\delta :S\\times \\Sigma \\rightarrow {\\mathcal {P}}(S) $, i.e., $ \\delta $ would return a set of states). $ F $ is the set of final states, a (possibly empty) subset of $ S $. For both deterministic and non-deterministic FSMs, it is conventional to allow $ \\delta $ to be a partial function , i.e. $ \\delta (q,x) $ does not have to be defined for every combination of $ q\\in S $ and $ x\\in \\Sigma $. If an FSM $ M $ is in a state $ q $, the next symbol is $ x $ and $ \\delta (q,x) $ is not defined, then $ M $ can announce an error (i.e. reject the input). This is useful in definitions of general state machines, but less useful when transforming the machine. Some algorithms in their default form may require total functions . A finite state machine has the same computational power as a Turing machine that is restricted such that its head may only perform \"read\" operations, and always has to move from left to right. That is, each formal language accepted by a finite state machine is accepted by such a kind of restricted Turing machine, and vice versa.[ 15] TIPS: We can conclude that Turing machine is an generalization of finite state machine or finite state machine is a restrictive version of Turing machine . Optimization # Main article: DFA minimization Optimizing an FSM means finding a machine with the minimum number of states that performs the same function. The fastest known algorithm doing this is the Hopcroft minimization algorithm .[ 17] [ 18] Other techniques include using an implication table , or the Moore reduction procedure . Additionally, acyclic FSAs can be minimized in linear time.[ 19] Usage # In addition to their use in modeling reactive systems presented here, finite state machines are significant in many different areas, including electrical engineering , linguistics , computer science , philosophy , biology , mathematics , and logic . Finite state machines are a class of automata studied in automata theory and the theory of computation . In computer science, finite state machines are widely used in modeling of application behavior, design of hardware digital systems , software engineering , compilers , network protocols , and the study of computation and languages. Software applications # The following concepts are commonly used to build software applications with finite state machines: Automata-based programming Event-driven finite-state machine Virtual finite-state machine State design pattern State machine replication Regular expression Finite state machines and compilers # Finite automata are often used in the frontend of programming language compilers. Such a frontend may comprise several finite state machines that implement a lexical analyzer and a parser. Starting from a sequence of characters, the lexical analyzer builds a sequence of language tokens (such as reserved words, literals, and identifiers) from which the parser builds a syntax tree. The lexical analyzer and the parser handle the regular and context-free parts of the programming language's grammar.[ 22] Deterministic finite automaton # Deterministic acyclic finite state automaton # In computer science , a deterministic acyclic finite state automaton ( DAFSA ),[ 1] also called a directed acyclic word graph ( DAWG ; though that name also refers to a related data structure that functions as a suffix index[ 2] ) is a data structure that represents a set of strings , and allows for a query operation that tests whether a given string belongs to the set in time proportional to its length. Algorithms exist to construct and maintain such automata,[ citation needed ] while keeping them minimal . A DAFSA is a special case of a finite state recognizer that takes the form of a directed acyclic graph with a single source vertex (a vertex with no incoming edges), in which each edge of the graph is labeled by a letter or symbol, and in which each vertex has at most one outgoing edge for each possible letter or symbol. The strings represented by the DAFSA are formed by the symbols on paths in the graph from the source vertex to any sink vertex (a vertex with no outgoing edges). In fact, a deterministic finite state automaton is acyclic if and only if it recognizes a finite set of strings .[ 1] application # jieba jieba\u5206\u8bcd\u7b97\u6cd5\u6e90\u7801\u89e3\u6790 jieba\u5206\u8bcd\u7684\u539f\u7406","title":"Automaton"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#finite-state-machine","text":"TIPS: In Chinese, Finite-state machine means \u6709\u7a77\u81ea\u52a8\u673a A finite-state machine ( FSM ) or finite-state automaton ( FSA , plural: automata ), finite automaton , or simply a state machine , is a mathematical model of computation . It is an abstract machine that can be in exactly one of a finite number of states at any given time. The FSM can change from one state to another in response to some external inputs and/or a condition is satisfied; the change from one state to another is called a transition .[ 1] An FSM is defined by a list of its states, its initial state, and the conditions for each transition. Finite state machines are of two types: deterministic finite state machines non-deterministic finite state machines .[ 2] A deterministic finite-state machine can be constructed equivalent to any non-deterministic one. The behavior of state machines can be observed in many devices in modern society that perform a predetermined sequence of actions depending on a sequence of events with which they are presented. Simple examples are vending machines , which dispense products when the proper combination of coins is deposited, elevators , whose sequence of stops is determined by the floors requested by riders, traffic lights , which change sequence when cars are waiting, and combination locks , which require the input of a sequence of numbers in the proper order. TIPS: The state machine can do much more, see Usage for more detail. The finite state machine has less computational power than some other models of computation such as the Turing machine .[ 3] The computational power distinction means there are computational tasks that a Turing machine can do but a FSM cannot. This is because a FSM's memory is limited by the number of states it has. FSMs are studied in the more general field of automata theory . TIPS: Turing machine operates on an infinite memory. TIPS: There is an incomplete hierarchy in terms of powers of different types of abstract machines in page automata theory","title":"Finite-state machine"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#concepts-and-terminology","text":"A state is a description of the status of a system that is waiting to execute a transition . A transition is a set of actions to be executed when a condition is fulfilled or when an event is received. For example, when using an audio system to listen to the radio (the system is in the \"radio\" state), receiving a \"next\" stimulus results in moving to the next station. When the system is in the \"CD\" state, the \"next\" stimulus results in moving to the next track. Identical stimuli trigger different actions depending on the current state. In some finite-state machine representations, it is also possible to associate actions with a state: an entry action: performed when entering the state, and an exit action: performed when exiting the state.","title":"Concepts and terminology"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#representations","text":"state transition table UML state machines SDL state machines State diagram","title":"Representations"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#classification","text":"Finite state machines can be subdivided into transducers\uff08\u8f6c\u6362\u5668\uff09 acceptors classifiers sequencers.[ 6]","title":"Classification"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#acceptors-recognizers","text":"Acceptors (also called recognizers and sequence detectors ), produce binary output , indicating whether or not the received input is accepted. Each state of an FSM is either \"accepting\" or \"not accepting\". Once all input has been received, if the current state is an accepting state , the input is accepted; otherwise it is rejected. As a rule, input is a sequence of symbols (characters); actions are not used. The example in figure 4 shows a finite state machine that accepts the string \"nice\". In this FSM, the only accepting state is state 7. TIPS: In machine learning terms, it's a dichotomy. Fig. 4 Acceptor FSM: parsing the string \"nice\" A (possibly infinite) set of symbol sequences, aka. formal language, is called a regular language if there is some Finite State Machine that accepts exactly that set. For example, the set of binary strings with an even number of zeroes is a regular language (cf. Fig. 5), while the set of all strings whose length is a prime number is not. Fig. 5: Representation of a finite-state machine; this example shows one that determines whether a binary number has an even number of 0s, where S 1 is an accepting state . A machine could also be described as defining a language, that would contain every string accepted by the machine but none of the rejected ones; that language is \"accepted\" by the machine. By definition, the languages accepted by FSMs are the regular languages \u2014; a language is regular if there is some FSM that accepts it. The problem of determining the language accepted by a given finite state acceptor is an instance of the algebraic path problem \u2014itself a generalization of the shortest path problem to graphs with edges weighted by the elements of an (arbitrary) semiring . TIPS: This passage reminds me of regular expression . The start state can also be an accepting state, in which case the automaton accepts the empty string. An example of an accepting state appears in Fig.5: a deterministic finite automaton (DFA) that detects whether the binary input string contains an even number of 0s. S 1 (which is also the start state) indicates the state at which an even number of 0s has been input. S1 is therefore an accepting state . This machine will finish in an accept state , if the binary string contains an even number of 0s (including any binary string containing no 0s). Examples of strings accepted by this DFA are \u03b5 (the empty string ), 1, 11, 11\u2026, 00, 010, 1010, 10110, etc.","title":"Acceptors (recognizers)"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#classifiers","text":"A classifier is a generalization of a finite state machine that, similar to an acceptor, produces a single output on termination but has more than two terminal states. TIPS: In machine learning terms, it's a multi-class classifier.","title":"Classifiers"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#determinism","text":"A further distinction is between deterministic ( DFA ) and non-deterministic ( NFA , GNFA ) automata. In a deterministic automaton, every state has exactly one transition for each possible input. In a non-deterministic automaton, an input can lead to one, more than one, or no transition for a given state. The powerset construction algorithm can transform any nondeterministic automaton into a (usually more complex) deterministic automaton with identical functionality. A finite state machine with only one state is called a \"combinatorial FSM\". It only allows actions upon transition into a state. This concept is useful in cases where a number of finite state machines are required to work together, and when it is convenient to consider a purely combinatorial part as a form of FSM to suit the design tools.[ 10]","title":"Determinism"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#mathematical-model","text":"In accordance with the general classification, the following formal definitions are found: A deterministic finite state machine or acceptor deterministic finite state machine is a quintuple $ (\\Sigma ,S,s_{0},\\delta ,F) $, where: $ \\Sigma $ is the input alphabet (a finite, non-empty set of symbols). $ S $ is a finite, non-empty set of states. $ s_{0} $ is an initial state, an element of $ S $. $ \\delta $ is the state-transition function: $ \\delta :S\\times \\Sigma \\rightarrow S $ (in a nondeterministic finite automaton it would be $ \\delta :S\\times \\Sigma \\rightarrow {\\mathcal {P}}(S) $, i.e., $ \\delta $ would return a set of states). $ F $ is the set of final states, a (possibly empty) subset of $ S $. For both deterministic and non-deterministic FSMs, it is conventional to allow $ \\delta $ to be a partial function , i.e. $ \\delta (q,x) $ does not have to be defined for every combination of $ q\\in S $ and $ x\\in \\Sigma $. If an FSM $ M $ is in a state $ q $, the next symbol is $ x $ and $ \\delta (q,x) $ is not defined, then $ M $ can announce an error (i.e. reject the input). This is useful in definitions of general state machines, but less useful when transforming the machine. Some algorithms in their default form may require total functions . A finite state machine has the same computational power as a Turing machine that is restricted such that its head may only perform \"read\" operations, and always has to move from left to right. That is, each formal language accepted by a finite state machine is accepted by such a kind of restricted Turing machine, and vice versa.[ 15] TIPS: We can conclude that Turing machine is an generalization of finite state machine or finite state machine is a restrictive version of Turing machine .","title":"Mathematical model"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#optimization","text":"Main article: DFA minimization Optimizing an FSM means finding a machine with the minimum number of states that performs the same function. The fastest known algorithm doing this is the Hopcroft minimization algorithm .[ 17] [ 18] Other techniques include using an implication table , or the Moore reduction procedure . Additionally, acyclic FSAs can be minimized in linear time.[ 19]","title":"Optimization"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#usage","text":"In addition to their use in modeling reactive systems presented here, finite state machines are significant in many different areas, including electrical engineering , linguistics , computer science , philosophy , biology , mathematics , and logic . Finite state machines are a class of automata studied in automata theory and the theory of computation . In computer science, finite state machines are widely used in modeling of application behavior, design of hardware digital systems , software engineering , compilers , network protocols , and the study of computation and languages.","title":"Usage"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#software-applications","text":"The following concepts are commonly used to build software applications with finite state machines: Automata-based programming Event-driven finite-state machine Virtual finite-state machine State design pattern State machine replication Regular expression","title":"Software applications"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#finite-state-machines-and-compilers","text":"Finite automata are often used in the frontend of programming language compilers. Such a frontend may comprise several finite state machines that implement a lexical analyzer and a parser. Starting from a sequence of characters, the lexical analyzer builds a sequence of language tokens (such as reserved words, literals, and identifiers) from which the parser builds a syntax tree. The lexical analyzer and the parser handle the regular and context-free parts of the programming language's grammar.[ 22]","title":"Finite state machines and compilers"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#deterministic-finite-automaton","text":"","title":"Deterministic finite automaton"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#deterministic-acyclic-finite-state-automaton","text":"In computer science , a deterministic acyclic finite state automaton ( DAFSA ),[ 1] also called a directed acyclic word graph ( DAWG ; though that name also refers to a related data structure that functions as a suffix index[ 2] ) is a data structure that represents a set of strings , and allows for a query operation that tests whether a given string belongs to the set in time proportional to its length. Algorithms exist to construct and maintain such automata,[ citation needed ] while keeping them minimal . A DAFSA is a special case of a finite state recognizer that takes the form of a directed acyclic graph with a single source vertex (a vertex with no incoming edges), in which each edge of the graph is labeled by a letter or symbol, and in which each vertex has at most one outgoing edge for each possible letter or symbol. The strings represented by the DAFSA are formed by the symbols on paths in the graph from the source vertex to any sink vertex (a vertex with no outgoing edges). In fact, a deterministic finite state automaton is acyclic if and only if it recognizes a finite set of strings .[ 1]","title":"Deterministic acyclic finite state automaton"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Automaton/#application","text":"jieba jieba\u5206\u8bcd\u7b97\u6cd5\u6e90\u7801\u89e3\u6790 jieba\u5206\u8bcd\u7684\u539f\u7406","title":"application"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/wikipedia-Regular-language/","text":"Regular language Regular grammar Regular language # Regular grammar #","title":"Regular-language"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/wikipedia-Regular-language/#regular-language","text":"","title":"Regular language"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/wikipedia-Regular-language/#regular-grammar","text":"","title":"Regular grammar"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Regular-expression/Regex-Engine/","text":"https://se.ifmo.ru/~ad/Documentation/Mastering_RegExp/mastregex2-CHP-4.html https://devopedia.org/regex-engines https://www.codeguru.com/cpp/cpp/cpp_mfc/parsing/article.php/c4093/Write-Your-Own-Regular-Expression-Parser.htm","title":"Regex-Engine"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Regular-expression/wikipedia-Regular-expression/","text":"Regular expression Regular expression #","title":"Regular-expression"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Regular-expression/wikipedia-Regular-expression/#regular-expression","text":"","title":"Regular expression"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Regular-expression/wikipedia-Thompson's-construction/","text":"Thompson's construction Thompson's construction #","title":"Thompson's-construction"},{"location":"Theory-framework/Formal-language/Formal-grammar/Chomsky-hierarchy/Type-3/Regular-expression/wikipedia-Thompson's-construction/#thompsons-construction","text":"","title":"Thompson's construction"},{"location":"Theory-framework/Formal-language/Formal-grammar/Parsing-Expression-Grammars/The-Packrat-Parsing-and-Parsing-Expression-Grammars-Page/","text":"The Packrat Parsing and Parsing Expression Grammars Page #","title":"[The Packrat Parsing and Parsing Expression Grammars Page](https://bford.info/packrat/)"},{"location":"Theory-framework/Formal-language/Formal-grammar/Parsing-Expression-Grammars/The-Packrat-Parsing-and-Parsing-Expression-Grammars-Page/#the-packrat-parsing-and-parsing-expression-grammars-page","text":"","title":"The Packrat Parsing and Parsing Expression Grammars Page"},{"location":"Theory-framework/Formal-language/Formal-grammar/Parsing-Expression-Grammars/wikipedia-Parsing-expression-grammar/","text":"Parsing expression grammar Parsing expression grammar # In computer science , a parsing expression grammar , or PEG , is a type of analytic formal grammar , i.e. it describes a formal language in terms of a set of rules for recognizing strings in the language. The formalism was introduced by Bryan Ford in 2004[ 1] and is closely related to the family of top-down parsing languages introduced in the early 1970s. Syntactically, PEGs also look similar to context-free grammars (CFGs), but they have a different interpretation: the choice operator selects the first match in PEG, while it is ambiguous in CFG. This is closer to how string recognition tends to be done in practice, e.g. by a recursive descent parser . NOTE: PEG include regular grammar. Unlike CFGs, PEGs cannot be ambiguous ; if a string parses, it has exactly one valid parse tree . It is conjectured that there exist context-free languages that cannot be recognized by a PEG, but this is not yet proven.[ 1] PEGs are well-suited to parsing computer languages (and artificial human languages such as Lojban ), but not natural languages where the performance of PEG algorithms is comparable to general CFG algorithms such as the Earley algorithm . NOTE: Python3.8+ use PEG to describe its grammar.","title":"wikipedia Parsing expression grammar"},{"location":"Theory-framework/Formal-language/Formal-grammar/Parsing-Expression-Grammars/wikipedia-Parsing-expression-grammar/#parsing-expression-grammar","text":"In computer science , a parsing expression grammar , or PEG , is a type of analytic formal grammar , i.e. it describes a formal language in terms of a set of rules for recognizing strings in the language. The formalism was introduced by Bryan Ford in 2004[ 1] and is closely related to the family of top-down parsing languages introduced in the early 1970s. Syntactically, PEGs also look similar to context-free grammars (CFGs), but they have a different interpretation: the choice operator selects the first match in PEG, while it is ambiguous in CFG. This is closer to how string recognition tends to be done in practice, e.g. by a recursive descent parser . NOTE: PEG include regular grammar. Unlike CFGs, PEGs cannot be ambiguous ; if a string parses, it has exactly one valid parse tree . It is conjectured that there exist context-free languages that cannot be recognized by a PEG, but this is not yet proven.[ 1] PEGs are well-suited to parsing computer languages (and artificial human languages such as Lojban ), but not natural languages where the performance of PEG algorithms is comparable to general CFG algorithms such as the Earley algorithm . NOTE: Python3.8+ use PEG to describe its grammar.","title":"Parsing expression grammar"},{"location":"Theory-framework/Theory-of-computation/","text":"\u5728\u9605\u8bfbautomata theory\u7684\u65f6\u5019\uff0c\u53d1\u73b0\u539f\u6765\u5b83\u662ftheory of computation\u7684\u4e00\u4e2a\u5206\u652f\uff0c\u6240\u4ee5\u6b64\u5904\u5c31\u5c06theory of computation\u4e00\u5e76\u7ed9\u6574\u7406\u4e86\u4e00\u4e0b\u3002 \u9996\u5148\u63cf\u8ff0 theory of computation \uff0c\u7136\u540e\u63cf\u8ff0 model of computation \uff0c\u7136\u540e\u63cf\u8ff0\u5b83\u7684\u5404\u4e2abranch\uff08\u5171\u4e09\u4e2a\uff0c\u8fd9\u4e09\u4e2abranch\u662fsoftware engineer\u7ecf\u5e38\u4f1a\u63a5\u89e6\u5230\u7684\uff09\u3002\u56e0\u4e3a model of computation \u5728\u4e09\u4e2abranch\u4e2d\u90fd\u4f1a\u4f7f\u7528\u5230\uff0c\u6240\u4ee5\u628a\u5b83\u653e\u5230\u524d\u9762\u6765\u8fdb\u884c\u63cf\u8ff0\u3002","title":"Home"},{"location":"Theory-framework/Theory-of-computation/wikipedia-Theory-of-computation/","text":"Theory of computation # In theoretical computer science and mathematics , the theory of computation is the branch that deals with how efficiently problems can be solved on a model of computation , using an algorithm . The field is divided into three major branches: automata theory and formal languages computability theory computational complexity theory , which are linked by the question: \"What are the fundamental capabilities and limitations of computers?\". In order to perform a rigorous study of computation, computer scientists work with a mathematical abstraction of computers called a model of computation . There are several models in use, but the most commonly examined is the Turing machine . Computer scientists study the Turing machine because it is simple to formulate, can be analyzed and used to prove results, and because it represents what many consider the most powerful possible \"reasonable\" model of computation (see Church\u2013Turing thesis ). It might seem that the potentially infinite memory capacity is an unrealizable attribute, but any decidable problem solved by a Turing machine will always require only a finite amount of memory. So in principle, any problem that can be solved (decided) by a Turing machine can be solved by a computer that has a finite amount of memory.","title":"[Theory of computation](https://en.wikipedia.org/wiki/Theory_of_computation)"},{"location":"Theory-framework/Theory-of-computation/wikipedia-Theory-of-computation/#theory-of-computation","text":"In theoretical computer science and mathematics , the theory of computation is the branch that deals with how efficiently problems can be solved on a model of computation , using an algorithm . The field is divided into three major branches: automata theory and formal languages computability theory computational complexity theory , which are linked by the question: \"What are the fundamental capabilities and limitations of computers?\". In order to perform a rigorous study of computation, computer scientists work with a mathematical abstraction of computers called a model of computation . There are several models in use, but the most commonly examined is the Turing machine . Computer scientists study the Turing machine because it is simple to formulate, can be analyzed and used to prove results, and because it represents what many consider the most powerful possible \"reasonable\" model of computation (see Church\u2013Turing thesis ). It might seem that the potentially infinite memory capacity is an unrealizable attribute, but any decidable problem solved by a Turing machine will always require only a finite amount of memory. So in principle, any problem that can be solved (decided) by a Turing machine can be solved by a computer that has a finite amount of memory.","title":"Theory of computation"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/","text":"","title":"Home"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/wikipedia-Abstract-machine/","text":"Abstract machine Abstract machine # An abstract machine , also called an abstract computer , is a theoretical model of a computer hardware or software system used in automata theory . Abstraction of computing processes is used in both the computer science and computer engineering disciplines and usually assumes a discrete time paradigm .","title":"wikipedia Abstract machine"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/wikipedia-Abstract-machine/#abstract-machine","text":"An abstract machine , also called an abstract computer , is a theoretical model of a computer hardware or software system used in automata theory . Abstraction of computing processes is used in both the computer science and computer engineering disciplines and usually assumes a discrete time paradigm .","title":"Abstract machine"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/wikipedia-Automata-theory/","text":"Automata theory Automata Informal description Formal definition Classes of automata Discrete, continuous, and hybrid automata Hierarchy in terms of powers Applications Automata simulators Automata theory # TIPS: In Chinese, Automata theory means \u81ea\u52a8\u673a\u7406\u8bba. Automata theory is the study of abstract machines and automata , as well as the computational problems that can be solved using them. It is a theory in theoretical computer science and discrete mathematics (a subject of study in both mathematics and computer science ). The word automata (the plural of automaton ) comes from the Greek word \u03b1\u1f50\u03c4\u03cc\u03bc\u03b1\u03c4\u03b1, which means \"self-making\". The figure at right illustrates a finite-state machine , which belongs to a well-known type of automaton. This automaton\uff08\u81ea\u52a8\u673a\uff09 consists of states (represented in the figure by circles) and transitions (represented by arrows). As the automaton sees a symbol of input, it makes a transition (or jump) to another state, according to its transition function , which takes the current state and the recent symbol as its inputs. Automata theory is closely related to formal language theory. An automaton is a finite representation of a formal language that may be an infinite set . Automata are often classified by the class of formal languages they can recognize, typically illustrated by the Chomsky hierarchy , which describes the relations between various languages and kinds of formalized logics. TIPS: It is obvious that automata theory is an important tool for research formal language. Automata play a major role in theory of computation , compiler construction \uff08\u7f16\u8bd1\u5668\u7684\u6784\u5efa\uff09, artificial intelligence , parsing and formal verification . Classes of automata: Turing machine Pushdown automaton Finite-state machine Combinational logic The study of the mathematical properties of such automata is automata theory. The picture is a visualization of an automaton that recognizes strings containing an even number of 0 s. The automaton starts in state S1 , and transitions to the non-accepting state S2 upon reading the symbol 0 . Reading another 0 causes the automaton to transition back to the accepting state S1 . In both states the symbol 1 is ignored by making a transition to the current state. TIPS: The diagram above is called a state diagram . Automata # Following is an introductory definition of one type of automaton, which attempts to help one grasp the essential concepts involved in automata theory/theories. Informal description # An automaton runs when it is given some sequence of inputs in discrete (individual) time steps or steps. An automaton processes one input picked from a set of symbols or letters , which is called an alphabet . The symbols received by the automaton as input at any step are a finite sequence of symbols called words . An automaton has a finite set of states . At each moment during a run of the automaton, the automaton is in one of its states. When the automaton receives new input it moves to another state (or transitions) based on a function that takes the current state and symbol as parameters. This function is called the transition function . The automaton reads the symbols of the input word one after another and transitions from state to state according to the transition function until the word is read completely. Once the input word has been read, the automaton is said to have stopped. The state at which the automaton stops is called the final state . Depending on the final state , it's said that the automaton either accepts or rejects an input word. There is a subset of states of the automaton, which is defined as the set of accepting states . If the final state is an accepting state , then the automaton accepts the word. Otherwise, the word is rejected . The set of all the words accepted by an automaton is called the language recognized by the automaton . In short, an automaton is a mathematical object that takes a word as input and decides whether to accept it or reject it. Since all computational problems are reducible into the accept/reject question on inputs, (all problem instances can be represented in a finite length of symbols), automata theory plays a crucial role in computational theory . TIPS: In formal language, automata act as recognizer or matcher consuming characters or tokens . The graph above is a good example of automaton. Automata can be used not only in formal language, it has many application in computer science, such as: Event-driven finite-state machine State machine replication In these applications, what automaton consume can be event. See Finite-state machine for more detail. Formal definition # Automaton Classes of automata # The following is an incomplete list of types of automata. Automaton Recognizable language Nondeterministic/Deterministic Finite state machine (FSM) regular languages Deterministic pushdown automaton (DPDA) deterministic context-free languages Pushdown automaton (PDA) context-free languages Linear bounded automaton (LBA) context-sensitive languages Turing machine recursively enumerable languages Deterministic B\u00fcchi automaton \u03c9-limit languages Nondeterministic B\u00fcchi automaton \u03c9-regular languages Rabin automaton , Streett automaton , Parity automaton , Muller automaton Discrete, continuous, and hybrid automata # Normally automata theory describes the states of abstract machines but there are analog automata or continuous automata or hybrid discrete-continuous automata , which use analog data, continuous time, or both. Hierarchy in terms of powers # The following is an incomplete hierarchy in terms of powers of different types of virtual machines. The hierarchy reflects the nested categories of languages the machines are able to accept.[ 1] Automaton Deterministic Finite Automaton (DFA) -- Lowest Power (same power) $ Applications # Each model in automata theory plays important roles in several applied areas. Finite automata are used in text processing, compilers, and hardware design. Context-free grammar (CFGs) are used in programming languages and artificial intelligence. Originally, CFGs were used in the study of the human languages. Cellular automata are used in the field of biology, the most common example being John Conway 's Game of Life . Some other examples which could be explained using automata theory in biology include mollusk and pine cones growth and pigmentation patterns. Going further, a theory suggesting that the whole universe is computed by some sort of a discrete automaton, is advocated by some scientists. The idea originated in the work of Konrad Zuse , and was popularized in America by Edward Fredkin . Automata also appear in the theory of finite fields: the set of irreducible polynomials which can be written as composition of degree two polynomials is in fact a regular language.[ 2] Automata simulators # Automata simulators are pedagogical tools used to teach, learn and research automata theory. An automata simulator takes as input the description of an automaton and then simulates its working for an arbitrary input string. The description of the automaton can be entered in several ways. An automaton can be defined in a symbolic language or its specification may be entered in a predesigned form or its transition diagram may be drawn by clicking and dragging the mouse. Well known automata simulators include Turing's World, JFLAP, VAS, TAGS and SimStudio.[ 3]","title":"wikipedia Automata theory"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/wikipedia-Automata-theory/#automata-theory","text":"TIPS: In Chinese, Automata theory means \u81ea\u52a8\u673a\u7406\u8bba. Automata theory is the study of abstract machines and automata , as well as the computational problems that can be solved using them. It is a theory in theoretical computer science and discrete mathematics (a subject of study in both mathematics and computer science ). The word automata (the plural of automaton ) comes from the Greek word \u03b1\u1f50\u03c4\u03cc\u03bc\u03b1\u03c4\u03b1, which means \"self-making\". The figure at right illustrates a finite-state machine , which belongs to a well-known type of automaton. This automaton\uff08\u81ea\u52a8\u673a\uff09 consists of states (represented in the figure by circles) and transitions (represented by arrows). As the automaton sees a symbol of input, it makes a transition (or jump) to another state, according to its transition function , which takes the current state and the recent symbol as its inputs. Automata theory is closely related to formal language theory. An automaton is a finite representation of a formal language that may be an infinite set . Automata are often classified by the class of formal languages they can recognize, typically illustrated by the Chomsky hierarchy , which describes the relations between various languages and kinds of formalized logics. TIPS: It is obvious that automata theory is an important tool for research formal language. Automata play a major role in theory of computation , compiler construction \uff08\u7f16\u8bd1\u5668\u7684\u6784\u5efa\uff09, artificial intelligence , parsing and formal verification . Classes of automata: Turing machine Pushdown automaton Finite-state machine Combinational logic The study of the mathematical properties of such automata is automata theory. The picture is a visualization of an automaton that recognizes strings containing an even number of 0 s. The automaton starts in state S1 , and transitions to the non-accepting state S2 upon reading the symbol 0 . Reading another 0 causes the automaton to transition back to the accepting state S1 . In both states the symbol 1 is ignored by making a transition to the current state. TIPS: The diagram above is called a state diagram .","title":"Automata theory"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/wikipedia-Automata-theory/#automata","text":"Following is an introductory definition of one type of automaton, which attempts to help one grasp the essential concepts involved in automata theory/theories.","title":"Automata"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/wikipedia-Automata-theory/#informal-description","text":"An automaton runs when it is given some sequence of inputs in discrete (individual) time steps or steps. An automaton processes one input picked from a set of symbols or letters , which is called an alphabet . The symbols received by the automaton as input at any step are a finite sequence of symbols called words . An automaton has a finite set of states . At each moment during a run of the automaton, the automaton is in one of its states. When the automaton receives new input it moves to another state (or transitions) based on a function that takes the current state and symbol as parameters. This function is called the transition function . The automaton reads the symbols of the input word one after another and transitions from state to state according to the transition function until the word is read completely. Once the input word has been read, the automaton is said to have stopped. The state at which the automaton stops is called the final state . Depending on the final state , it's said that the automaton either accepts or rejects an input word. There is a subset of states of the automaton, which is defined as the set of accepting states . If the final state is an accepting state , then the automaton accepts the word. Otherwise, the word is rejected . The set of all the words accepted by an automaton is called the language recognized by the automaton . In short, an automaton is a mathematical object that takes a word as input and decides whether to accept it or reject it. Since all computational problems are reducible into the accept/reject question on inputs, (all problem instances can be represented in a finite length of symbols), automata theory plays a crucial role in computational theory . TIPS: In formal language, automata act as recognizer or matcher consuming characters or tokens . The graph above is a good example of automaton. Automata can be used not only in formal language, it has many application in computer science, such as: Event-driven finite-state machine State machine replication In these applications, what automaton consume can be event. See Finite-state machine for more detail.","title":"Informal description"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/wikipedia-Automata-theory/#formal-definition","text":"Automaton","title":"Formal definition"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/wikipedia-Automata-theory/#classes-of-automata","text":"The following is an incomplete list of types of automata. Automaton Recognizable language Nondeterministic/Deterministic Finite state machine (FSM) regular languages Deterministic pushdown automaton (DPDA) deterministic context-free languages Pushdown automaton (PDA) context-free languages Linear bounded automaton (LBA) context-sensitive languages Turing machine recursively enumerable languages Deterministic B\u00fcchi automaton \u03c9-limit languages Nondeterministic B\u00fcchi automaton \u03c9-regular languages Rabin automaton , Streett automaton , Parity automaton , Muller automaton","title":"Classes of automata"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/wikipedia-Automata-theory/#discrete-continuous-and-hybrid-automata","text":"Normally automata theory describes the states of abstract machines but there are analog automata or continuous automata or hybrid discrete-continuous automata , which use analog data, continuous time, or both.","title":"Discrete, continuous, and hybrid automata"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/wikipedia-Automata-theory/#hierarchy-in-terms-of-powers","text":"The following is an incomplete hierarchy in terms of powers of different types of virtual machines. The hierarchy reflects the nested categories of languages the machines are able to accept.[ 1] Automaton Deterministic Finite Automaton (DFA) -- Lowest Power (same power) $","title":"Hierarchy in terms of powers"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/wikipedia-Automata-theory/#applications","text":"Each model in automata theory plays important roles in several applied areas. Finite automata are used in text processing, compilers, and hardware design. Context-free grammar (CFGs) are used in programming languages and artificial intelligence. Originally, CFGs were used in the study of the human languages. Cellular automata are used in the field of biology, the most common example being John Conway 's Game of Life . Some other examples which could be explained using automata theory in biology include mollusk and pine cones growth and pigmentation patterns. Going further, a theory suggesting that the whole universe is computed by some sort of a discrete automaton, is advocated by some scientists. The idea originated in the work of Konrad Zuse , and was popularized in America by Edward Fredkin . Automata also appear in the theory of finite fields: the set of irreducible polynomials which can be written as composition of degree two polynomials is in fact a regular language.[ 2]","title":"Applications"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/wikipedia-Automata-theory/#automata-simulators","text":"Automata simulators are pedagogical tools used to teach, learn and research automata theory. An automata simulator takes as input the description of an automaton and then simulates its working for an arbitrary input string. The description of the automaton can be entered in several ways. An automaton can be defined in a symbolic language or its specification may be entered in a predesigned form or its transition diagram may be drawn by clicking and dragging the mouse. Well known automata simulators include Turing's World, JFLAP, VAS, TAGS and SimStudio.[ 3]","title":"Automata simulators"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/State-space/VS-state-space-VS-graph/","text":"","title":"VS state space VS graph"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/State-space/wikipedia-State-space-search/","text":"State space search State space search #","title":"wikipedia State space search"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/State-space/wikipedia-State-space-search/#state-space-search","text":"","title":"State space search"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/State-space/wikipedia-State-space/","text":"State space TODO \u72b6\u6001\u7a7a\u95f4VS\u89e3\u7a7a\u95f4 State space # TODO \u72b6\u6001\u7a7a\u95f4VS\u89e3\u7a7a\u95f4 #","title":"wikipedia State space"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/State-space/wikipedia-State-space/#state-space","text":"","title":"State space"},{"location":"Theory-framework/Theory-of-computation/Automata-theory/State-space/wikipedia-State-space/#todo-vs","text":"","title":"TODO \u72b6\u6001\u7a7a\u95f4VS\u89e3\u7a7a\u95f4"},{"location":"Theory-framework/Theory-of-computation/Computability-theory/wikipedia-Computability-theory/","text":"Computability theory #","title":"[Computability theory](https://en.wikipedia.org/wiki/Computability_theory)"},{"location":"Theory-framework/Theory-of-computation/Computability-theory/wikipedia-Computability-theory/#computability-theory","text":"","title":"Computability theory"},{"location":"Theory-framework/Theory-of-computation/Model-of-computation/wikipedia-Model-of-computation/","text":"Model of computation # In computer science , and more specifically in computability theory and computational complexity theory , a model of computation is a model which describes how an output of a mathematical function is computed given an input. A model describes how units of computations, memories, and communications are organized. The computational complexity of an algorithm can be measured given a model of computation. Using a model allows studying the performance of algorithms independently of the variations that are specific to particular implementations and specific technology. Models # Models of computation can be classified in three categories: sequential models, functional models, and concurrent models. Sequential models include: Finite state machines Pushdown automata Turing machine Functional models include: Lambda calculus Recursive functions Combinatory logic Abstract rewriting systems Concurrent models include: Cellular automaton Kahn process networks Petri nets Synchronous Data Flow Interaction nets Actor model Models differ in their expressive power ; for example, each function that can be computed by a Finite state machine can also be computed by a Turing machine , but not vice versa. Categories # There are many models of computation, differing in the set of admissible operations and their computations cost. They fall into the following broad categories: Abstract machine and models equivalent to it (e.g. lambda calculus is equivalent to the Turing machine ) - used in proofs of computability and upper bounds on computational complexity of algorithms . Decision tree models - used in proofs of lower bounds on computational complexity of algorithmic problems.","title":"[Model of computation](https://en.wikipedia.org/wiki/Model_of_computation)"},{"location":"Theory-framework/Theory-of-computation/Model-of-computation/wikipedia-Model-of-computation/#model-of-computation","text":"In computer science , and more specifically in computability theory and computational complexity theory , a model of computation is a model which describes how an output of a mathematical function is computed given an input. A model describes how units of computations, memories, and communications are organized. The computational complexity of an algorithm can be measured given a model of computation. Using a model allows studying the performance of algorithms independently of the variations that are specific to particular implementations and specific technology.","title":"Model of computation"},{"location":"Theory-framework/Theory-of-computation/Model-of-computation/wikipedia-Model-of-computation/#models","text":"Models of computation can be classified in three categories: sequential models, functional models, and concurrent models. Sequential models include: Finite state machines Pushdown automata Turing machine Functional models include: Lambda calculus Recursive functions Combinatory logic Abstract rewriting systems Concurrent models include: Cellular automaton Kahn process networks Petri nets Synchronous Data Flow Interaction nets Actor model Models differ in their expressive power ; for example, each function that can be computed by a Finite state machine can also be computed by a Turing machine , but not vice versa.","title":"Models"},{"location":"Theory-framework/Theory-of-computation/Model-of-computation/wikipedia-Model-of-computation/#categories","text":"There are many models of computation, differing in the set of admissible operations and their computations cost. They fall into the following broad categories: Abstract machine and models equivalent to it (e.g. lambda calculus is equivalent to the Turing machine ) - used in proofs of computability and upper bounds on computational complexity of algorithms . Decision tree models - used in proofs of lower bounds on computational complexity of algorithmic problems.","title":"Categories"}]}