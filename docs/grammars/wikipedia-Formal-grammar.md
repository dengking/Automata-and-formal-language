[TOC]

# [Formal grammar](https://en.wikipedia.org/wiki/Formal_grammar)

In [formal language theory](https://en.wikipedia.org/wiki/Formal_language), a **grammar** (when the context is not given, often called a **formal grammar** for clarity) is a set of [production rules](https://en.wikipedia.org/wiki/Production_(computer_science)) for [strings](https://en.wikipedia.org/wiki/String_(computer_science)) in a [formal language](https://en.wikipedia.org/wiki/Formal_language). The rules describe how to form strings from the language's [alphabet](https://en.wikipedia.org/wiki/Alphabet_(computer_science)) that are valid according to the language's [syntax](https://en.wikipedia.org/wiki/Syntax_(programming_languages)). A grammar does not describe the [meaning of the strings](https://en.wikipedia.org/wiki/Semantics) or what can be done with them in whatever context—only their form.

***SUMMARY*** : 不涉及[semantics](https://en.wikipedia.org/wiki/Semantics)

[Formal language theory](https://en.wikipedia.org/wiki/Formal_language), the discipline that studies formal grammars and languages, is a branch of [applied mathematics](https://en.wikipedia.org/wiki/Applied_mathematics). Its applications are found in [theoretical computer science](https://en.wikipedia.org/wiki/Theoretical_computer_science), [theoretical linguistics](https://en.wikipedia.org/wiki/Theoretical_linguistics), [formal semantics](https://en.wikipedia.org/wiki/Formal_semantics_(logic)), [mathematical logic](https://en.wikipedia.org/wiki/Mathematical_logic), and other areas.

A formal grammar is a set of rules for **rewriting** strings, along with a "start symbol" from which **rewriting** starts. Therefore, a **grammar** is usually thought of as a **language generator**. However, it can also sometimes be used as the basis for a "[recognizer](https://en.wikipedia.org/wiki/Recognizer)"—a function in computing that determines whether a given string belongs to the language or is grammatically incorrect. To describe such **recognizers**, formal language theory uses separate formalisms（独立的形式主义）, known as [automata theory](https://en.wikipedia.org/wiki/Automata_theory). One of the interesting results of **automata theory** is that it is not possible to design a **recognizer** for certain **formal languages**.[[1\]](https://en.wikipedia.org/wiki/Formal_grammar#cite_note-1) [Parsing](https://en.wikipedia.org/wiki/Parsing) is the process of recognizing an utterance (a string in natural languages) by breaking it down to a set of **symbols** and analyzing each one against the **grammar** of the language. Most languages have the meanings of their utterances structured according to their **syntax**—a practice known as [compositional semantics](https://en.wikipedia.org/wiki/Compositional_semantics). As a result, the first step to describing the meaning of an utterance in language is to break it down part by part and look at its analyzed form (known as its [parse tree](https://en.wikipedia.org/wiki/Parse_tree) in computer science, and as its [deep structure](https://en.wikipedia.org/wiki/Deep_structure_and_surface_structure) in [generative grammar](https://en.wikipedia.org/wiki/Generative_grammar)).

## History

 *[Pāṇini](https://en.wikipedia.org/wiki/Pāṇini)*'s treatise *Astadyayi* gives formal production rules and definitions to describe the formal grammar of [Sanskrit](https://en.wikipedia.org/wiki/Sanskrit).[[2\]](https://en.wikipedia.org/wiki/Formal_grammar#cite_note-2) There are different uses of "form" and "formalism", which have changed over time, depending on the fields the relevant author was in contact with. A historical overview of the concept is given in [[3\]](https://en.wikipedia.org/wiki/Formal_grammar#cite_note-mcelvenny-3) 

## Introductory example

A grammar mainly consists of a set of rules for transforming strings. (If it *only* consisted of these rules, it would be a [semi-Thue system](https://en.wikipedia.org/wiki/Semi-Thue_system).) To generate a string in the language, one begins with a string consisting of only a single *start symbol*. The *[production rules](https://en.wikipedia.org/wiki/Production_(computer_science))* are then applied in any order, until a string that contains neither the start symbol nor designated *nonterminal symbols* is produced. A production rule is applied to a string by replacing one occurrence of the production rule's left-hand side in the string by that production rule's right-hand side (*cf.* the operation of the theoretical [Turing machine](https://en.wikipedia.org/wiki/Turing_machine)). The language formed by the grammar consists of all distinct strings that can be generated in this manner. Any particular sequence of production rules on the start symbol yields a distinct string in the language. If there are essentially different ways of generating the same single string, the grammar is said to be [ambiguous](https://en.wikipedia.org/wiki/Ambiguous_grammar).

For example, assume the alphabet consists of *a* and *b*, the start symbol is *S*, and we have the following production rules:

\1. $ S\rightarrow aSb $

\2. $ S\rightarrow ba $

then we start with *S*, and can choose a rule to apply to it. If we choose rule 1, we obtain the string *aSb*. If we then choose rule 1 again, we replace *S* with *aSb* and obtain the string *aaSbb*. If we now choose rule 2, we replace *S* with *ba* and obtain the string *aababb*, and are done. We can write this series of choices more briefly, using symbols: $ S\Rightarrow aSb\Rightarrow aaSbb\Rightarrow aababb $. The language of the grammar is then the infinite set $ \{a^{n}bab^{n}\mid n\geq 0\}=\{ba,abab,aababb,aaababbb,\dotsc \} $, where $ a^{k} $ is $ a $ repeated $ k $ times (and $ n $ in particular represents the number of times production rule 1 has been applied).

